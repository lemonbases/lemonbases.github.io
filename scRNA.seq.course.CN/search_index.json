[
["index.html", "scRNA-seq数据分析 1 说在前面的话 1.1 关于本项目 1.2 视频 1.3 GitHub 1.4 Docker 镜像 1.5 手动安装 1.6 许可 1.7 准备知识 1.8 联系我们", " scRNA-seq数据分析 碱基吃柠檬 2019-06-24 1 说在前面的话 本项目是将github上经典的scRNA-seq分析教程进行汉化，源项目参见hemberg-lab/scRNA.seq.course 1.1 关于本项目 随着技术发展的日新月异，现在对单个细胞进行高通量测序(scRNA-seq)获得其全基因组的表达谱数据成为可能。scRNA-seq的主要优势是其单细胞水平的分辨率和基因组范围检测能力可以解决其他方法难以解决的问题，比如bulk RNA-seq和RT-qPCR。然而，为了分析scRNA-seq数据，需要新的方法，并且一些针对bulk RNA-seq实验开发的方法的潜在假设也不再适用。 在本课程中，我们将讨论使用scRNA-seq可以解决的一些问题以及可用的计算和统计方法。 本课程通过University of Cambridge的Bioinformatics training unit进行教学，但该页面的材料适用于任何有兴趣了解scRNA-seq数据计算分析的人。 本课程每年讲授两次，每次授课前材料都会更新。 计算工具的数量正在迅速增加，我们正在尽最大努力跟上最新进展。 本课程的主要限制之一是我们倾向使用在R中实现且运行速度相当快的工具。 此外，我们还承认某种程度上偏向于我们或我们的朋友和同事开发的方法。 1.2 视频 该视频于2017年11月录制，当时课程包含的章节少于当前版本。 最新课程的直播录制版见YouTube 1.3 GitHub https://github.com/hemberg-lab/scRNA.seq.course https://github.com/lemonbases/scRNA.seq.course.CN 1.4 Docker 镜像 本课程提供包含所有必须软件的Docker镜像，可通过运行Docker镜像重复本课程的结果。 1.4.1 运行镜像 首先确保您的系统上安装了Docker。如果没有，请参照以下说明进行安装。运行本课程的Docker镜像(使用最新版而不是v3.13)。 docker run -p 8888:8888 -e PASSWORD=&quot;jupyter&quot; quay.io/hemberg-group/scrna-seq-course:v3.13 然后按照以下提供的说明操作, 比如: 要访问NoteBook，在浏览器中打开此文件: file:///home/jovyan/.local/share/jupyter/runtime/nbserver-6-open.html 或复制粘贴以下网址: http://(a9ee1aad5398 or 127.0.0.1):8888/?token=22debff49d9aae3c50e6b0b5241b47eefb1b8f883fcb7e6d Jupyter session会在web浏览器中打开(我们推荐使用Chrome浏览器) 1.4.1.1 Windows用户 Windows操作系统中容器的IP地址与127.0.0.1(localhost)不同。查找IP地址请运行: docker-machine ip default 1.4.2 下载数据或其它文件 请点击New -&gt; Terminal打开一个终端，在新的终端窗口运行: ./poststart.sh 如果您想在Docker镜像外下载数据，您依然可以使用相同poststart.sh脚本，但是您需要在您的计算机上安装AWS CLI。 Alternatively, you can browse and download the files in you web-browser by visiting this link 1.4.3 RStudio 返回到Jupyter浏览界面，将url中的tree更改为rstudio。RStudio server会打开课程文件，软件和数据文件夹。 1.5 手动安装 如果您没有使用本课程的Docker镜像，那么为了能够运行本课程所有的代码块，您需要克隆或下载GitHub仓，并在course_files文件夹中启动R session，然后您还需要手动安装所有必须的软件。 或者您可以只安装感兴趣章节列出的软件。 1.6 许可 本课程所有资料均遵循GPL-3协议。 欢迎任何人浏览材料来学习scRNA-seq数据的分析。 如果您打算将这些材料用于您自己的教学，除了提供合适的引用外，如果您告诉我们，我们将不胜感激。 1.7 准备知识 本课程面向那些基本熟悉Unix和R脚本语言的人。同时我们还假设您熟悉传统bulk RNA-seq数据的比对和分析，以及常用的计算工具。 我们推荐在参加本课程前参加Introduction to RNA-seq and ChIP-seq data analysis 或者 Analysis of high-throughput sequencing data with Bioconductor 1.8 联系我们 如果您有任何的关于课程的意见，问题和建议，请联系Vladimir Kiselev. 译者注 : 或者在该repo下开个issue进行提问。 "],
["introduction-to-single-cell-rna-seq.html", "2 scRNA-seq介绍 2.1 Bulk RNA-seq 2.2 scRNA-seq 2.3 工作流程 2.4 计算分析 2.5 挑战 2.6 实验方法 2.7 如何选择合适的平台", " 2 scRNA-seq介绍 2.1 Bulk RNA-seq 2000后期重大突破，取代微阵列芯片被广泛采用 测量大量混合细胞的平均表达水平 用于比较转录组学，例如比较不同物种同一组织的样本 用于量化整体表达特征，例如疾病研究 不足研究异质性系统，例如早起发育的研究，复杂组织(脑)的研究 不能呈现基因表达随机性 2.2 scRNA-seq 一项新兴技术，第一篇文章为汤富酬发表在Nature method (Tang et al. 2009) 直到~2014年，新测序手段和更低的成本使其流行起来 在大量细胞检测每个基因的表达水平 可以研究新的生物学问题，其中转录组的细胞特异性变化是重要的，比如细胞类型鉴定，细胞响应的异质性，基因表达的随机性，细胞间基因调控网络的推断 研究细胞数目从\\(10^2\\)到\\(10^6\\)个细胞，而且每年递增 目前有不同单细胞的protocol，比如SMART-seq2 (Picelli et al. 2013), CELL-seq (Hashimshony et al. 2012) 和 Drop-seq (Macosko et al. 2015) 也有商业平台, 包括 Fluidigm C1, Wafergen ICELL8 和 10X Genomics Chromium 一些计算分析bulk RNA-seq的方法也适用于 scRNA-seq 大多数情况下 scRNA-seq计算分析需要调整已有方法或者开发新方法 2.3 工作流程 Figure 2.1: 单细胞测序流程 (源自wiki) 总体而言，scRNA-seq实验protocol和bulk RNA-seq类似，我们将在下一章讨论一些最常用的方法。 2.4 计算分析 本课程是用scRNA-seq实验获得的数据进行计算分析。 第一步（黄色）对任何高通量测序数据都是通用的； 后续步骤（橙色）需要整合现有的RNA-Seq分析方法和新方法来解决scRNA-Seq的技术差异； 最后步骤（蓝色），用专门为scRNA-Seq开发的方法进行生物学解释。 Figure 2.2: scRNA-seq分析流程图 目前有几篇关于scRNA-seq分析的综述文章，包括 (Stegle, Teichmann, and Marioni 2015) 目前，也有不同的平台执行上述流程图的一步或多个步骤，包括: Falco 云端单细胞RNA-seq处理框架 SCONE (Single-Cell Overview of Normalized Expression), 单细胞RNA-seq数据质量控制和标准化的包. Seurat 用于单细胞RNA-seq数据质量控制，分析和数据探索的R包. ASAP (Automated Single-cell Analysis Pipeline) 是一个单细胞分析交互式webserver. Bioconductor 是一个分析高通量基因组数据开源，开放式软件项目，包括分析单细胞数据的工具包。 2.5 挑战 scRNA-seq和bulk RNA-seq最大的不同在于每个测序文库是单个细胞，而不是一群细胞。因此需要各位注意来自不同细胞（测序文库）的结果的比较。文库之间差异的主要来源是: 扩增偏好性和扩增效率 （高达1,000,000倍） 基因的’dropout’，其中一个基因在一个细胞中等表达水平，但在另外一个细胞没有检测到(Kharchenko, Silberstein, and Scadden 2014). 在两种情况下， 由于RNA仅来自一个细胞，因此低起始量的转录本是导致差异的主要原因。提高转录本捕获效率和减少扩增偏差是目前活跃的研究灵越。从后续的课程我们也可以看到，可以通过适当的标准化和校正方法来缓解这些问题。 2.6 实验方法 Figure 2.3: 单细胞转录组学摩尔定律 (图片来自 Svensson et al) 开发新的scRNA-seq方法和protocol是目前非常活跃的一个研究领域，在过去的几年中已经发表了一些protocol，不完全列表如下: CEL-seq (Hashimshony et al. 2012) CEL-seq2 (Hashimshony et al. 2016) Drop-seq (Macosko et al. 2015) InDrop-seq (Klein et al. 2015) MARS-seq (Jaitin et al. 2014) SCRB-seq (Soumillon et al. 2014) Seq-well (Gierahn et al. 2017) Smart-seq (Picelli et al. 2014) Smart-seq2 (Picelli et al. 2014) SMARTer STRT-seq (Islam et al. 2013) 这些方法可以按照不同方法进行归类，最重要的两个方面是定量和捕获 定量有两种类型，全长和基于标签。前者试图达到每个转录本均匀覆盖率；然而基于tag的protocol只捕获每个RNA的5’或3’端。量化方法的选择对于数据可用于何种类型的分析具有重要意义。理论上讲，基于全长的protocol可以对整个转录本进行均匀测序，然而通常测序覆盖有偏差。基于tag的protocol主要优势是其可以和唯一的分子标识符结合使用，提高定量准确性(see chapter ??)。另一方面，测序限制在转录组的一端，降低比对map率，并难以区分不同的异构体(Archer et al. 2016)。 捕获的策略决定了通量，细胞如何被选择以及除测序外还可以获得哪种附加信息。三种常用的方法是基于微孔(microwell)-，微流体(microfluidic)-，液滴(droplet)-的方法。 Figure 2.4: 微孔板 (图片来自wiki) 对于基于微孔的平台，使用例如移液管或激光捕获分离细胞并置于微流体孔中。 基于微孔的方法的一个优点是它们可以与荧光激活细胞分选（FACS）结合，基于表面标记物分选细胞。 因此，当想要分离特定细胞群体用于测序时，该策略非常有用。 另一个优点是可以拍摄细胞的照片。 该图像提供了额外的细胞形态，适用于识别包含受损细胞或双份细胞的微孔。 这些方法的主要缺点是它们通常是通量低并且每个单细胞所需的工作量可能相当大。 Figure 2.5: 96孔Fluidigm C1芯片 (图片来自Fluidigm) 微流体平台, 比如 Fluidigm’s C1, 提供了更加集成的系统，用于捕获细胞和进行文库制备所需的过程。 因此，它们提供比基于微孔的平台更高的通量。 通常，在微流体平台中仅捕获约10％的细胞，因此不适合处理稀有细胞类型或非常少量的细胞。 此外，芯片相对昂贵，但由于反应可以以较小的体积进行，因此可以节省试剂。 Figure 2.6: drop-seq方法的原理图 (图片来自Macosko et al) 基于液滴的方法将每个单独的细胞与包括建库所需酶的珠子(bead)一起封装在纳升液滴内。每个珠子都包含唯一的条形码(barcode)，加到所有来自该细胞的序列上。因此可以合并所有液滴进行测序，再基于barcode将序列分配给不同的细胞。Droplet平台通常具有最高的通量，因为建库准备成本约为\\(.05\\) 美元/细胞。相反，测序成本成为其限制因素，通常实验覆盖率低，仅检测到几千个转录本 (Ziegenhain et al. 2017)。 2.7 如何选择合适的平台 最合适的平台取决于手头的生物学问题。 例如，如果研究组织的组成，那么将允许捕获非常大量细胞的基于液滴的方法可能是最合适的。 另一方面，如果人们对具有已知表面标记物的稀有细胞类群感兴趣，那么最好使用FACS进行富集，然后对较少数量的细胞进行测序。 显然，如果研究不同的异构体，那么全长转录物定量将更合适。相比之下，UMI只能与基于tag的protocol一起使用，促进基因水平的量化。 来自Enard group (Ziegenhain et al. 2017)和Teichmann group (Svensson et al. 2017)最近两项研究比较了几种不同的protocol。Ziegenhain等人在同一小鼠胚胎干细胞样本（mESCs）上比较了五种不同的protocol。通过控制细胞数量和测序深度，作者能够直接比较不同protocol的灵敏度，噪声水平和成本。 他们的结论的一个例子如下图所示，不同protocol检测的基因数量（对于给定的检测阈值）差别很大。drop-seq和Smart-seq2之间几乎有两倍的差异，这表明protocol的选择会对研究有重大影响。 Figure 2.7: Enard group 研究 Svensson等采用了另外一种方法，通过使用已知浓度的合成转录本（spike-ins，后面详细介绍）来测量不同protocol的准确性和灵敏度。通过广泛的比较研究，他们同样发现不同protocol间区别较大。 Figure 2.8: Teichmann group 研究 随着实验技术的发展和用于量化技术噪声的计算方法的改进，后续研究有助于我们进一步了解不同方法的优缺点。因为基准测试可以确定哪些策略是最有用的，这些比较研究不仅有助于研究人员决定使用哪种protocol，而且有助于开发新方法。 References "],
["processing-raw-scrna-seq-data.html", "3 scRNA-seq原始数据处理 3.1 FastQC 3.2 移除接头和低质量碱基 3.3 文件格式 3.4 测序文库拆分 3.5 使用STAR比对read 3.6 Kallisto和Pseudo-Alignment", " 3 scRNA-seq原始数据处理 3.1 FastQC 获得单细胞RNA-seq数据后，首先要做的就是检查测序质量，我们使用FastQC来完成此任务。 FastQC是用于测序数据的质量控制工具，既可以用于bulk RNA-seq，也可以用于scRNA-seq。 FastQC将测序数据作为输入，并返回测序质量的报告。访问以下链接获取更多关于FastQC的信息： https://www.bioinformatics.babraham.ac.uk/projects/fastqc/ 该网站包含下载和安装FastQC的链接以及生成报告的文档。幸运的是，我们已经为您安装了FastQC1，因此这里我们将查看文档。将网页向下滚动到“示例报告”，然后单击“Good Illumina Data”。 这里给出了高质量Illumina测序数据立项报告的示例。 现在让我们自己生成一份FastQC报告。 今天，我们将使用(Kolodziejczyk et al. 2015)生成的mESC单细胞数据集进行分析。细胞使用SMART-seq2 protocol构建测序文库并进行双端测序。这些文件位于Share文件夹中。 注意 本课程的当前文本是为参加我们课程的人员编写的。您必须下载文件（ERR522959_1.fastq和ERR522959_2.fastq）并创建Share目录才能运行命令。你可以在这里找到这些文件： https://www.ebi.ac.uk/arrayexpress/experiments/E-MTAB-2600/samples/ 现在让我们来看看文件: less Share/ERR522959_1.fastq less Share/ERR522959_2.fastq 任务1: 尝试找出生成FastQC报告的命令，提示: 尝试执行 fastqc -h 该命令将告诉您可以传递给FastQC的参数。如果您遇到困难，请随时寻求帮助！ 如果运行成功，则应为正向和反向reads 都会生成.zip和.html文件。运行成功后，请跳到下一节。 3.1.1 解决方案并下载报告 如果还没有成功，请使用以下命令生成FastQC报告： mkdir fastqc_results fastqc -o fastqc_results Share/ERR522959_1.fastq Share/ERR522959_2.fastq 一旦命令执行完毕，您应该总共有四个文件 - 每个read对应一个zip和html文件，报告位于html文件中。 要查看它，我们需要使用filezilla或scp将它从AWS下载到您的计算机上。 下载到本地后，单击打开您的FastQC报告。记得要查看正向和反向read的质量报告！测序的质量如何？有什么我们应该关注的问题吗？ 我们如何解决这些问题呢？ 3.2 移除接头和低质量碱基 Trim Galore是一个cutadapt的封装，用于移除测序接头序列和测序末端的低质量碱基。 鉴于FastQC报告中存在一些接头污染，最好从数据中移除接头序列。 任务2：数据中使用了哪种类型的接头序列？提示：查看FastQC报告“Adapter Contern”图。 现在让我们使用Trim Galore移除那些有问题的接头序列，修剪后再次检查读取质量，使用FastQC生成另一个报告。 任务3：找出移除adapter的命令。提示1：您可以使用 trim_galore -h 查看Trim Galore的参数描述。 提示2：仔细阅读上述命令的输出。本实验中使用的接头序列非常常见。您是否需要知道接头的实际序列才能将其删除？ 任务4: 为清洗后的数据生成FastQC报告。接头序列污染消失了吗？ 一旦您认为您已成功去除接头序列并通过FastQC确认，请使用下一部分核验您的结果。 3.2.1 Solution 您可以使用以下命令去除Nextera测序接头序列： mkdir fastqc_trimmed_results trim_galore --nextera -o fastqc_trimmed_results Share/ERR522959_1.fastq Share/ERR522959_2.fastq 请记住为清洗后的数据文件重新生成FastQC报告！FastQC现在应该显示’Adaptor Content’为’pass’了。 祝贺您现在已生成测序质量报告并移除接头序列。在下一步中，我们将使用STAR和Kallisto将清洗后的reads比对到参考转录组上。 3.3 文件格式 3.3.1 FastQ FastQ是scRNA-seq数据中最原始数据格式。所有scRNA-seq protocol都使用双端测序，根据使用的protocol，条形码序列(barcode)可能出现在paired-reads中一条或两条上。但是使用唯一分子标识符(UMIs) 的protocol会生成包含细胞和UMI条形码加上接头序列但是没有转录本序列的read。因此虽然是双端测序，但比对时按照单端测序对待。 FastQ文件格式如下: &gt;ReadID READ SEQUENCE + SEQUENCING QUALITY SCORES 3.3.2 BAM BAM文件以标准且高效的方式存储比对结果。SAM文件为直接可读的，而BAM文件是高度压缩的版本。BAM / SAM文件包含头部信息，通常包括样本制备，测序和比对的信息;后面为每个read的比对结果，以tab作为分隔符。 比对行标准格式如下: QNAME : read名称(如果为UMI文库，则包括UMI条形码) FLAG : 数字指示reads比对的类型, link该网站有所有可能的类型 RNAME : 参考序列名称 (比如比对到的染色体名称). POS : 最左边比对位置 MAPQ : 比对质量 CIGAR : 表示reads中匹配/不匹配部分 (可能包括soft-clipping). RNEXT : mate/next reads比对到的参考序列名称 PNEXT : mate/next reads比对到的第一个碱基位置 TLEN : 模板长度（read比对到的参考区域的长度） SEQ : read序列 QUAL : read质量 BAM/SAM 文件可通过’samtools’互相转换: samtools view -S -b file.sam &gt; file.bam samtools view -h file.bam &gt; file.sam 一些测序设备会自动将测序reads比对到标准基因组上，并提供BAM或CRAM格式文件。通常基因组中不包含ERCC序列，因此不会又ERCCs reads比对到在BAM / CRAM文件中。 要量化ERCC（或任何其他遗传变异），或者如果您只想使用不同于标准流程的比对算法（通常过时），那么您将需要将BAM / CRAM文件转换回FastQs: BAM文件可以使用bedtools转为FastQ。为避免比对到多个基因组位置的一个read转换为FastQ多条read，首先将BAM文件按读取名称排序，并使用samtools删除次级比对。Picard也包含将BAM转换为FastQ文件的方法。 # sort reads by name samtools sort -n original.bam -o sorted_by_name.bam # remove secondary alignments samtools view -b -F 256 sorted_by_name.bam -o primary_alignment_only.bam # convert to fastq bedtools bamtofastq -i primary_alignment_only.bam -fq read1.fq -fq2 read2.fq 3.3.3 CRAM CRAM文件类似SAM文件，其头部信息包括比对使用的参考基因组信息，这使得read中和参考基因组一样的碱基可以进一步压缩。与BAM相比，CRAM还支持有损数据压缩方法以进一步优化存储。CRAM主要由Sanger/EBI测序机构使用。 CRAM和BAM文件可以使用最新版本的samtools（&gt; = v1.0）进行格式转换。但是，这种转换可能需要将参考基因组下载到缓存中。 或者，您可以从CRAM文件的头部元数据预先下载参考基因组，或者询问生成CRAM文件的人获得参考基因组，并使用’-T’指定该文件。因此我们建议在执行此操作之前设置特定的缓存位置： export REF_CACHE=/path_to/cache_directory_for_reference_genome samtools view -b -h -T reference_genome.fasta file.cram -o file.bam samtools view -C -h -T reference_genome.fasta file.bam -o file.cram 3.3.4 手动查看文件 有时，手动检查文件可能很有用，例如检查文件的头部信息。’less’和’more’可在命令行查看任何文本文件。管道符|可以在多个命令之间传输数据，省却把中间数据存储多个拷贝的过程。 less file.txt more file.txt # counts the number of lines in file.txt wc -l file.txt samtools view -h file.[cram/bam] | more # counts the number of lines in the samtools output samtools view -h file.[cram/bam] | wc -l 练习 现提供cram示例文件: EXAMPLE.cram 任务1: 这个文件是怎么生成的？使用了什么软件？参考基因组时什么？(提示: 检查头部信息) 任务2: 有多少reads比对上/没有比对上？总共有多少reads？secondary alignments有多少? (提示: 使用FLAG) 任务3: 将CRAM转为Fastq文件。转换后的read只有一个拷贝吗？(将转换后的Fastq文件命名为“10cells_read1.fastq” “10cells_read2.fastq”) 如果您遇到问题，可以通过输入命令来显示每个软件的帮助信息 - 例如 ‘samtools view’，‘bedtools’ 答案 samtools view -T data/2000_reference.transcripts.fa -H data/EXAMPLE.cram | more samtools view -T data/2000_reference.transcripts.fa -f 4 data/EXAMPLE.cram | wc -l # unmapped samtools view -T data/2000_reference.transcripts.fa -F 260 data/EXAMPLE.cram | wc -l # mapped samtools view -T data/2000_reference.transcripts.fa -F 256 data/EXAMPLE.cram | wc -l # total samtools view -T data/2000_reference.transcripts.fa -f 256 data/EXAMPLE.cram | wc -l # secondary alignments samtools view -b -h -T data/2000_reference.transcripts.fa data/EXAMPLE.cram -o data/EXAMPLE.bam samtools sort -n data/EXAMPLE.bam -o data/sorted_EXAMPLE.bam samtools view -b -F 256 data/sorted_EXAMPLE.bam -o data/primary_EXAMPLE.bam # convert to fastq bedtools bamtofastq -i data/primary_EXAMPLE.bam -fq data/10cells_read1.fq -fq2 data/10cells_read2.fq 3.3.5 Genome (FASTA, GTF) 为了比对序列，需要参考基因组和基因组注释文件(GTF或者GFF格式)。模式生物的基因组和注释文件可以从目前主流的基因组数据库下载: Ensembl, NCBI, 或者 UCSC Genome Browser. GTF文件包括基因，转录本和外显子的注释，格式如下： (1) seqname : 染色体/scaffold编号 (2) source : 注释来源 (3) feature : 注释信息类型(比如基因，转录本，外显子) (4) start : 起始位置 (bp) (5) end : 终止 (bp) (6) score : 得分 (7) strand : + (正链) or - (负链) (8) frame : 仅对CDS有效，起始编码位置，或者到达下一个密码子需要跳过的碱基个数 (0 = first base, 1 = second base, etc..) (9) attribute : ;分割的键值对来显示其它信息 (比如 names/IDs, biotype) 空字段用“.”填充 根据我们的经验，Ensembl是最容易使用的，并且具有最大的注释集。NCBI往往更严格，仅包括置信度高的基因注释。 而UCSC包含多个使用不同标准的基因组注释。 如果您的实验系统包含非标准序列，则必须将这些序列添加到基因组fasta和gtf中来定量它们的表达。 最常见的是针对ERCC spike-ins，CRISPR相关的序列或其他过表达/报告载体。 为了获得最大的可用性/灵活性，我们建议为添加的任何非标准序列创建完整和详细的fasta序列和gtf序列。 目前没有标准化的方法来做到这一点 以下是我们的自定义perl脚本，用于为ERCC创建一个gtf和fasta文件，可以将其附加到基因组中。如果要量化内含子读数时，您可能还需要更改gtf文件以处理内含子中的重复元素。任何脚本语言甚至“awk”或一些文本编辑器都可以用来相对有效地完成这项任务，但它们超出了本课程的范围。 # Converts the Annotation file from # https://www.thermofisher.com/order/catalog/product/4456740 to # gtf and fasta files that can be added to existing genome fasta &amp; gtf files. my @FASTAlines = (); my @GTFlines = (); open (my $ifh, &quot;ERCC_Controls_Annotation.txt&quot;) or die $!; &lt;$ifh&gt;; #header while (&lt;$ifh&gt;) { # Do all the important stuff chomp; my @record = split(/\\t/); my $sequence = $record[4]; $sequence =~ s/\\s+//g; # get rid of any preceeding/tailing white space $sequence = $sequence.&quot;NNNN&quot;; my $name = $record[0]; my $genbank = $record[1]; push(@FASTAlines, &quot;&gt;$name\\n$sequence\\n&quot;); # is GTF 1 indexed or 0 indexed? -&gt; it is 1 indexed # + or - strand? push(@GTFlines, &quot;$name\\tERCC\\tgene\\t1\\t&quot;.(length($sequence)-2).&quot;\\t.\\t+\\t.\\tgene_id \\&quot;$name-$genbank\\&quot;; transcript_id \\&quot;$name-$genbank\\&quot;; exon_number \\&quot;1\\&quot;; gene_name \\&quot;ERCC $name-$genbank\\&quot;\\n&quot;); push(@GTFlines, &quot;$name\\tERCC\\ttranscript\\t1\\t&quot;.(length($sequence)-2).&quot;\\t.\\t+\\t.\\tgene_id \\&quot;$name-$genbank\\&quot;; transcript_id \\&quot;$name-$genbank\\&quot;; exon_number \\&quot;1\\&quot;; gene_name \\&quot;ERCC $name-$genbank\\&quot;\\n&quot;); push(@GTFlines, &quot;$name\\tERCC\\texon\\t1\\t&quot;.(length($sequence)-2).&quot;\\t.\\t+\\t.\\tgene_id \\&quot;$name-$genbank\\&quot;; transcript_id \\&quot;$name-$genbank\\&quot;; exon_number \\&quot;1\\&quot;; gene_name \\&quot;ERCC $name-$genbank\\&quot;\\n&quot;); } close($ifh); # Write output open(my $ofh, &quot;&gt;&quot;, &quot;ERCC_Controls.fa&quot;) or die $!; foreach my $line (@FASTAlines) { print $ofh $line; } close ($ofh); open($ofh, &quot;&gt;&quot;, &quot;ERCC_Controls.gtf&quot;) or die $!; foreach my $line (@GTFlines) { print $ofh $line; } close ($ofh); 3.4 测序文库拆分 文库拆分根据Protocol不同或构建的流程不同需要有对应的处理方式。我们所知道的最灵活的文库拆分工具是zUMIs，可用于拆分和比对大多数基于UMI的protocol。对于Smartseq2或其他全长转录本双端测序protocol，数据通常已经被拆分好。诸如GEO或ArrayExpress之类的公共存储库需要在上传之前对基于小规模/基于板的scRNASeq数据拆分，并且许多测序公司在数据返回给您之前自动拆分数据。如果您没有使用已发表的流程，并且数据未被测序公司拆分，则您必须自己对其进行文库拆分。因为不同的建库方案引入的barcode序列的长度和位置不同，通常都需要自己写脚本解决。 对于所有数据类型，文库拆分涉及从一端或双端短序列中识别并移除细胞条形码序列(cell-barcode)。如果提前知道加入的cell-barcodes，比如数据来自基于PCR板的protocol，需要将每个cell-barcode与预期的cell-barcode进行比对，并将其归类于最相近的cell-barcode(根据cell-barcode的设计，一般允许最多1-2错配)。这些数据通常在比对之前进行拆分，从而可以并行比对。 我们提供公开可用perl脚本，可以拆分任何有或没有UMI 的plate-based的建库方案生成的数据，用法如下： perl utils/1_Flexible_UMI_Demultiplexing.pl data/10cells_read1.fq data/10cells_read2.fq &quot;C12U8&quot; data/10cells_barcodes.txt 2 Ex Barcode Structure: 12 bp CellID followed by 8 bp UMI Doesn&#39;t match any cell: 0 Ambiguous: 0 Exact Matches: 400 Contain mismatches: 0 Input Reads: 400 Output Reads: 400 perl utils/1_Flexible_FullTranscript_Demultiplexing.pl data/10cells_read1.fq data/10cells_read2.fq &quot;start&quot; 12 data/10cells_barcodes.txt 2 Ex Doesn&#39;t match any cell: 0 Ambiguous: 0 Exact Matches: 400 Contain Mismatches: 0 Input Reads: 400 Output Reads: 400 对于包含UMI的数据，文库拆分包括将UMI code附加到包含基因区的序列read名字上。如果数据来自droplet-based protocol或SeqWell，其中预期条形码的数量远远高于预期的细胞数量，为避免生成才能大量的文件么cell-barcode也加到测序read的名字后面。在这些情况下，在量化步骤期间进行文库拆分，以便于识别来源于完整细胞而不是背景噪声的cell-barcode。 3.4.1 鉴定含有细胞的液滴/微孔 基于液滴的scRNA-seq方法，只有一部分液滴包含bead和一个完整的细胞。然而生物实验可能不理想，一些RNA会从死细胞/受伤细胞中泄露出去。因此，没有完整细胞的液滴可能捕获少量环境游离RNA，这些RNA将进入测序文库，出现在最终测序结果中。液滴大小，扩增效率和测序的变化将导致“背景”和真实细胞文库大小区别很大。目前已有很多方法用来区分对应真实细胞的cell-barcode 已经使用各种方法来试图区分对应于真实细胞的那些细胞条形码。 大多数方法使用每个barcode的总分子数（可以应用于总reads）并尝试寻找“break point”，区分来自真实细胞较大的文库和来自背景较小的文库。下面加载包含大小文库细胞的示例模拟数据： umi_per_barcode &lt;- read.table(&quot;data/droplet_id_example_per_barcode.txt.gz&quot;) truth &lt;- read.delim(&quot;data/droplet_id_example_truth.gz&quot;, sep=&quot;,&quot;) 练习 多少唯一的barcode被检测到？ 数据中多少来自真实的细胞？ 为简化计算，去除所有少于10个分子的barcode。 答案 dim(umi_per_barcode)[1] dim(truth)[1] 一种方法是寻找每个条形码对应总分子突然下降的拐点。 One approach is to look for the inflection point where the total molecules per barcode suddenly drops: barcode_rank &lt;- rank(-umi_per_barcode[,2]) plot(barcode_rank, umi_per_barcode[,2], xlim=c(1,8000)) 可以看出文库大小近似指数分布，简单起见，对数据进行log转换。 log_lib_size &lt;- log10(umi_per_barcode[,2]) plot(barcode_rank, log_lib_size, xlim=c(1,8000)) 从上图可以看出，拐点更加明显了。我们可以手动估计拐点的位置，但是用算法估计更加精确，以及可重复。 # inflection point o &lt;- order(barcode_rank) log_lib_size &lt;- log_lib_size[o] barcode_rank &lt;- barcode_rank[o] rawdiff &lt;- diff(log_lib_size)/diff(barcode_rank) inflection &lt;- which(rawdiff == min(rawdiff[100:length(rawdiff)], na.rm=TRUE)) plot(barcode_rank, log_lib_size, xlim=c(1,8000)) abline(v=inflection, col=&quot;red&quot;, lwd=2) threshold &lt;- 10^log_lib_size[inflection] cells &lt;- umi_per_barcode[umi_per_barcode[,2] &gt; threshold,1] TPR &lt;- sum(cells %in% truth[,1])/length(cells) Recall &lt;- sum(cells %in% truth[,1])/length(truth[,1]) c(TPR, Recall) ## [1] 1.0000000 0.7831707 另外一种方法是构建混合模型，找出重叠区域的最高和最低分布。然而数据可能并不满足假定的分布。 set.seed(-92497) # mixture model require(&quot;mixtools&quot;) ## 载入需要的程辑包：mixtools ## mixtools package, version 1.1.0, Released 2017-03-10 ## This package is based upon work supported by the National Science Foundation under Grant No. SES-0518772. mix &lt;- normalmixEM(log_lib_size) ## number of iterations= 43 plot(mix, which=2, xlab2=&quot;log(mol per cell)&quot;) p1 &lt;- dnorm(log_lib_size, mean=mix$mu[1], sd=mix$sigma[1]) p2 &lt;- dnorm(log_lib_size, mean=mix$mu[2], sd=mix$sigma[2]) if (mix$mu[1] &lt; mix$mu[2]) { split &lt;- min(log_lib_size[p2 &gt; p1]) } else { split &lt;- min(log_lib_size[p1 &gt; p2]) } 练习 使用分割点识别细胞并计算TPR和Recall 答案 cells &lt;- umi_per_barcode[umi_per_barcode[,2] &gt; 10^split,1] TPR &lt;- sum(cells %in% truth[,1])/length(cells) Recall &lt;- sum(cells %in% truth[,1])/length(truth[,1]) c(TPR, Recall) 第三种方法，CellRanger假设真实细胞文库大小变化范围在10倍以内，然后用哪个期望的细胞数目估计区间的分布。 n_cells &lt;- length(truth[,1]) # CellRanger totals &lt;- umi_per_barcode[,2] totals &lt;- sort(totals, decreasing = TRUE) # 99th percentile of top n_cells divided by 10 thresh = totals[round(0.01*n_cells)]/10 plot(totals, xlim=c(1,8000)) abline(h=thresh, col=&quot;red&quot;, lwd=2) 练习 用该阈值识别细胞并计算TPR和Recall。 答案 cells &lt;- umi_per_barcode[umi_per_barcode[,2] &gt; thresh,1] TPR &lt;- sum(cells %in% truth[,1])/length(cells) Recall &lt;- sum(cells %in% truth[,1])/length(truth[,1]) c(TPR, Recall) 最后EmptyDrops，目前处于Beta测试阶段，其实用所有液滴的基因 × 细胞分子计数矩阵，从具有极低counts的液滴估计背景RNA的分布，然后寻找与背景基因表达模式不同的细胞。背景RNA通常和群体中大部分细胞的表达模式相似，该方法与拐点方法相结合。因此，EmptyDrops是唯一能够识别高度多样化样本中鉴定小群体细胞条形码的方法。 下面提供了该方法的运行代码：（我们会根据官方发布及时更新代码） require(&quot;Matrix&quot;) raw.counts &lt;- readRDS(&quot;data/droplet_id_example.rds&quot;) require(&quot;DropletUtils&quot;) # emptyDrops set.seed(100) e.out &lt;- emptyDrops(my.counts) is.cell &lt;- e.out$FDR &lt;= 0.01 sum(is.cell, na.rm=TRUE) plot(e.out$Total, -e.out$LogProb, col=ifelse(is.cell, &quot;red&quot;, &quot;black&quot;), xlab=&quot;Total UMI count&quot;, ylab=&quot;-Log Probability&quot;) cells &lt;- colnames(raw.counts)[is.cell] TPR &lt;- sum(cells %in% truth[,1])/length(cells) Recall &lt;- sum(cells %in% truth[,1])/length(truth[,1]) c(TPR, Recall) 3.5 使用STAR比对read 现在我们已经对测序数据进行质控，并且获得了高质量的清洗后数据，下一步将其比对到参考基因组上。如果我们想要定量基因表达或筛选样品间差异表达的基因，则通常需要某种形式的比对。 短序列比对的工具有很多，目前我们主要关注两个。第一个工具是STAR (???)，对于测序数据中的每一个read，STAR尝试寻找参考基因组中一个或多个最长可能序列。例如，下图所示，read(蓝色)跨越两个外显子和一个可变剪切位点(紫色)。STAR能够找出read的第一部分和序列的第一个外显子仙童，同时第二部分和序列的第二个外显子相同。因为STAR可能够以这种方式识别剪切事件，又被称为“spice aware alinger”。 Figure 3.1: STAR比对示意图, 来自Dobin et al. 通常，STAR将reads比对到参考基因组是允许其检测新的剪接事件或染色体重排。然而，STAR的一个问题是它需要大量的内存，特别是当参考基因组很大（例如，小鼠和人类）。为了加速我们今天的分析，我们将使用STAR将reads与只包含2000个转录本的参考转录组进行比对。请注意，这不是正常或推荐的做法，我们只是出于时间原因这样做。我们建议比对到参考基因组。 STAR对齐需要两个步骤。第一步，用户向STAR提供参考基因组序列（FASTA）和注释文件（GTF），STAR用它来创建基因组索引。 第二步，STAR将用户的reads比对到基因组索引。 首先现在创建索引。请记住，由于时间的原因，我们比对到转录组而不是基因组，这意味着我们只需要向STAR提供比对的转录本序列。可以从Ensembl获取许多模式生物的转录组数据。 任务 1: 执行以下命令创建索引: mkdir indices mkdir indices/STAR STAR --runThreadN 4 --runMode genomeGenerate --genomeDir indices/STAR --genomeFastaFiles Share/2000_reference.transcripts.fa 任务 2: STAR用到的每个参数意义? 提示: 参考STAR帮助文档 任务 3: 如果比对到基因组而不是转录组，命令是什么？ 现在索引创建完成，进行比对步骤。 任务 4: 尝试找出应该使用什么命令将我们的清洗后的数据（从ERR522959）比对索引上。参考使用STAR手册， 您认为知道答案，检查它是否与下一节中的解决方案匹配并执行比对。 任务 5: 尝试了解比对结果文件。 3.5.1 STAR比对命令 使用以下命令完成比对: mkdir results mkdir results/STAR STAR --runThreadN 4 --genomeDir indices/STAR --readFilesIn Share/ERR522959_1.fastq Share/ERR522959_2.fastq --outFileNamePrefix results/STAR/ 3.6 Kallisto和Pseudo-Alignment STAR是read比对工具，而Kallisto是伪比对工具(Bray et al. 2016)。它们的主要区别是aligner比对到参考基因组或转录组上，而pseudo-aligner将k-mers比对到参考基因组或转录组上。 3.6.1 k-mer是什么? k-mer是来自reads长度为k的序列。例如，假设read为ATCCCGGGTTAT，从中制作7-mer。为此，提取read的前七个碱基找到第一个7-mer。然后向下移动一个碱基得到第二个7-mer，然后计算接下来的七个碱基。图2显示了可以从read得到的所有7-mers： Figure 3.2: 示例read产生7-mer 3.6.2 为什么比对k-mer而不是reads? 主要有两个原因： psudi-aligners使用计算技巧使得比对k-mers比传统比对reads要快，具体细节参考(Bray et al., 2017) 在一些情况下，pseudo-aligners比对传统的比对工具更好地处理测序错误。比如，假设序列的第一个碱基存在测序错误，实际为T但是测序为A，这会影响pseduo-aligners比对第一个7-mer，而不影响后面7-mers的比对。 3.6.3 Kallisto伪比对模式 Kallisto有一个为scRNA-seq实验特别设计的伪比对模式。与STAR不同的是，Kallisto比对到参考转录组而不是参考基因组。 这意味着Kallisto将reads比对到剪接异构体而不是基因，然而对scRNA-seq而言，这很有挑战性： 由于以下原因，对单细胞RNA-seq特异性地将读数映射到同种型而不是基因： scRNA-seq覆盖率比bulk RNA-seq低，意味着从reads获得的信息减少。 许多scRNA-seq protocol 在3’端覆盖存在偏差，意味着如果两个异构体只在5’端不同，则很难确定read来自哪个异构体。 一些scRNA-seq protocol测序读段较短，难以区分read来自哪个异构体。 Kallisto的pseudo mode和pseudo alignment略有不同。Kallisto不与异构体比对，而是与等价类(equivalence classes)比对。如果read比对到多个异构体上，Kallisto会记录read比对到包含有所有异构体的等价类，因此可以使用等价类计数而非基因或转录本计数用于下游的聚类等分析。具体见下图： Figure 3.3: Kallisto等价类示意图, 来自 https://pachterlab.github.io/kallisto/singlecell.html. 今天我们只用1个细胞进行pseudo-alignment, 但是Kallisto可以同时对大量细胞进行pseudo-alignment以及使用UMI信息，具体参看官方文档 类似STAR，pseudo-alignment之前需要用Kallisto生成索引。 任务 6: 使用以下命令构建Kallisto索引, 使用官方手册理解每个参数的意义 mkdir indices/Kallisto kallisto index -i indices/Kallisto/transcripts.idx Share/2000_reference.transcripts.fa 任务 7: 使用Kallisto手册找出运行pseudo-alignment的命令，如果您认为知道答案，可以去下一节核验并运行pseudo-alignment。 3.6.4 Kallisto Pseudo-Alignment命令 使用以下命令执行pseudo-alignment mkdir results/Kallisto kallisto pseudo -i indices/Kallisto/transcripts.idx -o results/Kallisto -b batch.txt 参考官方手册构建batch.txt。 3.6.5 理解Kallisto输出结果 上述命令会生成4个文件 - matrix.cells, matrix.ec, matrix.tsv and run_info.json. matrix.cells 细胞ID列表. 因为我们只使用一个细胞，该文件应该只包含“ERR522959” matrix.ec 等价类信息。每一行的第一个数字为等价类ID，第二个数字对应等价类的转录本ID。比如，“10 1,2,3”表示等价类10包括3个转录本，分别是1,2,3. ID顺序对应转录本在参考转录本的顺序。采用0-base技术，转录本ID为1,2,3分别对应2000_reference.transcripts.fa中第2,3,4个转录本。 matrix.tsv 每个等价类在不同cell的read count信息。第一个数字为等价类ID，如matrix.ec一样。第二个数字为cell ID，和matrix.cells文件中细胞名字对应。第三个数字等价类在该细胞的reads count。比如，“5 1 3”表示来自细胞1的3个reads比对到等价类5上。这里的细胞ID同样是0-based，所以细胞1对应matrix.cells的第二行。 Note that zero indexing is used, so cell 1 corresponds to the second line of matrix.cells. run_info.json Kallisto执行信息，一般可忽略。 References "],
["construction-of-expression-matrix.html", "4 构建表达矩阵 4.1 质量控制 4.2 Reads 比对 4.3 比对示例 4.4 Mapping QC 4.5 Reads定量 4.6 唯一分子标识符", " 4 构建表达矩阵 很多scRNA-seq数据分析从表达矩为开始。 一般来说，表达矩阵的每一行代表一个基因，每列代表一个细胞（但是一些作者会使用转置）。 每个条目代表特定基因在特定细胞的表达水平。表达量的单位取决于protocol和标准化方法。 4.1 质量控制 scRNA-seq实验测序结果是大量的cDNA reads。第一步是确保测序的高质量，可以使用以下标准工具执行质量控制，例如 FastQC 或 Kraken. 假设有experiment.bam文件,运行以下FASTQC命令 $&lt;path_to_fastQC&gt;/fastQC experiment.bam 下面是125 bp reads数据集的FastQC输出结果示例。下图显示了由于技术错误导致在read中心无法正确测序几个碱基。 但是，由于read的其余部分质量很高，因此该错误很可能对比对效率的影响可以忽略不计。 Figure 4.1: Example of FastQC output 另外，使用Integrative Genomics Browser (IGV)或者SeqMonk对数据进行可视化非常有帮助。 4.2 Reads 比对 将reads低质量碱基取出后，把剩下的序列比对到参考基因组上。同样，没有专门为scRNA-seq设计的比对方法。我们可以使用STAR或者TopHat进行比对。对来自有丰富注释信息模式生物(比如小鼠和人)的大型全长转录本数据集，pseudo-alignment方法(比如Kallisto，Salmon)可能比传统比对方法表现更好。基于drop-seq数据集包含数十万reads，pseudoaligners运行时间比传统比对工具快不止一个量级。 使用STAR比对示例 $&lt;path_to_STAR&gt;/STAR --runThreadN 1 --runMode alignReads --readFilesIn reads1.fq.gz reads2.fq.gz --readFilesCommand zcat --genomeDir &lt;path&gt; --parametersFiles FileOfMoreParameters.txt --outFileNamePrefix &lt;outpath&gt;/output 注意, 如果使用了spike-ins, 在比对前应将spike-ins的DNA序列添加到参考基因组序列中. 注意, 当使用UMIs，应该从read序列中取出条形码序列。通常做法是将barcode加到read名称上。 一旦将每个细胞的reads比对到参考基因组，我们需要确保每个细胞有足够数量的read比对到参考基因组。 根据我们的经验，小鼠或人类细胞的reads的map率为60-70％。但是此结果可能会因protocols，read长度和read比对工具参数而异。一般来说，我们希望所有细胞都具有相似的map率，因此应检查并可能删除任何异常值，map率低通常表示污染。 使用Salmon定量基因表达： $&lt;path_to_Salmon&gt;/salmon quant -i salmon_transcript_index -1 reads1.fq.gz -2 reads2.fq.gz -p #threads -l A -g genome.gtf --seqBias --gcBias --posBias 注意：Salmon或得到估计read counts和估计transcripts per million(tpm), TMP对scRNA-seq长基因的表达进行了过度校正，因此我们建议使用read counts。 4.3 比对示例 下列直方图显示scRNA-seq实验每个细胞比对reads总数。每个条形代表一个细胞，按照每个细胞的总reads数升序排列。三个红色箭头表示比对覆盖率降低的异常细胞，应该在后续分析中将其去除。黄色箭头表示unmapped reads较多的细胞。在比对质控步骤我们保留这两个细胞，但是在细胞质控时由于高的核糖体RNA reads比例将其移除。 Figure 4.2: Example of the total number of reads mapped to each cell. 4.4 Mapping QC 将原始测序数据比对到基因组后，需要评估比对的质量。目前有很多方法对比对质量进行评估，包括：rRNA/tRNAs reads数目，uniquely mapping reads比例，跨剪切位点的reads数，转录本read深度。为bulk RNA-seq开发的方法，比如RSeQC也适合单细胞数据： python &lt;RSeQCpath&gt;/geneBody_coverage.py -i input.bam -r genome.bed -o output.txt python &lt;RSeQCpath&gt;/bam_stat.py -i input.bam -r genome.bed -o output.txt python &lt;RSeQCpath&gt;/split_bam.py -i input.bam -r rRNAmask.bed -o output.txt 然而预期结果依赖于实验protocol，比如很多scRNA-seq方法是用poly-A富集来排除rRNA，但导致read覆盖率具有3’偏好性，即基因的3’区域更容易被检测到。下图展示了测序reads的3’偏好性，以及3个从数据集中移除的异常细胞。 Figure 4.3: Example of the 3’ bias in the read coverage. 4.5 Reads定量 下一步是定量每个细胞的基因表达水平。对于mRNA数据，可以使用针对bulk RNA-seq开发的工具，比如HT-seq 或者FeatureCounts # include multimapping &lt;featureCounts_path&gt;/featureCounts -O -M -Q 30 -p -a genome.gtf -o outputfile input.bam # exclude multimapping &lt;featureCounts_path&gt;/featureCounts -Q 30 -p -a genome.gtf -o outputfile input.bam Unique molecular identifiers (UMIs) 使得计算分子的绝对数目成为可能，并且在scRNA-seq非常受欢迎。下一章将讨论如何处理UMIs。 4.6 唯一分子标识符 感谢来 EMBL Monterotondo的Andreas Buness在本节的合作。 4.6.1 UMI介绍 UMI是在反转录过程中添加到转录本中的短（4-10bp）随机条形码序列。它们使测序read能够对应到单个转录物，从而去除scRNA-Seq数据扩增噪声和偏差。 Figure 4.4: UMI sequencing protocol 当对包含UMI数据测序时，仅对包含UMI的转录本末端进行测序（通常是3’末端） 4.6.2 比对条形码序列 由于条形码数量(\\(4^N\\),\\(N\\)为UMI的长度)比细胞中RNA分子(~\\(10^6\\))数目多，每个barcode通常会连接多个转录本。因此需要barcode和转录本比对位置来鉴定转录本分子。第一步比对UMI reads，推荐使用STAR，因为其运行速度快并且输出高质量BAM比对。此外，比对位置对鉴定转录本新的3’UTR很有帮助。 UMI-sequencing typically consists of paired-end reads where one read from each pair captures the cell and UMI barcodes while the other read consists of exonic sequence from the transcript (Figure 4.5). Note that trimming and/or filtering to remove reads containing poly-A sequence is recommended to avoid erors due to these read mapping to genes/transcripts with internal poly-A/poly-T sequences. After processing the reads from a UMI experiment, the following conventions are often used: The UMI is added to the read name of the other paired read. Reads are sorted into separate files by cell barcode For extremely large, shallow datasets, the cell barcode may be added to the read name as well to reduce the number of files. Figure 4.5: UMI sequencing reads, red lightning bolts represent different fragmentation locations 4.6.3 Counting Barcodes In theory, every unique UMI-transcript pair should represent all reads originating from a single RNA molecule. However, in practice this is frequently not the case and the most common reasons are: Different UMI does not necessarily mean different molecule Due to PCR or sequencing errors, base-pair substitution events can result in new UMI sequences. Longer UMIs give more opportunity for errors to arise and based on estimates from cell barcodes we expect 7-10% of 10bp UMIs to contain at least one error. If not corrected for, this type of error will result in an overestimate of the number of transcripts. Different transcript does not necessarily mean different molecule Mapping errors and/or multimapping reads may result in some UMIs being assigned to the wrong gene/transcript. This type of error will also result in an overestimate of the number of transcripts. Same UMI does not necessarily mean same molecule Biases in UMI frequency and short UMIs can result in the same UMI being attached to different mRNA molecules from the same gene. Thus, the number of transcripts may be underestimated. Figure 4.6: Potential Errors in UMIs 4.6.4 Correcting for Errors How to best account for errors in UMIs remains an active area of research. The best approaches that we are aware of for resolving the issues mentioned above are: UMI-tools’ directional-adjacency method implements a procedure which considers both the number of mismatches and the relative frequency of similar UMIs to identify likely PCR/sequencing errors. Currently an open question. The problem may be mitigated by removing UMIs with few reads to support their association with a particular transcript, or by removing all multi-mapping reads. Simple saturation (aka “collision probability”) correction proposed by Grun, Kester and van Oudenaarden (2014) to estimate the true number of molecules \\(M\\): \\[M \\approx -N*log(1 - \\frac{n}{N})\\] where N = total number of unique UMI barcodes and n = number of observed barcodes. An important caveat of this method is that it assumes that all UMIs are equally frequent. In most cases this is incorrect, since there is often a bias related to the GC content. Figure 4.7: Per gene amplification rate Determining how to best process and use UMIs is currently an active area of research in the bioinformatics community. We are aware of several methods that have recently been developed, including: UMI-tools PoissonUMIs zUMIs dropEst 4.6.5 Downstream Analysis Current UMI platforms (DropSeq, InDrop, ICell8) exhibit low and highly variable capture efficiency as shown in the figure below. Figure 4.8: Variability in Capture Efficiency This variability can introduce strong biases and it needs to be considered in downstream analysis. Recent analyses often pool cells/genes together based on cell-type or biological pathway to increase the power. Robust statistical analyses of this data is still an open research question and it remains to be determined how to best adjust for biases. Exercise 1 We have provided you with UMI counts and read counts from induced pluripotent stem cells generated from three different individuals (Tung et al. 2017) (see: Chapter ?? for details of this dataset). umi_counts &lt;- read.table(&quot;data/tung/molecules.txt&quot;, sep = &quot;\\t&quot;) read_counts &lt;- read.table(&quot;data/tung/reads.txt&quot;, sep = &quot;\\t&quot;) Using this data: Plot the variability in capture efficiency Determine the amplification rate: average number of reads per UMI. References "],
["references.html", "5 References", " 5 References "]
]
