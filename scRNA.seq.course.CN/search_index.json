[
["index.html", "scRNA-seq数据分析 1 说在前面的话 1.1 关于本项目 1.2 视频 1.3 GitHub 1.4 Docker 镜像 1.5 手动安装 1.6 许可 1.7 准备知识 1.8 联系我们", " scRNA-seq数据分析 碱基吃柠檬 2019-07-04 1 说在前面的话 本项目是将github上经典的scRNA-seq分析教程进行汉化，源项目参见hemberg-lab/scRNA.seq.course 1.1 关于本项目 随着技术发展的日新月异，现在对单个细胞进行高通量测序(scRNA-seq)获得其全基因组的表达谱数据成为可能。scRNA-seq的主要优势是其单细胞水平的分辨率和基因组范围检测能力可以解决其他方法难以解决的问题，比如bulk RNA-seq和RT-qPCR。然而，为了分析scRNA-seq数据，需要新的方法，并且一些针对bulk RNA-seq实验开发的方法的潜在假设也不再适用。 在本课程中，我们将讨论使用scRNA-seq可以解决的一些问题以及可用的计算和统计方法。 本课程通过University of Cambridge的Bioinformatics training unit进行教学，但该页面的材料适用于任何有兴趣了解scRNA-seq数据计算分析的人。 本课程每年讲授两次，每次授课前材料都会更新。 计算工具的数量正在迅速增加，我们正在尽最大努力跟上最新进展。 本课程的主要限制之一是我们倾向使用在R中实现且运行速度相当快的工具。 此外，我们还承认某种程度上偏向于我们或我们的朋友和同事开发的方法。 1.2 视频 该视频于2017年11月录制，当时课程包含的章节少于当前版本。 最新课程的直播录制版见YouTube 1.3 GitHub https://github.com/hemberg-lab/scRNA.seq.course https://github.com/lemonbases/scRNA.seq.course.CN 1.4 Docker 镜像 本课程提供包含所有必须软件的Docker镜像，可通过运行Docker镜像重复本课程的结果。 1.4.1 运行镜像 首先确保您的系统上安装了Docker。如果没有，请参照以下说明进行安装。运行本课程的Docker镜像(使用最新版而不是v3.13)。 docker run -p 8888:8888 -e PASSWORD=&quot;jupyter&quot; quay.io/hemberg-group/scrna-seq-course:v3.13 然后按照以下提供的说明操作, 比如: 要访问NoteBook，在浏览器中打开此文件: file:///home/jovyan/.local/share/jupyter/runtime/nbserver-6-open.html 或复制粘贴以下网址: http://(a9ee1aad5398 or 127.0.0.1):8888/?token=22debff49d9aae3c50e6b0b5241b47eefb1b8f883fcb7e6d Jupyter session会在web浏览器中打开(我们推荐使用Chrome浏览器) 1.4.1.1 Windows用户 Windows操作系统中容器的IP地址与127.0.0.1(localhost)不同。查找IP地址请运行: docker-machine ip default 1.4.2 下载数据或其它文件 请点击New -&gt; Terminal打开一个终端，在新的终端窗口运行: ./poststart.sh 如果您想在Docker镜像外下载数据，您依然可以使用相同poststart.sh脚本，但是您需要在您的计算机上安装AWS CLI。 Alternatively, you can browse and download the files in you web-browser by visiting this link 1.4.3 RStudio 返回到Jupyter浏览界面，将url中的tree更改为rstudio。RStudio server会打开课程文件，软件和数据文件夹。 1.5 手动安装 如果您没有使用本课程的Docker镜像，那么为了能够运行本课程所有的代码块，您需要克隆或下载GitHub仓，并在course_files文件夹中启动R session，然后您还需要手动安装所有必须的软件。 或者您可以只安装感兴趣章节列出的软件。 1.6 许可 本课程所有资料均遵循GPL-3协议。 欢迎任何人浏览材料来学习scRNA-seq数据的分析。 如果您打算将这些材料用于您自己的教学，除了提供合适的引用外，如果您告诉我们，我们将不胜感激。 1.7 准备知识 本课程面向那些基本熟悉Unix和R脚本语言的人。同时我们还假设您熟悉传统bulk RNA-seq数据的比对和分析，以及常用的计算工具。 我们推荐在参加本课程前参加Introduction to RNA-seq and ChIP-seq data analysis 或者 Analysis of high-throughput sequencing data with Bioconductor 1.8 联系我们 如果您有任何的关于课程的意见，问题和建议，请联系Vladimir Kiselev. 译者注 : 或者在该repo下开个issue进行提问。 "],
["introduction-to-single-cell-rna-seq.html", "2 scRNA-seq介绍 2.1 Bulk RNA-seq 2.2 scRNA-seq 2.3 工作流程 2.4 计算分析 2.5 挑战 2.6 实验方法 2.7 如何选择合适的平台", " 2 scRNA-seq介绍 2.1 Bulk RNA-seq 2000后期重大突破，取代微阵列芯片被广泛采用 测量大量混合细胞的平均表达水平 用于比较转录组学，例如比较不同物种同一组织的样本 用于量化整体表达特征，例如疾病研究 不足研究异质性系统，例如早起发育的研究，复杂组织(脑)的研究 不能呈现基因表达随机性 2.2 scRNA-seq 一项新兴技术，第一篇文章为汤富酬发表在Nature method (Tang et al. 2009) 直到~2014年，新测序手段和更低的成本使其流行起来 在大量细胞检测每个基因的表达水平 可以研究新的生物学问题，其中转录组的细胞特异性变化是重要的，比如细胞类型鉴定，细胞响应的异质性，基因表达的随机性，细胞间基因调控网络的推断 研究细胞数目从\\(10^2\\)到\\(10^6\\)个细胞，而且每年递增 目前有不同单细胞的protocol，比如SMART-seq2 (Picelli et al. 2013), CELL-seq (Hashimshony et al. 2012) 和 Drop-seq (Macosko et al. 2015) 也有商业平台, 包括 Fluidigm C1, Wafergen ICELL8 和 10X Genomics Chromium 一些计算分析bulk RNA-seq的方法也适用于 scRNA-seq 大多数情况下 scRNA-seq计算分析需要调整已有方法或者开发新方法 2.3 工作流程 Figure 2.1: 单细胞测序流程 (源自wiki) 总体而言，scRNA-seq实验protocol和bulk RNA-seq类似，我们将在下一章讨论一些最常用的方法。 2.4 计算分析 本课程是用scRNA-seq实验获得的数据进行计算分析。 第一步（黄色）对任何高通量测序数据都是通用的； 后续步骤（橙色）需要整合现有的RNA-Seq分析方法和新方法来解决scRNA-Seq的技术差异； 最后步骤（蓝色），用专门为scRNA-Seq开发的方法进行生物学解释。 Figure 2.2: scRNA-seq分析流程图 目前有几篇关于scRNA-seq分析的综述文章，包括 (Stegle, Teichmann, and Marioni 2015) 目前，也有不同的平台执行上述流程图的一步或多个步骤，包括: Falco 云端单细胞RNA-seq处理框架 SCONE (Single-Cell Overview of Normalized Expression), 单细胞RNA-seq数据质量控制和标准化的包. Seurat 用于单细胞RNA-seq数据质量控制，分析和数据探索的R包. ASAP (Automated Single-cell Analysis Pipeline) 是一个单细胞分析交互式webserver. Bioconductor 是一个分析高通量基因组数据开源，开放式软件项目，包括分析单细胞数据的工具包。 2.5 挑战 scRNA-seq和bulk RNA-seq最大的不同在于每个测序文库是单个细胞，而不是一群细胞。因此需要各位注意来自不同细胞（测序文库）的结果的比较。文库之间差异的主要来源是: 扩增偏好性和扩增效率 （高达1,000,000倍） 基因的’dropout’，其中一个基因在一个细胞中等表达水平，但在另外一个细胞没有检测到(Kharchenko, Silberstein, and Scadden 2014). 在两种情况下， 由于RNA仅来自一个细胞，因此低起始量的转录本是导致差异的主要原因。提高转录本捕获效率和减少扩增偏差是目前活跃的研究灵越。从后续的课程我们也可以看到，可以通过适当的标准化和校正方法来缓解这些问题。 2.6 实验方法 Figure 2.3: 单细胞转录组学摩尔定律 (图片来自 Svensson et al) 开发新的scRNA-seq方法和protocol是目前非常活跃的一个研究领域，在过去的几年中已经发表了一些protocol，不完全列表如下: CEL-seq (Hashimshony et al. 2012) CEL-seq2 (Hashimshony et al. 2016) Drop-seq (Macosko et al. 2015) InDrop-seq (Klein et al. 2015) MARS-seq (Jaitin et al. 2014) SCRB-seq (Soumillon et al. 2014) Seq-well (Gierahn et al. 2017) Smart-seq (Picelli et al. 2014) Smart-seq2 (Picelli et al. 2014) SMARTer STRT-seq (Islam et al. 2013) 这些方法可以按照不同方法进行归类，最重要的两个方面是定量和捕获 定量有两种类型，全长和基于标签。前者试图达到每个转录本均匀覆盖率；然而基于tag的protocol只捕获每个RNA的5’或3’端。量化方法的选择对于数据可用于何种类型的分析具有重要意义。理论上讲，基于全长的protocol可以对整个转录本进行均匀测序，然而通常测序覆盖有偏差。基于tag的protocol主要优势是其可以和唯一的分子标识符结合使用，提高定量准确性(see chapter ??)。另一方面，测序限制在转录组的一端，降低比对map率，并难以区分不同的异构体(Archer et al. 2016)。 捕获的策略决定了通量，细胞如何被选择以及除测序外还可以获得哪种附加信息。三种常用的方法是基于微孔(microwell)-，微流体(microfluidic)-，液滴(droplet)-的方法。 Figure 2.4: 微孔板 (图片来自wiki) 对于基于微孔的平台，使用例如移液管或激光捕获分离细胞并置于微流体孔中。 基于微孔的方法的一个优点是它们可以与荧光激活细胞分选（FACS）结合，基于表面标记物分选细胞。 因此，当想要分离特定细胞群体用于测序时，该策略非常有用。 另一个优点是可以拍摄细胞的照片。 该图像提供了额外的细胞形态，适用于识别包含受损细胞或双份细胞的微孔。 这些方法的主要缺点是它们通常是通量低并且每个单细胞所需的工作量可能相当大。 Figure 2.5: 96孔Fluidigm C1芯片 (图片来自Fluidigm) 微流体平台, 比如 Fluidigm’s C1, 提供了更加集成的系统，用于捕获细胞和进行文库制备所需的过程。 因此，它们提供比基于微孔的平台更高的通量。 通常，在微流体平台中仅捕获约10％的细胞，因此不适合处理稀有细胞类型或非常少量的细胞。 此外，芯片相对昂贵，但由于反应可以以较小的体积进行，因此可以节省试剂。 Figure 2.6: drop-seq方法的原理图 (图片来自Macosko et al) 基于液滴的方法将每个单独的细胞与包括建库所需酶的珠子(bead)一起封装在纳升液滴内。每个珠子都包含唯一的条形码(barcode)，加到所有来自该细胞的序列上。因此可以合并所有液滴进行测序，再基于barcode将序列分配给不同的细胞。Droplet平台通常具有最高的通量，因为建库准备成本约为\\(.05\\) 美元/细胞。相反，测序成本成为其限制因素，通常实验覆盖率低，仅检测到几千个转录本 (Ziegenhain et al. 2017)。 2.7 如何选择合适的平台 最合适的平台取决于手头的生物学问题。 例如，如果研究组织的组成，那么将允许捕获非常大量细胞的基于液滴的方法可能是最合适的。 另一方面，如果人们对具有已知表面标记物的稀有细胞类群感兴趣，那么最好使用FACS进行富集，然后对较少数量的细胞进行测序。 显然，如果研究不同的异构体，那么全长转录物定量将更合适。相比之下，UMI只能与基于tag的protocol一起使用，促进基因水平的量化。 来自Enard group (Ziegenhain et al. 2017)和Teichmann group (Svensson et al. 2017)最近两项研究比较了几种不同的protocol。Ziegenhain等人在同一小鼠胚胎干细胞样本（mESCs）上比较了五种不同的protocol。通过控制细胞数量和测序深度，作者能够直接比较不同protocol的灵敏度，噪声水平和成本。 他们的结论的一个例子如下图所示，不同protocol检测的基因数量（对于给定的检测阈值）差别很大。drop-seq和Smart-seq2之间几乎有两倍的差异，这表明protocol的选择会对研究有重大影响。 Figure 2.7: Enard group 研究 Svensson等采用了另外一种方法，通过使用已知浓度的合成转录本（spike-ins，后面详细介绍）来测量不同protocol的准确性和灵敏度。通过广泛的比较研究，他们同样发现不同protocol间区别较大。 Figure 2.8: Teichmann group 研究 随着实验技术的发展和用于量化技术噪声的计算方法的改进，后续研究有助于我们进一步了解不同方法的优缺点。因为基准测试可以确定哪些策略是最有用的，这些比较研究不仅有助于研究人员决定使用哪种protocol，而且有助于开发新方法。 References "],
["processing-raw-scrna-seq-data.html", "3 scRNA-seq原始数据处理 3.1 FastQC 3.2 移除接头和低质量碱基 3.3 文件格式 3.4 测序文库拆分 3.5 使用STAR比对read 3.6 Kallisto和Pseudo-Alignment", " 3 scRNA-seq原始数据处理 3.1 FastQC 获得单细胞RNA-seq数据后，首先要做的就是检查测序质量，我们使用FastQC来完成此任务。 FastQC是用于测序数据的质量控制工具，既可以用于bulk RNA-seq，也可以用于scRNA-seq。 FastQC将测序数据作为输入，并返回测序质量的报告。访问以下链接获取更多关于FastQC的信息： https://www.bioinformatics.babraham.ac.uk/projects/fastqc/ 该网站包含下载和安装FastQC的链接以及生成报告的文档。幸运的是，我们已经为您安装了FastQC1，因此这里我们将查看文档。将网页向下滚动到“示例报告”，然后单击“Good Illumina Data”。 这里给出了高质量Illumina测序数据立项报告的示例。 现在让我们自己生成一份FastQC报告。 今天，我们将使用(Kolodziejczyk et al. 2015)生成的mESC单细胞数据集进行分析。细胞使用SMART-seq2 protocol构建测序文库并进行双端测序。这些文件位于Share文件夹中。 注意 本课程的当前文本是为参加我们课程的人员编写的。您必须下载文件（ERR522959_1.fastq和ERR522959_2.fastq）并创建Share目录才能运行命令。你可以在这里找到这些文件： https://www.ebi.ac.uk/arrayexpress/experiments/E-MTAB-2600/samples/ 现在让我们来看看文件: less Share/ERR522959_1.fastq less Share/ERR522959_2.fastq 任务1: 尝试找出生成FastQC报告的命令，提示: 尝试执行 fastqc -h 该命令将告诉您可以传递给FastQC的参数。如果您遇到困难，请随时寻求帮助！ 如果运行成功，则应为正向和反向reads 都会生成.zip和.html文件。运行成功后，请跳到下一节。 3.1.1 解决方案并下载报告 如果还没有成功，请使用以下命令生成FastQC报告： mkdir fastqc_results fastqc -o fastqc_results Share/ERR522959_1.fastq Share/ERR522959_2.fastq 一旦命令执行完毕，您应该总共有四个文件 - 每个read对应一个zip和html文件，报告位于html文件中。 要查看它，我们需要使用filezilla或scp将它从AWS下载到您的计算机上。 下载到本地后，单击打开您的FastQC报告。记得要查看正向和反向read的质量报告！测序的质量如何？有什么我们应该关注的问题吗？ 我们如何解决这些问题呢？ 3.2 移除接头和低质量碱基 Trim Galore是一个cutadapt的封装，用于移除测序接头序列和测序末端的低质量碱基。 鉴于FastQC报告中存在一些接头污染，最好从数据中移除接头序列。 任务2：数据中使用了哪种类型的接头序列？提示：查看FastQC报告“Adapter Contern”图。 现在让我们使用Trim Galore移除那些有问题的接头序列，修剪后再次检查读取质量，使用FastQC生成另一个报告。 任务3：找出移除adapter的命令。提示1：您可以使用 trim_galore -h 查看Trim Galore的参数描述。 提示2：仔细阅读上述命令的输出。本实验中使用的接头序列非常常见。您是否需要知道接头的实际序列才能将其删除？ 任务4: 为清洗后的数据生成FastQC报告。接头序列污染消失了吗？ 一旦您认为您已成功去除接头序列并通过FastQC确认，请使用下一部分核验您的结果。 3.2.1 Solution 您可以使用以下命令去除Nextera测序接头序列： mkdir fastqc_trimmed_results trim_galore --nextera -o fastqc_trimmed_results Share/ERR522959_1.fastq Share/ERR522959_2.fastq 请记住为清洗后的数据文件重新生成FastQC报告！FastQC现在应该显示’Adaptor Content’为’pass’了。 祝贺您现在已生成测序质量报告并移除接头序列。在下一步中，我们将使用STAR和Kallisto将清洗后的reads比对到参考转录组上。 3.3 文件格式 3.3.1 FastQ FastQ是scRNA-seq数据中最原始数据格式。所有scRNA-seq protocol都使用双端测序，根据使用的protocol，条形码序列(barcode)可能出现在paired-reads中一条或两条上。但是使用唯一分子标识符(UMIs) 的protocol会生成包含细胞和UMI条形码加上接头序列但是没有转录本序列的read。因此虽然是双端测序，但比对时按照单端测序对待。 FastQ文件格式如下: &gt;ReadID READ SEQUENCE + SEQUENCING QUALITY SCORES 3.3.2 BAM BAM文件以标准且高效的方式存储比对结果。SAM文件为直接可读的，而BAM文件是高度压缩的版本。BAM / SAM文件包含头部信息，通常包括样本制备，测序和比对的信息;后面为每个read的比对结果，以tab作为分隔符。 比对行标准格式如下: QNAME : read名称(如果为UMI文库，则包括UMI条形码) FLAG : 数字指示reads比对的类型, link该网站有所有可能的类型 RNAME : 参考序列名称 (比如比对到的染色体名称). POS : 最左边比对位置 MAPQ : 比对质量 CIGAR : 表示reads中匹配/不匹配部分 (可能包括soft-clipping). RNEXT : mate/next reads比对到的参考序列名称 PNEXT : mate/next reads比对到的第一个碱基位置 TLEN : 模板长度（read比对到的参考区域的长度） SEQ : read序列 QUAL : read质量 BAM/SAM 文件可通过’samtools’互相转换: samtools view -S -b file.sam &gt; file.bam samtools view -h file.bam &gt; file.sam 一些测序设备会自动将测序reads比对到标准基因组上，并提供BAM或CRAM格式文件。通常基因组中不包含ERCC序列，因此不会又ERCCs reads比对到在BAM / CRAM文件中。 要量化ERCC（或任何其他遗传变异），或者如果您只想使用不同于标准流程的比对算法（通常过时），那么您将需要将BAM / CRAM文件转换回FastQs: BAM文件可以使用bedtools转为FastQ。为避免比对到多个基因组位置的一个read转换为FastQ多条read，首先将BAM文件按读取名称排序，并使用samtools删除次级比对。Picard也包含将BAM转换为FastQ文件的方法。 # sort reads by name samtools sort -n original.bam -o sorted_by_name.bam # remove secondary alignments samtools view -b -F 256 sorted_by_name.bam -o primary_alignment_only.bam # convert to fastq bedtools bamtofastq -i primary_alignment_only.bam -fq read1.fq -fq2 read2.fq 3.3.3 CRAM CRAM文件类似SAM文件，其头部信息包括比对使用的参考基因组信息，这使得read中和参考基因组一样的碱基可以进一步压缩。与BAM相比，CRAM还支持有损数据压缩方法以进一步优化存储。CRAM主要由Sanger/EBI测序机构使用。 CRAM和BAM文件可以使用最新版本的samtools（&gt; = v1.0）进行格式转换。但是，这种转换可能需要将参考基因组下载到缓存中。 或者，您可以从CRAM文件的头部元数据预先下载参考基因组，或者询问生成CRAM文件的人获得参考基因组，并使用’-T’指定该文件。因此我们建议在执行此操作之前设置特定的缓存位置： export REF_CACHE=/path_to/cache_directory_for_reference_genome samtools view -b -h -T reference_genome.fasta file.cram -o file.bam samtools view -C -h -T reference_genome.fasta file.bam -o file.cram 3.3.4 手动查看文件 有时，手动检查文件可能很有用，例如检查文件的头部信息。’less’和’more’可在命令行查看任何文本文件。管道符|可以在多个命令之间传输数据，省却把中间数据存储多个拷贝的过程。 less file.txt more file.txt # counts the number of lines in file.txt wc -l file.txt samtools view -h file.[cram/bam] | more # counts the number of lines in the samtools output samtools view -h file.[cram/bam] | wc -l 练习 现提供cram示例文件: EXAMPLE.cram 任务1: 这个文件是怎么生成的？使用了什么软件？参考基因组时什么？(提示: 检查头部信息) 任务2: 有多少reads比对上/没有比对上？总共有多少reads？secondary alignments有多少? (提示: 使用FLAG) 任务3: 将CRAM转为Fastq文件。转换后的read只有一个拷贝吗？(将转换后的Fastq文件命名为“10cells_read1.fastq” “10cells_read2.fastq”) 如果您遇到问题，可以通过输入命令来显示每个软件的帮助信息 - 例如 ‘samtools view’，‘bedtools’ 答案 samtools view -T data/2000_reference.transcripts.fa -H data/EXAMPLE.cram | more samtools view -T data/2000_reference.transcripts.fa -f 4 data/EXAMPLE.cram | wc -l # unmapped samtools view -T data/2000_reference.transcripts.fa -F 260 data/EXAMPLE.cram | wc -l # mapped samtools view -T data/2000_reference.transcripts.fa -F 256 data/EXAMPLE.cram | wc -l # total samtools view -T data/2000_reference.transcripts.fa -f 256 data/EXAMPLE.cram | wc -l # secondary alignments samtools view -b -h -T data/2000_reference.transcripts.fa data/EXAMPLE.cram -o data/EXAMPLE.bam samtools sort -n data/EXAMPLE.bam -o data/sorted_EXAMPLE.bam samtools view -b -F 256 data/sorted_EXAMPLE.bam -o data/primary_EXAMPLE.bam # convert to fastq bedtools bamtofastq -i data/primary_EXAMPLE.bam -fq data/10cells_read1.fq -fq2 data/10cells_read2.fq 3.3.5 Genome (FASTA, GTF) 为了比对序列，需要参考基因组和基因组注释文件(GTF或者GFF格式)。模式生物的基因组和注释文件可以从目前主流的基因组数据库下载: Ensembl, NCBI, 或者 UCSC Genome Browser. GTF文件包括基因，转录本和外显子的注释，格式如下： (1) seqname : 染色体/scaffold编号 (2) source : 注释来源 (3) feature : 注释信息类型(比如基因，转录本，外显子) (4) start : 起始位置 (bp) (5) end : 终止 (bp) (6) score : 得分 (7) strand : + (正链) or - (负链) (8) frame : 仅对CDS有效，起始编码位置，或者到达下一个密码子需要跳过的碱基个数 (0 = first base, 1 = second base, etc..) (9) attribute : ;分割的键值对来显示其它信息 (比如 names/IDs, biotype) 空字段用“.”填充 根据我们的经验，Ensembl是最容易使用的，并且具有最大的注释集。NCBI往往更严格，仅包括置信度高的基因注释。 而UCSC包含多个使用不同标准的基因组注释。 如果您的实验系统包含非标准序列，则必须将这些序列添加到基因组fasta和gtf中来定量它们的表达。 最常见的是针对ERCC spike-ins，CRISPR相关的序列或其他过表达/报告载体。 为了获得最大的可用性/灵活性，我们建议为添加的任何非标准序列创建完整和详细的fasta序列和gtf序列。 目前没有标准化的方法来做到这一点 以下是我们的自定义perl脚本，用于为ERCC创建一个gtf和fasta文件，可以将其附加到基因组中。如果要量化内含子读数时，您可能还需要更改gtf文件以处理内含子中的重复元素。任何脚本语言甚至“awk”或一些文本编辑器都可以用来相对有效地完成这项任务，但它们超出了本课程的范围。 # Converts the Annotation file from # https://www.thermofisher.com/order/catalog/product/4456740 to # gtf and fasta files that can be added to existing genome fasta &amp; gtf files. my @FASTAlines = (); my @GTFlines = (); open (my $ifh, &quot;ERCC_Controls_Annotation.txt&quot;) or die $!; &lt;$ifh&gt;; #header while (&lt;$ifh&gt;) { # Do all the important stuff chomp; my @record = split(/\\t/); my $sequence = $record[4]; $sequence =~ s/\\s+//g; # get rid of any preceeding/tailing white space $sequence = $sequence.&quot;NNNN&quot;; my $name = $record[0]; my $genbank = $record[1]; push(@FASTAlines, &quot;&gt;$name\\n$sequence\\n&quot;); # is GTF 1 indexed or 0 indexed? -&gt; it is 1 indexed # + or - strand? push(@GTFlines, &quot;$name\\tERCC\\tgene\\t1\\t&quot;.(length($sequence)-2).&quot;\\t.\\t+\\t.\\tgene_id \\&quot;$name-$genbank\\&quot;; transcript_id \\&quot;$name-$genbank\\&quot;; exon_number \\&quot;1\\&quot;; gene_name \\&quot;ERCC $name-$genbank\\&quot;\\n&quot;); push(@GTFlines, &quot;$name\\tERCC\\ttranscript\\t1\\t&quot;.(length($sequence)-2).&quot;\\t.\\t+\\t.\\tgene_id \\&quot;$name-$genbank\\&quot;; transcript_id \\&quot;$name-$genbank\\&quot;; exon_number \\&quot;1\\&quot;; gene_name \\&quot;ERCC $name-$genbank\\&quot;\\n&quot;); push(@GTFlines, &quot;$name\\tERCC\\texon\\t1\\t&quot;.(length($sequence)-2).&quot;\\t.\\t+\\t.\\tgene_id \\&quot;$name-$genbank\\&quot;; transcript_id \\&quot;$name-$genbank\\&quot;; exon_number \\&quot;1\\&quot;; gene_name \\&quot;ERCC $name-$genbank\\&quot;\\n&quot;); } close($ifh); # Write output open(my $ofh, &quot;&gt;&quot;, &quot;ERCC_Controls.fa&quot;) or die $!; foreach my $line (@FASTAlines) { print $ofh $line; } close ($ofh); open($ofh, &quot;&gt;&quot;, &quot;ERCC_Controls.gtf&quot;) or die $!; foreach my $line (@GTFlines) { print $ofh $line; } close ($ofh); 3.4 测序文库拆分 文库拆分根据Protocol不同或构建的流程不同需要有对应的处理方式。我们所知道的最灵活的文库拆分工具是zUMIs，可用于拆分和比对大多数基于UMI的protocol。对于Smartseq2或其他全长转录本双端测序protocol，数据通常已经被拆分好。诸如GEO或ArrayExpress之类的公共存储库需要在上传之前对基于小规模/基于板的scRNASeq数据拆分，并且许多测序公司在数据返回给您之前自动拆分数据。如果您没有使用已发表的流程，并且数据未被测序公司拆分，则您必须自己对其进行文库拆分。因为不同的建库方案引入的barcode序列的长度和位置不同，通常都需要自己写脚本解决。 对于所有数据类型，文库拆分涉及从一端或双端短序列中识别并移除细胞条形码序列(cell-barcode)。如果提前知道加入的cell-barcodes，比如数据来自基于PCR板的protocol，需要将每个cell-barcode与预期的cell-barcode进行比对，并将其归类于最相近的cell-barcode(根据cell-barcode的设计，一般允许最多1-2错配)。这些数据通常在比对之前进行拆分，从而可以并行比对。 我们提供公开可用perl脚本，可以拆分任何有或没有UMI 的plate-based的建库方案生成的数据，用法如下： perl utils/1_Flexible_UMI_Demultiplexing.pl data/10cells_read1.fq data/10cells_read2.fq &quot;C12U8&quot; data/10cells_barcodes.txt 2 Ex Barcode Structure: 12 bp CellID followed by 8 bp UMI Doesn&#39;t match any cell: 0 Ambiguous: 0 Exact Matches: 400 Contain mismatches: 0 Input Reads: 400 Output Reads: 400 perl utils/1_Flexible_FullTranscript_Demultiplexing.pl data/10cells_read1.fq data/10cells_read2.fq &quot;start&quot; 12 data/10cells_barcodes.txt 2 Ex Doesn&#39;t match any cell: 0 Ambiguous: 0 Exact Matches: 400 Contain Mismatches: 0 Input Reads: 400 Output Reads: 400 对于包含UMI的数据，文库拆分包括将UMI code附加到包含基因区的序列read名字上。如果数据来自droplet-based protocol或SeqWell，其中预期条形码的数量远远高于预期的细胞数量，为避免生成才能大量的文件么cell-barcode也加到测序read的名字后面。在这些情况下，在量化步骤期间进行文库拆分，以便于识别来源于完整细胞而不是背景噪声的cell-barcode。 3.4.1 鉴定含有细胞的液滴/微孔 基于液滴的scRNA-seq方法，只有一部分液滴包含bead和一个完整的细胞。然而生物实验可能不理想，一些RNA会从死细胞/受伤细胞中泄露出去。因此，没有完整细胞的液滴可能捕获少量环境游离RNA，这些RNA将进入测序文库，出现在最终测序结果中。液滴大小，扩增效率和测序的变化将导致“背景”和真实细胞文库大小区别很大。目前已有很多方法用来区分对应真实细胞的cell-barcode 已经使用各种方法来试图区分对应于真实细胞的那些细胞条形码。 大多数方法使用每个barcode的总分子数（可以应用于总reads）并尝试寻找“break point”，区分来自真实细胞较大的文库和来自背景较小的文库。下面加载包含大小文库细胞的示例模拟数据： umi_per_barcode &lt;- read.table(&quot;data/droplet_id_example_per_barcode.txt.gz&quot;) truth &lt;- read.delim(&quot;data/droplet_id_example_truth.gz&quot;, sep=&quot;,&quot;) 练习 多少唯一的barcode被检测到？ 数据中多少来自真实的细胞？ 为简化计算，去除所有少于10个分子的barcode。 答案 dim(umi_per_barcode)[1] dim(truth)[1] 一种方法是寻找每个条形码对应总分子突然下降的拐点。 One approach is to look for the inflection point where the total molecules per barcode suddenly drops: barcode_rank &lt;- rank(-umi_per_barcode[,2]) plot(barcode_rank, umi_per_barcode[,2], xlim=c(1,8000)) 可以看出文库大小近似指数分布，简单起见，对数据进行log转换。 log_lib_size &lt;- log10(umi_per_barcode[,2]) plot(barcode_rank, log_lib_size, xlim=c(1,8000)) 从上图可以看出，拐点更加明显了。我们可以手动估计拐点的位置，但是用算法估计更加精确，以及可重复。 # inflection point o &lt;- order(barcode_rank) log_lib_size &lt;- log_lib_size[o] barcode_rank &lt;- barcode_rank[o] rawdiff &lt;- diff(log_lib_size)/diff(barcode_rank) inflection &lt;- which(rawdiff == min(rawdiff[100:length(rawdiff)], na.rm=TRUE)) plot(barcode_rank, log_lib_size, xlim=c(1,8000)) abline(v=inflection, col=&quot;red&quot;, lwd=2) threshold &lt;- 10^log_lib_size[inflection] cells &lt;- umi_per_barcode[umi_per_barcode[,2] &gt; threshold,1] TPR &lt;- sum(cells %in% truth[,1])/length(cells) Recall &lt;- sum(cells %in% truth[,1])/length(truth[,1]) c(TPR, Recall) ## [1] 1.0000000 0.7831707 另外一种方法是构建混合模型，找出重叠区域的最高和最低分布。然而数据可能并不满足假定的分布。 set.seed(-92497) # mixture model require(&quot;mixtools&quot;) ## 载入需要的程辑包：mixtools ## mixtools package, version 1.1.0, Released 2017-03-10 ## This package is based upon work supported by the National Science Foundation under Grant No. SES-0518772. mix &lt;- normalmixEM(log_lib_size) ## number of iterations= 43 plot(mix, which=2, xlab2=&quot;log(mol per cell)&quot;) p1 &lt;- dnorm(log_lib_size, mean=mix$mu[1], sd=mix$sigma[1]) p2 &lt;- dnorm(log_lib_size, mean=mix$mu[2], sd=mix$sigma[2]) if (mix$mu[1] &lt; mix$mu[2]) { split &lt;- min(log_lib_size[p2 &gt; p1]) } else { split &lt;- min(log_lib_size[p1 &gt; p2]) } 练习 使用分割点识别细胞并计算TPR和Recall 答案 cells &lt;- umi_per_barcode[umi_per_barcode[,2] &gt; 10^split,1] TPR &lt;- sum(cells %in% truth[,1])/length(cells) Recall &lt;- sum(cells %in% truth[,1])/length(truth[,1]) c(TPR, Recall) 第三种方法，CellRanger假设真实细胞文库大小变化范围在10倍以内，然后用哪个期望的细胞数目估计区间的分布。 n_cells &lt;- length(truth[,1]) # CellRanger totals &lt;- umi_per_barcode[,2] totals &lt;- sort(totals, decreasing = TRUE) # 99th percentile of top n_cells divided by 10 thresh = totals[round(0.01*n_cells)]/10 plot(totals, xlim=c(1,8000)) abline(h=thresh, col=&quot;red&quot;, lwd=2) 练习 用该阈值识别细胞并计算TPR和Recall。 答案 cells &lt;- umi_per_barcode[umi_per_barcode[,2] &gt; thresh,1] TPR &lt;- sum(cells %in% truth[,1])/length(cells) Recall &lt;- sum(cells %in% truth[,1])/length(truth[,1]) c(TPR, Recall) 最后EmptyDrops，目前处于Beta测试阶段，其实用所有液滴的基因 × 细胞分子计数矩阵，从具有极低counts的液滴估计背景RNA的分布，然后寻找与背景基因表达模式不同的细胞。背景RNA通常和群体中大部分细胞的表达模式相似，该方法与拐点方法相结合。因此，EmptyDrops是唯一能够识别高度多样化样本中鉴定小群体细胞条形码的方法。 下面提供了该方法的运行代码：（我们会根据官方发布及时更新代码） require(&quot;Matrix&quot;) raw.counts &lt;- readRDS(&quot;data/droplet_id_example.rds&quot;) require(&quot;DropletUtils&quot;) # emptyDrops set.seed(100) e.out &lt;- emptyDrops(my.counts) is.cell &lt;- e.out$FDR &lt;= 0.01 sum(is.cell, na.rm=TRUE) plot(e.out$Total, -e.out$LogProb, col=ifelse(is.cell, &quot;red&quot;, &quot;black&quot;), xlab=&quot;Total UMI count&quot;, ylab=&quot;-Log Probability&quot;) cells &lt;- colnames(raw.counts)[is.cell] TPR &lt;- sum(cells %in% truth[,1])/length(cells) Recall &lt;- sum(cells %in% truth[,1])/length(truth[,1]) c(TPR, Recall) 3.5 使用STAR比对read 现在我们已经对测序数据进行质控，并且获得了高质量的清洗后数据，下一步将其比对到参考基因组上。如果我们想要定量基因表达或筛选样品间差异表达的基因，则通常需要某种形式的比对。 短序列比对的工具有很多，目前我们主要关注两个。第一个工具是STAR (Dobin et al. 2013)，对于测序数据中的每一个read，STAR尝试寻找参考基因组中一个或多个最长可能序列。例如，下图所示，read(蓝色)跨越两个外显子和一个可变剪切位点(紫色)。STAR能够找出read的第一部分和序列的第一个外显子仙童，同时第二部分和序列的第二个外显子相同。因为STAR可能够以这种方式识别剪切事件，又被称为“spice aware alinger”。 Figure 3.1: STAR比对示意图, 来自Dobin et al. 通常，STAR将reads比对到参考基因组是允许其检测新的剪接事件或染色体重排。然而，STAR的一个问题是它需要大量的内存，特别是当参考基因组很大（例如，小鼠和人类）。为了加速我们今天的分析，我们将使用STAR将reads与只包含2000个转录本的参考转录组进行比对。请注意，这不是正常或推荐的做法，我们只是出于时间原因这样做。我们建议比对到参考基因组。 STAR对齐需要两个步骤。第一步，用户向STAR提供参考基因组序列（FASTA）和注释文件（GTF），STAR用它来创建基因组索引。 第二步，STAR将用户的reads比对到基因组索引。 首先现在创建索引。请记住，由于时间的原因，我们比对到转录组而不是基因组，这意味着我们只需要向STAR提供比对的转录本序列。可以从Ensembl获取许多模式生物的转录组数据。 任务 1: 执行以下命令创建索引: mkdir indices mkdir indices/STAR STAR --runThreadN 4 --runMode genomeGenerate --genomeDir indices/STAR --genomeFastaFiles Share/2000_reference.transcripts.fa 任务 2: STAR用到的每个参数意义? 提示: 参考STAR帮助文档 任务 3: 如果比对到基因组而不是转录组，命令是什么？ 现在索引创建完成，进行比对步骤。 任务 4: 尝试找出应该使用什么命令将我们的清洗后的数据（从ERR522959）比对索引上。参考使用STAR手册， 您认为知道答案，检查它是否与下一节中的解决方案匹配并执行比对。 任务 5: 尝试了解比对结果文件。 3.5.1 STAR比对命令 使用以下命令完成比对: mkdir results mkdir results/STAR STAR --runThreadN 4 --genomeDir indices/STAR --readFilesIn Share/ERR522959_1.fastq Share/ERR522959_2.fastq --outFileNamePrefix results/STAR/ 3.6 Kallisto和Pseudo-Alignment STAR是read比对工具，而Kallisto是伪比对工具(Bray et al. 2016)。它们的主要区别是aligner比对到参考基因组或转录组上，而pseudo-aligner将k-mers比对到参考基因组或转录组上。 3.6.1 k-mer是什么? k-mer是来自reads长度为k的序列。例如，假设read为ATCCCGGGTTAT，从中制作7-mer。为此，提取read的前七个碱基找到第一个7-mer。然后向下移动一个碱基得到第二个7-mer，然后计算接下来的七个碱基。图2显示了可以从read得到的所有7-mers： Figure 3.2: 示例read产生7-mer 3.6.2 为什么比对k-mer而不是reads? 主要有两个原因： psudi-aligners使用计算技巧使得比对k-mers比传统比对reads要快，具体细节参考(Bray et al., 2017) 在一些情况下，pseudo-aligners比对传统的比对工具更好地处理测序错误。比如，假设序列的第一个碱基存在测序错误，实际为T但是测序为A，这会影响pseduo-aligners比对第一个7-mer，而不影响后面7-mers的比对。 3.6.3 Kallisto伪比对模式 Kallisto有一个为scRNA-seq实验特别设计的伪比对模式。与STAR不同的是，Kallisto比对到参考转录组而不是参考基因组。 这意味着Kallisto将reads比对到剪接异构体而不是基因，然而对scRNA-seq而言，这很有挑战性： 由于以下原因，对单细胞RNA-seq特异性地将读数映射到同种型而不是基因： scRNA-seq覆盖率比bulk RNA-seq低，意味着从reads获得的信息减少。 许多scRNA-seq protocol 在3’端覆盖存在偏差，意味着如果两个异构体只在5’端不同，则很难确定read来自哪个异构体。 一些scRNA-seq protocol测序读段较短，难以区分read来自哪个异构体。 Kallisto的pseudo mode和pseudo alignment略有不同。Kallisto不与异构体比对，而是与等价类(equivalence classes)比对。如果read比对到多个异构体上，Kallisto会记录read比对到包含有所有异构体的等价类，因此可以使用等价类计数而非基因或转录本计数用于下游的聚类等分析。具体见下图： Figure 3.3: Kallisto等价类示意图, 来自 https://pachterlab.github.io/kallisto/singlecell.html. 今天我们只用1个细胞进行pseudo-alignment, 但是Kallisto可以同时对大量细胞进行pseudo-alignment以及使用UMI信息，具体参看官方文档 类似STAR，pseudo-alignment之前需要用Kallisto生成索引。 任务 6: 使用以下命令构建Kallisto索引, 使用官方手册理解每个参数的意义 mkdir indices/Kallisto kallisto index -i indices/Kallisto/transcripts.idx Share/2000_reference.transcripts.fa 任务 7: 使用Kallisto手册找出运行pseudo-alignment的命令，如果您认为知道答案，可以去下一节核验并运行pseudo-alignment。 3.6.4 Kallisto Pseudo-Alignment命令 使用以下命令执行pseudo-alignment mkdir results/Kallisto kallisto pseudo -i indices/Kallisto/transcripts.idx -o results/Kallisto -b batch.txt 参考官方手册构建batch.txt。 3.6.5 理解Kallisto输出结果 上述命令会生成4个文件 - matrix.cells, matrix.ec, matrix.tsv and run_info.json. matrix.cells 细胞ID列表. 因为我们只使用一个细胞，该文件应该只包含“ERR522959” matrix.ec 等价类信息。每一行的第一个数字为等价类ID，第二个数字对应等价类的转录本ID。比如，“10 1,2,3”表示等价类10包括3个转录本，分别是1,2,3. ID顺序对应转录本在参考转录本的顺序。采用0-base技术，转录本ID为1,2,3分别对应2000_reference.transcripts.fa中第2,3,4个转录本。 matrix.tsv 每个等价类在不同cell的read count信息。第一个数字为等价类ID，如matrix.ec一样。第二个数字为cell ID，和matrix.cells文件中细胞名字对应。第三个数字等价类在该细胞的reads count。比如，“5 1 3”表示来自细胞1的3个reads比对到等价类5上。这里的细胞ID同样是0-based，所以细胞1对应matrix.cells的第二行。 Note that zero indexing is used, so cell 1 corresponds to the second line of matrix.cells. run_info.json Kallisto执行信息，一般可忽略。 References "],
["construction-of-expression-matrix.html", "4 构建表达矩阵 4.1 质量控制 4.2 Reads 比对 4.3 比对示例 4.4 Mapping QC 4.5 Reads定量 4.6 唯一分子标识符", " 4 构建表达矩阵 很多scRNA-seq数据分析从表达矩阵为开始。 一般来说，表达矩阵的每一行代表一个基因，每列代表一个细胞（但是一些作者会使用转置）。 每个条目代表特定基因在特定细胞的表达水平。表达量的单位取决于protocol和标准化方法。 4.1 质量控制 scRNA-seq实验测序结果是大量的cDNA reads。第一步是确保测序的高质量，可以使用以下标准工具执行质量控制，例如 FastQC 或 Kraken. 假设有experiment.bam文件,运行以下FASTQC命令 $&lt;path_to_fastQC&gt;/fastQC experiment.bam 下面是125 bp reads数据集的FastQC输出结果示例。下图显示了由于技术错误导致在read中心无法正确测序几个碱基。 但是，由于read的其余部分质量很高，因此该错误很可能对比对效率的影响可以忽略不计。 Figure 4.1: Example of FastQC output 另外，使用Integrative Genomics Browser (IGV)或者SeqMonk对数据进行可视化非常有帮助。 4.2 Reads 比对 将reads低质量碱基取出后，把剩下的序列比对到参考基因组上。同样，没有专门为scRNA-seq设计的比对方法。我们可以使用STAR或者TopHat进行比对。对来自有丰富注释信息模式生物(比如小鼠和人)的大型全长转录本数据集，pseudo-alignment方法(比如Kallisto，Salmon)可能比传统比对方法表现更好。基于drop-seq数据集包含数十万reads，pseudoaligners运行时间比传统比对工具快不止一个量级。 使用STAR比对示例 $&lt;path_to_STAR&gt;/STAR --runThreadN 1 --runMode alignReads --readFilesIn reads1.fq.gz reads2.fq.gz --readFilesCommand zcat --genomeDir &lt;path&gt; --parametersFiles FileOfMoreParameters.txt --outFileNamePrefix &lt;outpath&gt;/output 注意, 如果使用了spike-ins, 在比对前应将spike-ins的DNA序列添加到参考基因组序列中. 注意, 当使用UMIs，应该从read序列中取出条形码序列。通常做法是将barcode加到read名称上。 一旦将每个细胞的reads比对到参考基因组，我们需要确保每个细胞有足够数量的read比对到参考基因组。 根据我们的经验，小鼠或人类细胞的reads的map率为60-70％。但是此结果可能会因protocols，read长度和read比对工具参数而异。一般来说，我们希望所有细胞都具有相似的map率，因此应检查并可能删除任何异常值，map率低通常表示污染。 使用Salmon定量基因表达： $&lt;path_to_Salmon&gt;/salmon quant -i salmon_transcript_index -1 reads1.fq.gz -2 reads2.fq.gz -p #threads -l A -g genome.gtf --seqBias --gcBias --posBias 注意：Salmon或得到估计read counts和估计transcripts per million(tpm), TMP对scRNA-seq长基因的表达进行了过度校正，因此我们建议使用read counts。 4.3 比对示例 下列直方图显示scRNA-seq实验每个细胞比对reads总数。每个条形代表一个细胞，按照每个细胞的总reads数升序排列。三个红色箭头表示比对覆盖率降低的异常细胞，应该在后续分析中将其去除。黄色箭头表示unmapped reads较多的细胞。在比对质控步骤我们保留这两个细胞，但是在细胞质控时由于高的核糖体RNA reads比例将其移除。 Figure 4.2: Example of the total number of reads mapped to each cell. 4.4 Mapping QC 将原始测序数据比对到基因组后，需要评估比对的质量。目前有很多方法对比对质量进行评估，包括：rRNA/tRNAs reads数目，uniquely mapping reads比例，跨剪切位点的reads数，转录本read深度。为bulk RNA-seq开发的方法，比如RSeQC也适合单细胞数据： python &lt;RSeQCpath&gt;/geneBody_coverage.py -i input.bam -r genome.bed -o output.txt python &lt;RSeQCpath&gt;/bam_stat.py -i input.bam -r genome.bed -o output.txt python &lt;RSeQCpath&gt;/split_bam.py -i input.bam -r rRNAmask.bed -o output.txt 然而预期结果依赖于实验protocol，比如很多scRNA-seq方法是用poly-A富集来排除rRNA，但导致read覆盖率具有3’偏好性，即基因的3’区域更容易被检测到。下图展示了测序reads的3’偏好性，以及3个从数据集中移除的异常细胞。 Figure 4.3: Example of the 3’ bias in the read coverage. 4.5 Reads定量 下一步是定量每个细胞的基因表达水平。对于mRNA数据，可以使用针对bulk RNA-seq开发的工具，比如HT-seq 或者FeatureCounts # include multimapping &lt;featureCounts_path&gt;/featureCounts -O -M -Q 30 -p -a genome.gtf -o outputfile input.bam # exclude multimapping &lt;featureCounts_path&gt;/featureCounts -Q 30 -p -a genome.gtf -o outputfile input.bam Unique molecular identifiers (UMIs) 使得计算分子的绝对数目成为可能，并且在scRNA-seq非常受欢迎。下一章将讨论如何处理UMIs。 4.6 唯一分子标识符 感谢来 EMBL Monterotondo的Andreas Buness在本节的合作。 4.6.1 UMI介绍 UMI是在反转录过程中添加到转录本中的短（4-10bp）随机条形码序列。它们使测序read能够对应到单个转录物，从而去除scRNA-Seq数据扩增噪声和偏差。 Figure 4.4: UMI sequencing protocol 当对包含UMI数据测序时，仅对包含UMI的转录本末端进行测序（通常是3’末端） 4.6.2 比对条形码序列 由于条形码数量(\\(4^N\\),\\(N\\)为UMI的长度)比细胞中RNA分子(~\\(10^6\\))数目多，每个barcode通常会连接多个转录本。因此需要barcode和转录本比对位置来鉴定转录本分子。第一步比对UMI reads，推荐使用STAR，因为其运行速度快并且输出高质量BAM比对。此外，比对位置对鉴定转录本新的3’UTR很有帮助。 UMI测序通常由双端reads组成，其中一端read捕获细胞和UMI条形码，然后另一端read包含转录本的外显子序列(Figure 4.5)。注意：推荐移除reads中poly-A序列避免比对到基因/转录本内部的poly-A/poly-T序列而产生错误。 处理完UMI实验的reads后，通常有以下惯例： UMI加到另外一个配对read的序列名称中 reads按照cell barcode归类到不同的文件，对特别大，测序深度浅的数据集，cell barcode加到read名称中以减少文件数量。 Figure 4.5: UMI测序reads, 红色闪电代表不同片段的文职 4.6.3 Barcodes计数 理论上，每个唯一的UMI-转录本对应该对应来自一个RNA分子的所有reads，然而实际情况并非如此，常见原因如下： 不同UMI不一定表示为不同的分子，由于PCR或测序错误，碱基对替换事件可产生新的UMI序列。 较长的UMI碱基替换的可能性更高。根据cell barcode测序误差估计，7-10％的10bp UMI至少会包含一个错误。如果没有纠正错误，将导致高估转录本的数量。 不同转录本不一定是不同分子，比对错误，或者multimapping reads可能导致某些UMI对应到错误的基因/转录本，这种类型的错误也会导致高估转录本的数量。 相同的UMI不一定是相同分子，UMI频率和短UMI可导致相同UMI连接到相同基因的不同mRNA分子。因此，将导致低估转录本数量。 Figure 4.6: UMIs中可能错误 4.6.4 错误校正 如何最好地解释UMI中的错误仍然是一个活跃的研究领域。我们认为解决上述问题的最佳方法是： UMI-tools 使用directional-adjacency方法，同时考虑错配数目和相似UMIs相对频率来识别可能的PCR/测序错误。 目前问题还没完全解决，通过删除很少reads支持的UMI-转录本对，或者移除multi-mapping reads可以减轻该问题。 简单饱和校正 (又称 “collision probability”) Grun, Kester and van Oudenaarden (2014) 估计真实的分子数目 \\(M\\): \\[M \\approx -N*log(1 - \\frac{n}{N})\\] 其中N=唯一UMI barcode的总数，n=观测barcode数目 该方法的一个重要缺陷是其假设所有UMI出现频率相同。大多数情况下并不是，因为GC含量不同引入偏差。 Figure 4.7: 基因扩增效率 如何最好地处理和使用UMI目前是生物信息学界的一个活跃的研究领域。最近开发的几种方法，包括： UMI-tools PoissonUMIs zUMIs dropEst 4.6.5 下游分析 目前UMI平台(DropSeq, InDrop, ICell8)捕获效率从低到高差异很大，如下图所示。 Figure 4.8: 捕获效率差异 这种差异引入强烈的偏差，需要在下游分析中考虑。最近的分析通常基于细胞类型或生物通路吧细胞/基因混合在一起增强检测能力。对这些数据的稳健统计分析仍然是一个开放的研究问题，还有待确定如何最好地调整偏差。 练习1 现提供三个不同来源的诱导多功能干细胞UMI counts和read counts数据 (Tung et al. 2017) (查看章节 7.1 获得更多关于此数据集的信息) umi_counts &lt;- read.table(&quot;data/tung/molecules.txt&quot;, sep = &quot;\\t&quot;) read_counts &lt;- read.table(&quot;data/tung/reads.txt&quot;, sep = &quot;\\t&quot;) 使用该数据: 绘制捕获效率可变性 确定扩增率：每个UMI的平均reads数目 Determine the amplification rate: average number of reads per UMI. 答案1 # Exercise 1 # Part 1 plot(colSums(umi_counts), colSums(umi_counts &gt; 0), xlab=&quot;Total Molecules Detected&quot;, ylab=&quot;Total Genes Detected&quot;) # Part 2 amp_rate &lt;- sum(read_counts)/sum(umi_counts) amp_rate ## [1] 30.87586 References "],
["intro-r-bioc.html", "5 R/Bioconductor介绍 5.1 安装R包 5.2 安装说明: 5.3 数据类型/类 5.4 基本数据结构 5.5 更多信息 5.6 数据类型 5.7 Bioconductor, SingleCellExperiment 和 scater 5.8 ggplot2介绍", " 5 R/Bioconductor介绍 5.1 安装R包 5.1.1 CRAN The Comprehensive R Archive Network CRAN 是最大的R包库。除了成功build和安装之外，对上传R包要求很少，因此文档和相关支持通常很少，弄清楚如何使用这些R包本身成为一个挑战。CRAN是R搜索安装R包的默认库： install.packages(&quot;devtools&quot;) require(&quot;devtools&quot;) 5.1.2 Github Github 并不特定于R，任何状态的任何类型的代码都可以上传。但无法保证上传到github的软件包可以安装，也不保证它声称做的事情。可以使用上述安装的“devtools”软件包直接从github下载和安装R软件包。 devtools::install_github(&quot;tallulandrews/M3Drop&quot;) Github同时也是一个版本控制系统，可以存储任何软件包的多个版本。默认情况下，会安装最新的“master”版本的软件包。如果您想使用旧版本或开发分支，可以使用“ref”参数指定： # different branch devtools::install_github(&quot;tallulandrews/M3D&quot;, ref=&quot;nbumi&quot;) # previous commit devtools::install_github(&quot;tallulandrews/M3Drop&quot;, ref=&quot;434d2da28254acc8de4940c1dc3907ac72973135&quot;) 注意: 确保重新安装M3Drop master分支以便后续课堂使用。 5.1.3 Bioconductor Bioconductor是专门用于生物分析的R包库。它对提交有最严格的要求，包括在各平台上安装，以及完整的文档和教程（称为vignette），解释如何使用包。Bioconductor还鼓励使用标准数据结构/类。 source(&quot;https://bioconductor.org/biocLite.R&quot;) biocLite(&quot;edgeR&quot;) 注意: 某些情况下有必要将上述的“http://” 替换为 “https://” ,这取决于网络连接的安全属性。 Bioconductor还要求作者维护他们的R包，并定期6个月发布更新。 在尝试安装课程所需R包之前，请确保使用最新版本的bioconductor。 source(&quot;https://bioconductor.org/biocLite.R&quot;) biocLite(&quot;BiocUpgrade&quot;) 5.1.4 源码安装 安装包的最后一种方法是直接从源码安装。 在这种情况下，必须下载完整构建的源代码文件，通常是packagename.tar.gz，或克隆github仓并重新build软件包。通常，只有在编辑包或者由于某种原因前一种方法失败时才会这样做。 install.packages(&quot;M3Drop_3.05.00.tar.gz&quot;, type=&quot;source&quot;) 5.2 安装说明: 本课程所需的所有软件包都可以在这里获得。从“RUN Rscript -e”install.packages(‘devtools’)\" “开始，在命令行或者R session运行引号内的命令(移除”RUN\")。注意，某些情况下安装顺序也很重要，请确保按顺序执行。 5.3 数据类型/类 R是一种高级语言，因此底层数据类型通常并不重要。 如果您使用其他语言（如C）直接访问R数据，则需要考虑，但这超出了本课程的范围。 相反，我们将考虑基本数据类型：数值(numeric)，整数(integer)，逻辑(logical)和字符(character)，以及高级数据类“因子”。 使用“class（）”函数检查数据的类型。 除此之外：R还可以将数据存储为“复数(complex)”，但通常这与生物分析无关。 5.3.1 数值 “数值”类型是存储任何数值数据的默认类 - 整数，十进制数，科学计数法中的数字等… x = 1.141 class(x) ## [1] &quot;numeric&quot; y = 42 class(y) ## [1] &quot;numeric&quot; z = 6.02e23 class(z) ## [1] &quot;numeric&quot; 即使R有一个“整数”类型，42可以更有效地存储为整数，默认是将其存储为“数值”类型。 如果我们想要将42存储为整数，我们必须强制类型转换： y = as.integer(42) class(y) ## [1] &quot;integer&quot; 强制R将数据存储为特定类，如果我们的数据与该类不兼容，它仍将执行此操作，但数据将转换为NA： as.numeric(&quot;H&quot;) ## Warning: 强制改变过程中产生了NA ## [1] NA 上述将“字符”数据强制转换为无意义的数值，因此触发（“抛出”）警告消息。 由于这只是一个警告信息，R将继续执行脚本/函数中的后续命令，而“错误”将导致R停止执行。 5.3.2 字符/字符串 “character”类型存储各种文本数据。 编程约定将包含多个字母的数据称为“字符串”，因此大多数作用于字符数据的R函数将数据称为“字符串”，并且通常在其名称中包含“str”或“string”。字符串通过双引号标识，而变量/函数名称则不是： x = 5 a = &quot;x&quot; # character &quot;x&quot; a ## [1] &quot;x&quot; b = x # variable x b ## [1] 5 除了标准的字母数字字符外，字符串还可以存储各种特殊字符。 特殊字符后跟单个字符进行标识，最常见的是tab的特殊字符：\\t和换行符：\\n。 为了演示这些特殊字符，用特殊字符将两个字符串连接起来： cat(&quot;Hello&quot;, &quot;World&quot;, sep= &quot; &quot;) ## Hello World cat(&quot;Hello&quot;, &quot;World&quot;, sep= &quot;\\t&quot;) ## Hello World cat(&quot;Hello&quot;, &quot;World&quot;, sep= &quot;\\n&quot;) ## Hello ## World 注意：特殊字符在不同函数中工作方式不同。比如paste函数和cat函数功能相同，但是不识别特殊字符。 paste(&quot;Hello&quot;, &quot;World&quot;, sep= &quot; &quot;) ## [1] &quot;Hello World&quot; paste(&quot;Hello&quot;, &quot;World&quot;, sep= &quot;\\t&quot;) ## [1] &quot;Hello\\tWorld&quot; paste(&quot;Hello&quot;, &quot;World&quot;, sep= &quot;\\n&quot;) ## [1] &quot;Hello\\nWorld&quot; 单反斜杠或双反斜杠也用作转义字符来关闭特殊字符功能或允许引号包含在字符串中： cat(&quot;This \\&quot;string\\&quot; contains quotation marks.&quot;) ## This &quot;string&quot; contains quotation marks. 特殊字符通常仅用于模式匹配，以及将数据读取/写入文件 例如，将tab分隔文件读入R。 dat = read.delim(&quot;file.tsv&quot;, sep=&quot;\\t&quot;) 另一种特殊类型的字符数据是颜色。 颜色可以通过三种主要方式指定：名字，使用rgb功能的红色，绿色，蓝色值以及使用hsv函数的色调，饱和度和亮度。 默认情况下，rgb和hsvs三个值在0-1之间，透明度可选的第四个值。或者，可以从许多不同的包中加载预定颜色组，其中RColorBrewer是最受欢迎的一种。 reds = c(&quot;red&quot;, rgb(1,0,0), hsv(0, 1, 1)) reds ## [1] &quot;red&quot; &quot;#FF0000&quot; &quot;#FF0000&quot; barplot(c(1,1,1), col=reds, names=c(&quot;by_name&quot;, &quot;by_rgb&quot;, &quot;by_hsv&quot;)) 5.3.3 逻辑值 logical类型存储布尔值，即TRUE和FALSE。它用于存储逻辑运算的结果，条件语句将被强制转换为此类。 大多数其他数据类型可以强制转换为布尔值而不会触发（或“抛出”）错误消息，但这可能会导致意料之外的情况。 x = TRUE class(x) ## [1] &quot;logical&quot; y = &quot;T&quot; as.logical(y) ## [1] TRUE z = 5 as.logical(z) ## [1] TRUE x = FALSE class(x) ## [1] &quot;logical&quot; y = &quot;F&quot; as.logical(y) ## [1] FALSE z = 0 as.logical(z) ## [1] FALSE 练习1 试验其他字符和数值，其中哪些被强制为TRUE或FALSE？哪些都不是？ 有没有抛出警告/错误信息？ 5.3.4 因子 字符串/字符数据存储效率非常低，每个字母通常需要与整数相同的内存。 因此，当存储具有重复元素的字符串向量时，更有效的方式是将每个元素分配给整数，将向量存储为整数和字符串到整数关联表。 因此，默认情况下，R将读取数据表的文本列作为因子。 str_vector = c(&quot;Apple&quot;, &quot;Apple&quot;, &quot;Banana&quot;, &quot;Banana&quot;, &quot;Banana&quot;, &quot;Carrot&quot;, &quot;Carrot&quot;, &quot;Apple&quot;, &quot;Banana&quot;) factored_vector = factor(str_vector) factored_vector ## [1] Apple Apple Banana Banana Banana Carrot Carrot Apple Banana ## Levels: Apple Banana Carrot as.numeric(factored_vector) ## [1] 1 1 2 2 2 3 3 1 2 因子的双重性质可能导致一些不直观的行为。例如，连接两个因子会将它们转换为数字形式，丢失原始字符串。 c(factored_vector, factored_vector) ## [1] 1 1 2 2 2 3 3 1 2 1 1 2 2 2 3 3 1 2 同样，如果由于格式化问题，数值数据被错误地解释为字符串，那么在强制转换为数值之前必须将因子转换回字符串： x = c(&quot;20&quot;, &quot;25&quot;, &quot;23&quot;, &quot;38&quot;, &quot;20&quot;, &quot;40&quot;, &quot;25&quot;, &quot;30&quot;) x = factor(x) as.numeric(x) ## [1] 1 3 2 5 1 6 3 4 as.numeric(as.character(x)) ## [1] 20 25 23 38 20 40 25 30 要使R读取文本作为字符数据而不是因子，在每个R会话开始s时，设置环境选项stringsAsFactors = FALSE。 options(stringsAsFactors=FALSE) 练习 使用因子为任意长的水果矢量创建一个颜色矢量，如上面的’str_vector`？ 答案 long_str_vector = c(str_vector, str_vector, str_vector) fruit_cols = c(&quot;red&quot;, &quot;yellow&quot;, &quot;orange&quot;) fruit_colour_vec = fruit_cols[as.numeric(factor(long_str_vector, levels=c(&quot;Apple&quot;, &quot;Banana&quot;, &quot;Carrot&quot;)))] 5.3.5 检查数据类型 建议在读取文件后检查数类型据是否正确： x = 1.4 is.numeric(x) ## [1] TRUE is.character(x) ## [1] FALSE is.logical(x) ## [1] FALSE is.factor(x) ## [1] FALSE 5.4 基本数据结构 到目前为止，我们只关注单个值和向量。向量是R中最简单的数据结构。它们是所有相同类型数据的一维数组。 如果创建向量时的输入具有不同类型，则它将被强制转换为与数据最一致的数据类型。 x = c(&quot;Hello&quot;, 5, TRUE) x ## [1] &quot;Hello&quot; &quot;5&quot; &quot;TRUE&quot; class(x) ## [1] &quot;character&quot; 在这里，尝试将字符，数值和逻辑数据放入单个向量中，所有值强制转换为character数据。 矩阵是二维向量，它也要求所有数据都是相同的类型。 如果将字符向量和数字向量组合成矩阵，所有数据都将被强制转换为字符类型： x = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;) y = c(1, 2, 3) class(x) ## [1] &quot;character&quot; class(y) ## [1] &quot;numeric&quot; m = cbind(x, y) m ## x y ## [1,] &quot;A&quot; &quot;1&quot; ## [2,] &quot;B&quot; &quot;2&quot; ## [3,] &quot;C&quot; &quot;3&quot; 引号表示数字向量已被强制转换为字符类型。或者，使用数据框用不同数据类型的列存储数据。 z = data.frame(x, y) z ## x y ## 1 A 1 ## 2 B 2 ## 3 C 3 class(z[,1]) ## [1] &quot;character&quot; class(z[,2]) ## [1] &quot;numeric&quot; 如果已经设置stringsAsFactors = FALSE，会发现第一列仍然是字类型符，否则它将自动转换为因子。 options(stringsAsFactors=TRUE) z = data.frame(x, y) class(z[,1]) ## [1] &quot;factor&quot; 矩阵和数据框之间的另一个区别是能够使用$运算符选择列： m$x # throws an error z$x # ok 最后的基本数据结构是list。列表允许将不同类型和不同长度的数据存储在单个对象中。 列表的每个元素可以是任何其他R对象：任何类型的数据，任何数据结构，甚至其他列表或函数。 l = list(m, z) ll = list(sublist=l, a_matrix=m, numeric_value=42, this_string=&quot;Hello World&quot;, even_a_function=cbind) ll ## $sublist ## $sublist[[1]] ## x y ## [1,] &quot;A&quot; &quot;1&quot; ## [2,] &quot;B&quot; &quot;2&quot; ## [3,] &quot;C&quot; &quot;3&quot; ## ## $sublist[[2]] ## x y ## 1 A 1 ## 2 B 2 ## 3 C 3 ## ## ## $a_matrix ## x y ## [1,] &quot;A&quot; &quot;1&quot; ## [2,] &quot;B&quot; &quot;2&quot; ## [3,] &quot;C&quot; &quot;3&quot; ## ## $numeric_value ## [1] 42 ## ## $this_string ## [1] &quot;Hello World&quot; ## ## $even_a_function ## function (..., deparse.level = 1) ## .Internal(cbind(deparse.level, ...)) ## &lt;bytecode: 0x00000000082cc0a8&gt; ## &lt;environment: namespace:base&gt; 列表最常用于从不适合任何先前数据结构的函数返回大量结果时。 5.5 更多信息 通过在交互式会话中键入?function，可以获得这些数据类型相关的R命令的更多信息。 5.6 数据类型 5.6.1 什么是整洁的数据 整洁的数据主要是Hadley Wickham (Wickham 2014)定义的概念。整洁的数据具有以下三个特征： 每个变量都有自己的列; 每个观测都有自己的行; 每个值都有自己的单元格。 以下是一些整洁数据的示例： ## Students Subject Years Score ## 1 Mark Maths 1 5 ## 2 Jane Biology 2 6 ## 3 Mohammed Physics 3 4 ## 4 Tom Maths 2 7 ## 5 Celia Computing 3 9 以下是一些不整洁数据的示例： ## Students Sport Category Counts ## 1 Matt Tennis Wins 0 ## 2 Matt Tennis Losses 1 ## 3 Ellie Rugby Wins 3 ## 4 Ellie Rugby Losses 2 ## 5 Tim Football Wins 1 ## 6 Tim Football Losses 4 ## 7 Louise Swimming Wins 2 ## 8 Louise Swimming Losses 2 ## 9 Kelly Running Wins 5 ## 10 Kelly Running Losses 1 任务1：不整洁的数据在哪些方面不整洁？ z怎么整理数据？ 整洁的数据通常比不整齐的数据更容易使用，特别是使用ggplot等软件包。 幸运的是，可以使用软件包来整理不整洁的数据。 今天将探讨tidyr包中一些整理数据的函数。如果有兴趣了解有关整理数据的更多信息，建议阅读Garrett Grolemund和Hadley Wickham撰写的“R for Data Science”。 电子版可在此处获取：http://r4ds.had.co.nz/ 上面不整洁的数据因为两个变量（Wins和Lossses）存储在一列（Category）中。这是数据不整洁的常见方式。 为了整理这些数据，我们需要将Wins和Lossses分成两列，并将Counts中的值拆分到这两列。 幸运的是，tidyverse包中有一个函数来执行此操作。spread有两个参数，key和value。 将包含多个变量的列的名称传递给key，并将包含多个变量值的列的名称传递给value。 例如： library(tidyverse) sports&lt;-data.frame(Students=c(&quot;Matt&quot;, &quot;Matt&quot;, &quot;Ellie&quot;, &quot;Ellie&quot;, &quot;Tim&quot;, &quot;Tim&quot;, &quot;Louise&quot;, &quot;Louise&quot;, &quot;Kelly&quot;, &quot;Kelly&quot;), Sport=c(&quot;Tennis&quot;,&quot;Tennis&quot;, &quot;Rugby&quot;, &quot;Rugby&quot;,&quot;Football&quot;, &quot;Football&quot;,&quot;Swimming&quot;,&quot;Swimming&quot;, &quot;Running&quot;, &quot;Running&quot;), Category=c(&quot;Wins&quot;, &quot;Losses&quot;, &quot;Wins&quot;, &quot;Losses&quot;, &quot;Wins&quot;, &quot;Losses&quot;, &quot;Wins&quot;, &quot;Losses&quot;, &quot;Wins&quot;, &quot;Losses&quot;), Counts=c(0,1,3,2,1,4,2,2,5,1)) sports ## Students Sport Category Counts ## 1 Matt Tennis Wins 0 ## 2 Matt Tennis Losses 1 ## 3 Ellie Rugby Wins 3 ## 4 Ellie Rugby Losses 2 ## 5 Tim Football Wins 1 ## 6 Tim Football Losses 4 ## 7 Louise Swimming Wins 2 ## 8 Louise Swimming Losses 2 ## 9 Kelly Running Wins 5 ## 10 Kelly Running Losses 1 spread(sports, key=Category, value=Counts) ## Students Sport Losses Wins ## 1 Ellie Rugby 2 3 ## 2 Kelly Running 1 5 ## 3 Louise Swimming 2 2 ## 4 Matt Tennis 1 0 ## 5 Tim Football 4 1 任务2：下面定义的数据框foods不是整洁的数据，找出不整洁的原因并用spread()整理数据。 foods&lt;-data.frame(student=c(&quot;Antoinette&quot;,&quot;Antoinette&quot;,&quot;Taylor&quot;, &quot;Taylor&quot;, &quot;Alexa&quot;, &quot;Alexa&quot;), Category=c(&quot;Dinner&quot;, &quot;Dessert&quot;, &quot;Dinner&quot;, &quot;Dessert&quot;, &quot;Dinner&quot;,&quot;Dessert&quot;), Frequency=c(3,1,4,5,2,1)) 数据不整洁的另一种常见方式为列是值而不是变量。例如，下面的数据框显示了一些学生在5月和6月的测试中获得的分数。 数据不整洁，因为“May”和“June”列是值，而不是变量。 percentages&lt;-data.frame(student=c(&quot;Alejandro&quot;, &quot;Pietro&quot;, &quot;Jane&quot;), &quot;May&quot;=c(90,12,45), &quot;June&quot;=c(80,30,100)) tidyverse包中有一个函数来处理这种问题。gather()获取列为值的名称，key和value作为参数。 key是变量的名称，值为列名，value是变量的名称，其值分布在多个列上。即： gather(percentages, &quot;May&quot;, &quot;June&quot;, key=&quot;Month&quot;, value = &quot;Percentage&quot;) ## student Month Percentage ## 1 Alejandro May 90 ## 2 Pietro May 12 ## 3 Jane May 45 ## 4 Alejandro June 80 ## 5 Pietro June 30 ## 6 Jane June 100 这些例子与scRNA-seq分析没有多大关系，但旨在帮助说明整洁和不整洁数据的特征。 如果数据以整齐的格式存储，会发现分析单细胞RNA-seq数据要容易得多。通常鼓励以整齐的方式存储数据促进单细胞RNA-seq分析。 5.6.2 什么是Rich data? 如果你谷歌“Rich datga”，会发现这个术语有很多不同的定义。在本课程中，我们将使用“Rich data”来表示通过整合多个来源的信息生成的数据。例如，在R中创建一个对象来生成Rich data，该对象包含scRNA-seq实验中细胞的基因表达矩阵，还有关于如何进行实验的信息。 下面讨论的SingleCellExperiment类的对象是Rich data的一个例子。 5.7 Bioconductor, SingleCellExperiment 和 scater 5.7.1 Bioconductor 来自Wikipedia: Bioconductor是一个免费的，开源的开放式开发软件项目，用于分析和理解湿实验室产生的基因组数据。Bioconductor主要基于统计R编程语言，但也包含其他编程语言的贡献。 它每年有两个版本，伴随R的半年一个版本。在任何时候都存在一个发布版本，它对应于R的发布版本，以及一个开发版本，它对应于R的开发版本。大多数用户可以找到适合他们需求的发布版本。 我们强烈建议所有新成员，甚至经验丰富的高通量数据分析师使用Bioconductor方法和类。 5.7.2 SingleCellExperiment 类 SingleCellExperiment(SCE)是用于存储单细胞实验数据的S4类。 这包括存储和检索spike-in信息，细胞的降维坐标和尺寸因子，以及基因和文库的常用元数据。 可以使用其构造函数创建此类的对象： library(SingleCellExperiment) counts &lt;- matrix(rpois(100, lambda = 10), ncol=10, nrow=10) rownames(counts) &lt;- paste(&quot;gene&quot;, 1:10, sep = &quot;&quot;) colnames(counts) &lt;- paste(&quot;cell&quot;, 1:10, sep = &quot;&quot;) sce &lt;- SingleCellExperiment( assays = list(counts = counts), rowData = data.frame(gene_names = paste(&quot;gene_name&quot;, 1:10, sep = &quot;&quot;)), colData = data.frame(cell_names = paste(&quot;cell_name&quot;, 1:10, sep = &quot;&quot;)) ) sce ## class: SingleCellExperiment ## dim: 10 10 ## metadata(0): ## assays(1): counts ## rownames(10): gene1 gene2 ... gene9 gene10 ## rowData names(1): gene_names ## colnames(10): cell1 cell2 ... cell9 cell10 ## colData names(1): cell_names ## reducedDimNames(0): ## spikeNames(0): SingleCellExperiment中, 用户可以为实验条目指定任意名称。 为了协助软件包之间的互操作性，作者提供了针对特定类型数据的名称的一些建议： counts: 原始count数据，比如特定基因或转录本的reads数目; normcounts: 标准化的值与原始counts具有相同的尺度。比如，counts除以细胞特异尺寸因子; logcounts: 对数转换counts或类似counts的值。在大多数情况下，这被定义为对数转换的标准值，例如使用log2(count+1); cpm: Counts-per-million，\\(CPM=A*10^6/mappedreads\\), A为比对到某基因的reads数（read count）; tpm: Transcripts-per-million。\\(TPM_i=(N_i/L_i)*10^6/sum(N_i/L_i+……..+ N_m/L_m)\\). Ni：mapping到基因i上的read数； Li：基因i的外显子长度的总和. 上述建议命名都有其getter/setter方法，方便操作SingleCellExperiment。比如，可以将counts标准化并赋值给normcounts： normcounts(sce) &lt;- log2(counts(sce) + 1) sce ## class: SingleCellExperiment ## dim: 10 10 ## metadata(0): ## assays(2): counts normcounts ## rownames(10): gene1 gene2 ... gene9 gene10 ## rowData names(1): gene_names ## colnames(10): cell1 cell2 ... cell9 cell10 ## colData names(1): cell_names ## reducedDimNames(0): ## spikeNames(0): dim(normcounts(sce)) ## [1] 10 10 head(normcounts(sce)) ## cell1 cell2 cell3 cell4 cell5 cell6 cell7 ## gene1 3.169925 3.169925 2.000000 2.584963 2.584963 3.321928 3.584963 ## gene2 3.459432 1.584963 3.584963 3.807355 3.700440 3.700440 3.000000 ## gene3 3.000000 3.169925 3.807355 3.169925 3.321928 3.321928 3.321928 ## gene4 3.584963 3.459432 3.000000 3.807355 3.700440 3.700440 3.700440 ## gene5 3.906891 3.000000 3.169925 3.321928 3.584963 3.459432 3.807355 ## gene6 3.700440 3.700440 3.584963 4.000000 3.169925 3.000000 3.459432 ## cell8 cell9 cell10 ## gene1 3.321928 3.807355 2.807355 ## gene2 3.807355 3.700440 4.000000 ## gene3 2.584963 4.000000 3.700440 ## gene4 3.169925 3.584963 3.700440 ## gene5 3.807355 2.584963 3.584963 ## gene6 3.321928 3.459432 4.000000 5.7.3 scater 包 scater是用于scRNA-seq分析的R包(McCarthy et al. 2017)。 其包括下游分析前的质量控制，可视化和预处理等方法。 scater具有以下功能： 自动计算QC指标 定量来自pseudo-alignment read数据转录本 数据格式标准化 丰富的探索性分析可视化 无缝集成到Bioconductor环境 简单的规范化方法 建议对所有scRNA-seq分析使用scater，而scater是课程第一部分的基础。 如下图所示，scater在比对后对表达矩阵进行质量控制，过滤和标准化。注意，此图为scater的原始版本，其中使用SCESet类。 在最新版本中，该图仍然适用，除了SCESet用SingleCellExperiment替代。&lt;/ span&gt; 5.8 ggplot2介绍 5.8.1 ggplot2是什么? ggplot2是由Hadley Wickham开发用于数据绘图的R软件包。在本实验中，我们将简要介绍该软件包的一些功能。 如果想了解更多关于如何使用ggplot2的信息，建议阅读Hadley Wickham撰写的“ggplot2 Elegant graphics for data analysis”。 5.8.2 ggplot2j原则 ggplot2数据类型为数据框(dataframe) 使用aes映射函数指定数据框中的变量如何映射到绘图上的要素 使用geoms指定数据在图表中的表示方式，例如，散点图，条形图，箱形图等。 5.8.3 使用aes映射函数 aes函数指定数据框中的变量如何映射到绘图上的元素。了解其工作原理，先看一个例子： library(ggplot2) library(tidyverse) set.seed(1) counts &lt;- as.data.frame(matrix(rpois(100, lambda = 10), ncol=10, nrow=10)) Gene_ids &lt;- paste(&quot;gene&quot;, 1:10, sep = &quot;&quot;) colnames(counts) &lt;- paste(&quot;cell&quot;, 1:10, sep = &quot;&quot;) counts&lt;-data.frame(Gene_ids, counts) counts ## Gene_ids cell1 cell2 cell3 cell4 cell5 cell6 cell7 cell8 cell9 cell10 ## 1 gene1 8 8 3 5 5 9 11 9 13 6 ## 2 gene2 10 2 11 13 12 12 7 13 12 15 ## 3 gene3 7 8 13 8 9 9 9 5 15 12 ## 4 gene4 11 10 7 13 12 12 12 8 11 12 ## 5 gene5 14 7 8 9 11 10 13 13 5 11 ## 6 gene6 12 12 11 15 8 7 10 9 10 15 ## 7 gene7 11 11 14 11 11 5 9 13 13 7 ## 8 gene8 9 12 9 8 6 14 7 12 12 10 ## 9 gene9 14 12 11 7 10 10 8 14 7 10 ## 10 gene10 11 10 9 7 11 16 8 7 7 4 ggplot(data = counts, mapping = aes(x = cell1, y = cell2)) 最后一条命令，ggplot(data = counts，mapping = aes(x = cell1，y = cell2))，ggplot()初始化一个ggplot对象并接受参数data和mapping。 将counts数据框传递给data并使用aes()函数来指定将变量cell1用作x变量而将变量cell2用作y变量。 任务1：修改上述命令，初始化ggplot对象，其中cell10是x变量，cell8是y变量。 然而刚刚创建的图表信息量不大，因为它们上没有显示数据。要显示数据，我们需要使用geoms。 5.8.4 Geoms 使用geoms来指定希望数据在图表上显示的方式。例如，可以指定数据显示为散点图，条形图或箱形图。 下面是一个散点图的例子 ggplot(data = counts, mapping = aes(x = cell1, y = cell2)) + geom_point() 可以看到，cell1和cell2中的基因表达之间似乎没有任何相关性。鉴于counts为随机生成数据，这并不令人奇怪。 任务2：修改上述命令创建折线图。提示：执行?ggplot查看帮助页面。底部是ggplot包索引的链接，滚动索引，直到找到geom选项。 5.8.5 绘制2个以上细胞的数据 到目前为止，我们一直在考虑数据框中2个细胞的基因counts。但是实际上数据框中有10个细胞，最好同时比较所有这些细胞的gene count会。如果同时绘制来自所有10个细胞的数据怎么办？ 目前不能这样做，因为将每个单独的细胞视为变量并将该变量分配给x轴或y轴。 可以创建一个10维图来绘制来自所有10个细胞的数据，但这a)不能用ggplot实现和b)不容易解释。 可以整理数据，使用表示细胞ID的变量和表示基因counts的变量。 counts&lt;-gather(counts, colnames(counts)[2:11], key = &#39;Cell_ID&#39;, value=&#39;Counts&#39;) head(counts) ## Gene_ids Cell_ID Counts ## 1 gene1 cell1 8 ## 2 gene2 cell1 10 ## 3 gene3 cell1 7 ## 4 gene4 cell1 11 ## 5 gene5 cell1 14 ## 6 gene6 cell1 12 基本上，之前的问题是数据不整洁，变量（Cell_ID）分布在多列上。 现在解决了这个问题，更容易在一个图上绘制来自所有10个单元格的数据。 ggplot(counts,aes(x=Cell_ID, y=Counts)) + geom_boxplot() 任务3：使用更新的counts数据框绘制条形图，其中Cell_ID为x变量，Counts为y变量。 提示：?geom_bar查看帮助文档。 任务4：使用更新的counts数据框绘制散点图，其中Gene_ids为x变量，Counts为y变量。 5.8.6 绘制热图 可视化基因表达数据的常用方法是使用热图，这里使用R包pheatmap来进行分析。 library(pheatmap) set.seed(2) test = matrix(rnorm(200), 20, 10) test[1:10, seq(1, 10, 2)] = test[1:10, seq(1, 10, 2)] + 3 test[11:20, seq(2, 10, 2)] = test[11:20, seq(2, 10, 2)] + 2 test[15:20, seq(2, 10, 2)] = test[15:20, seq(2, 10, 2)] + 4 colnames(test) = paste(&quot;Cell&quot;, 1:10, sep = &quot;&quot;) rownames(test) = paste(&quot;Gene&quot;, 1:20, sep = &quot;&quot;) pheatmap(test) 上面热图每行代表一个基因，每列代表一个细胞。细胞中基因表达量用相应框的颜色表示。 例如，从该图中看出，基因18在细胞10中高表达，但在细胞1中低表达。 该图还提供了聚类结果的信息。通常，聚类算法旨在将数据点(比如细胞)拆分成cluster，其中cluster中点的相似性比cluster间的点相似性高。在图的顶部和左侧为层次聚类结果，可以看出，细胞4,8,2,6和10彼此更相似。 pheatmap(test, kmeans_k = 2) 现在可以看到这些基因分为两个簇 - Cluster1中8个基因在细胞2,10,6,4和8表达上调，Cluster2中12个基因在细胞2,10,6,4,8中表达下调。 任务5：将cluster数量设置为3.哪个cluster数目提供更多有用信息？ 5.8.7 主成分分析 主成分分析（PCA）是一种统计方法，使用变换将一组观察值转换为一组线性不相关变量值，称之为主成分。 变换使得第一主成分解释最大数据的变异，并且每个后续主成分在与之前主成分正交的约束下解释最大方差。 PCA图可以很好地对数据进行概览，有时可以帮助识别解释数据变异的干扰因子。 在将来的实验中我们将研究如何更深入地使用单细胞RNA-seq分析中的PCA图，这里的目的是概述PCA图以及如何生成。 为test数据生成PCA图，使用ggfortify包让ggplot解释主成分。 library(ggfortify) Principal_Components&lt;-prcomp(test) autoplot(Principal_Components, label=TRUE) 任务6：将Cluster与pheatmap的Cluster进行比较。它们有关系吗？（提示：绘制的第一个pheatmap的基因树） 任务7：为counts生成热图和PCA图： set.seed(1) counts &lt;- as.data.frame(matrix(rpois(100, lambda = 10), ncol=10, nrow=10)) rownames(counts) &lt;- paste(&quot;gene&quot;, 1:10, sep = &quot;&quot;) colnames(counts) &lt;- paste(&quot;cell&quot;, 1:10, sep = &quot;&quot;) References "],
["tabula-muris.html", "6 Tabula Muris 6.1 介绍 6.2 下载数据 6.3 读取Smartseq2数据 6.4 构建scater对象 6.5 读取10X数据 6.6 创建scater对象 6.7 进阶练习", " 6 Tabula Muris 6.1 介绍 为了提供完整分析scRNA-seq数据的体验，我们以Tabula Muris初始发布的数据为例。Tabula Muris是旨在使用标准化方法分析小鼠细胞类型的国际合作项目。其结合高通量但低覆盖率的10X数据和低通量但高覆盖率FACS分选细胞+ Smartseq2. 最初发布的数据（2017年12月20日）包含20个不同组织/器官的近100,000个细胞。 6.2 下载数据 和大多数scRNA-seq数据不同，Tabula Muris在figshare上发布其数据，而不是上传到GEO或ArrayExpress。使用他们文章中doi获取数据：10.6084/m9.figshare.5715040 FACS/Smartseq2数据，10.6084/m9.figshare.5715025 10X数据。可以通过手动点击doi链接下载或者通过下面的命令: 基于终端的FACS数据下载: wget https://ndownloader.figshare.com/files/10038307 unzip 10038307 wget https://ndownloader.figshare.com/files/10038310 mv 10038310 FACS_metadata.csv wget https://ndownloader.figshare.com/files/10039267 mv 10039267 FACS_annotations.csv 基于终端的10X数据下载：: wget https://ndownloader.figshare.com/files/10038325 unzip 10038325 wget https://ndownloader.figshare.com/files/10038328 mv 10038328 droplet_metadata.csv wget https://ndownloader.figshare.com/files/10039264 mv 10039264 droplet_annotation.csv 注意，如果手动下载数据，则应在继续之前解压缩并重命名文件。 现在应该有两个文件夹：“FACS”和“Droplet”文件夹，以及各自一个注释和元数据文件。使用head查看文本文件的前几行（按q退出）： head -n 10 data/droplet/droplet_metadata.csv 使用wc查看文件行数： wc -l data/droplet/droplet_annotation.csv 练习 我们从FACS和10X注释了多少个细胞？ 答案 wc -l FACS_annotations.csv wc -l droplet_annotation.csv #FACS : 54,838 cells #Droplet : 42,193 cells 6.3 读取Smartseq2数据 从逗号分隔文件中读取相应的的count矩阵。然后检查结果数据框： dat = read.delim(&quot;data/FACS/Kidney-counts.csv&quot;, sep=&quot;,&quot;, header=TRUE) dat[1:5,1:5] ## X A14.MAA000545.3_8_M.1.1 E1.MAA000545.3_8_M.1.1 ## 1 0610005C13Rik 0 0 ## 2 0610007C21Rik 1 0 ## 3 0610007L01Rik 0 0 ## 4 0610007N19Rik 0 0 ## 5 0610007P08Rik 0 0 ## M4.MAA000545.3_8_M.1.1 O21.MAA000545.3_8_M.1.1 ## 1 0 0 ## 2 0 0 ## 3 0 0 ## 4 0 0 ## 5 0 0 数据框中的第一列是基因，将数据框rownames重命名为基因名 dim(dat) ## [1] 23433 866 rownames(dat) &lt;- dat[,1] dat &lt;- dat[,-1] 由于这是一个Smartseq2数据集，它可能包含spike-ins，通过下述命令检查数据集： rownames(dat)[grep(&quot;^ERCC-&quot;, rownames(dat))] ## [1] &quot;ERCC-00002&quot; &quot;ERCC-00003&quot; &quot;ERCC-00004&quot; &quot;ERCC-00009&quot; &quot;ERCC-00012&quot; ## [6] &quot;ERCC-00013&quot; &quot;ERCC-00014&quot; &quot;ERCC-00016&quot; &quot;ERCC-00017&quot; &quot;ERCC-00019&quot; ## [11] &quot;ERCC-00022&quot; &quot;ERCC-00024&quot; &quot;ERCC-00025&quot; &quot;ERCC-00028&quot; &quot;ERCC-00031&quot; ## [16] &quot;ERCC-00033&quot; &quot;ERCC-00034&quot; &quot;ERCC-00035&quot; &quot;ERCC-00039&quot; &quot;ERCC-00040&quot; ## [21] &quot;ERCC-00041&quot; &quot;ERCC-00042&quot; &quot;ERCC-00043&quot; &quot;ERCC-00044&quot; &quot;ERCC-00046&quot; ## [26] &quot;ERCC-00048&quot; &quot;ERCC-00051&quot; &quot;ERCC-00053&quot; &quot;ERCC-00054&quot; &quot;ERCC-00057&quot; ## [31] &quot;ERCC-00058&quot; &quot;ERCC-00059&quot; &quot;ERCC-00060&quot; &quot;ERCC-00061&quot; &quot;ERCC-00062&quot; ## [36] &quot;ERCC-00067&quot; &quot;ERCC-00069&quot; &quot;ERCC-00071&quot; &quot;ERCC-00073&quot; &quot;ERCC-00074&quot; ## [41] &quot;ERCC-00075&quot; &quot;ERCC-00076&quot; &quot;ERCC-00077&quot; &quot;ERCC-00078&quot; &quot;ERCC-00079&quot; ## [46] &quot;ERCC-00081&quot; &quot;ERCC-00083&quot; &quot;ERCC-00084&quot; &quot;ERCC-00085&quot; &quot;ERCC-00086&quot; ## [51] &quot;ERCC-00092&quot; &quot;ERCC-00095&quot; &quot;ERCC-00096&quot; &quot;ERCC-00097&quot; &quot;ERCC-00098&quot; ## [56] &quot;ERCC-00099&quot; &quot;ERCC-00104&quot; &quot;ERCC-00108&quot; &quot;ERCC-00109&quot; &quot;ERCC-00111&quot; ## [61] &quot;ERCC-00112&quot; &quot;ERCC-00113&quot; &quot;ERCC-00116&quot; &quot;ERCC-00117&quot; &quot;ERCC-00120&quot; ## [66] &quot;ERCC-00123&quot; &quot;ERCC-00126&quot; &quot;ERCC-00130&quot; &quot;ERCC-00131&quot; &quot;ERCC-00134&quot; ## [71] &quot;ERCC-00136&quot; &quot;ERCC-00137&quot; &quot;ERCC-00138&quot; &quot;ERCC-00142&quot; &quot;ERCC-00143&quot; ## [76] &quot;ERCC-00144&quot; &quot;ERCC-00145&quot; &quot;ERCC-00147&quot; &quot;ERCC-00148&quot; &quot;ERCC-00150&quot; ## [81] &quot;ERCC-00154&quot; &quot;ERCC-00156&quot; &quot;ERCC-00157&quot; &quot;ERCC-00158&quot; &quot;ERCC-00160&quot; ## [86] &quot;ERCC-00162&quot; &quot;ERCC-00163&quot; &quot;ERCC-00164&quot; &quot;ERCC-00165&quot; &quot;ERCC-00168&quot; ## [91] &quot;ERCC-00170&quot; &quot;ERCC-00171&quot; 从列名中提取这些数据的元数据： cellIDs &lt;- colnames(dat) cell_info &lt;- strsplit(cellIDs, &quot;\\\\.&quot;) Well &lt;- lapply(cell_info, function(x){x[1]}) Well &lt;- unlist(Well) Plate &lt;- unlist(lapply(cell_info, function(x){x[2]})) Mouse &lt;- unlist(lapply(cell_info, function(x){x[3]})) 查看元数据的分布信息 summary(factor(Mouse)) ## 3_10_M 3_11_M 3_38_F 3_39_F 3_8_M 3_9_M ## 104 196 237 169 82 77 检查是否有任何技术因素混淆： table(Mouse, Plate) ## Plate ## Mouse B001717 B002775 MAA000545 MAA000752 MAA000801 MAA000922 ## 3_10_M 0 0 0 104 0 0 ## 3_11_M 0 0 0 0 196 0 ## 3_38_F 237 0 0 0 0 0 ## 3_39_F 0 169 0 0 0 0 ## 3_8_M 0 0 82 0 0 0 ## 3_9_M 0 0 0 0 0 77 最后，读取计算推测的细胞类型注释，并与表达矩阵中的细胞进行匹配： ann &lt;- read.table(&quot;data/FACS/FACS_annotations.csv&quot;, sep=&quot;,&quot;, header=TRUE) ann &lt;- ann[match(cellIDs, ann[,1]),] celltype &lt;- ann[,3] 6.4 构建scater对象 要创建SingleCellExperiment对象，必须将所有细胞注释放在一个数据框中，因为实验批处理（pcr板）与供体鼠标完全混淆，我们只保留其中一个。 library(&quot;SingleCellExperiment&quot;) library(&quot;scater&quot;) cell_anns &lt;- data.frame(mouse = Mouse, well=Well, type=celltype) rownames(cell_anns) &lt;- colnames(dat) sceset &lt;- SingleCellExperiment(assays = list(counts = as.matrix(dat)), colData=cell_anns) 如果数据集包含spike-ins，在SingleCellExperiment对象中设置一个隐藏变量来跟踪它们： isSpike(sceset, &quot;ERCC&quot;) &lt;- grepl(&quot;ERCC-&quot;, rownames(sceset)) 6.5 读取10X数据 由于10X数据的大规模和稀疏性（表达矩阵中高达90％可能是0），它通常存储为稀疏矩阵。 CellRanger的默认输出格式是.mtx文件，将稀疏矩阵存储为一列行坐标,一列列坐标，一列&gt;0的表达值。注意，如果查看.mtx文件，发现两行标题行后紧跟一行，其详细说明完整矩阵的行数，列数和计数。由于只有坐标存储在.mtx文件中，因此每行和列的名称必须分别存储在“genes.tsv”和“barcodes.tsv”文件中。 使用“Matrix”包读取稀疏矩阵。 library(&quot;Matrix&quot;) cellbarcodes &lt;- read.table(&quot;data/droplet/Kidney-10X_P4_5/barcodes.tsv&quot;) genenames &lt;- read.table(&quot;data/droplet/Kidney-10X_P4_5/genes.tsv&quot;) molecules &lt;- readMM(&quot;data/droplet/Kidney-10X_P4_5/matrix.mtx&quot;) 添加适当的行名和列名。查看read的cellbarcode，发现只有与每个细胞相关的barcode序列。考虑到10X数据每一批的cellbarcodes序列可能有重复，因此在合并数据前将批次ID与cellbarcode合并。 head(cellbarcodes) ## V1 ## 1 AAACCTGAGATGCCAG-1 ## 2 AAACCTGAGTGTCCAT-1 ## 3 AAACCTGCAAGGCTCC-1 ## 4 AAACCTGTCCTTGCCA-1 ## 5 AAACGGGAGCTGAACG-1 ## 6 AAACGGGCAGGACCCT-1 rownames(molecules) &lt;- genenames[,1] colnames(molecules) &lt;- paste(&quot;10X_P4_5&quot;, cellbarcodes[,1], sep=&quot;_&quot;) 读入元数据和计算注释信息。 meta &lt;- read.delim(&quot;data/droplet/droplet_metadata.csv&quot;, sep=&quot;,&quot;, header = TRUE) head(meta) ## channel mouse.id tissue subtissue mouse.sex ## 1 10X_P4_0 3-M-8 Tongue &lt;NA&gt; M ## 2 10X_P4_1 3-M-9 Tongue &lt;NA&gt; M ## 3 10X_P4_2 3-M-8/9 Liver hepatocytes M ## 4 10X_P4_3 3-M-8 Bladder &lt;NA&gt; M ## 5 10X_P4_4 3-M-9 Bladder &lt;NA&gt; M ## 6 10X_P4_5 3-M-8 Kidney &lt;NA&gt; M 需要用“10X_P4_5”获得这批数据的meta信息，注意到metadata表格中mouse ID和FACS数据集中mouse ID不同，这里用“-”而不是\"_\"作为分隔符，而且性别位于ID的中间。通过查阅文献得知，droplet和FACS技术使用相同的8只小鼠，所以修改小鼠ID，与FACS实验保持一致。 meta[meta$channel == &quot;10X_P4_5&quot;,] ## channel mouse.id tissue subtissue mouse.sex ## 6 10X_P4_5 3-M-8 Kidney &lt;NA&gt; M mouseID &lt;- &quot;3_8_M&quot; 注意：有些组织的10X数据可能来自混合样本，比如mouse id = 3-M-5/6。仍然需要格式化mouse id，但是可能与FACS数据的mouse id不一致，影响下游分析。如果小鼠不是来自近交系，那么可以使用exonic-SNP将每个细胞分配给特定小鼠，但这超出了本课程的范围。 ann &lt;- read.delim(&quot;data/droplet/droplet_annotation.csv&quot;, sep=&quot;,&quot;, header=TRUE) head(ann) ## cell tissue cell_ontology_class ## 1 10X_P4_3_AAAGTAGAGATGCCAG Bladder mesenchymal cell ## 2 10X_P4_3_AACCGCGTCCAACCAA Bladder mesenchymal cell ## 3 10X_P4_3_AACTCCCGTCGGGTCT Bladder mesenchymal cell ## 4 10X_P4_3_AACTCTTAGTTGCAGG Bladder bladder cell ## 5 10X_P4_3_AACTCTTTCATAACCG Bladder mesenchymal cell ## 6 10X_P4_3_AAGACCTAGATCCGAG Bladder endothelial cell ## cell_ontology_term_iri cell_ontology_id ## 1 http://purl.obolibrary.org/obo/CL_0008019 CL:0008019 ## 2 http://purl.obolibrary.org/obo/CL_0008019 CL:0008019 ## 3 http://purl.obolibrary.org/obo/CL_0008019 CL:0008019 ## 4 http://purl.obolibrary.org/obo/CL_1001319 CL:1001319 ## 5 http://purl.obolibrary.org/obo/CL_0008019 CL:0008019 ## 6 http://purl.obolibrary.org/obo/CL_0000115 CL:0000115 注释中的cellID和cellbarcode格式有些差别，在匹配前进行校正。 ann[,1] &lt;- paste(ann[,1], &quot;-1&quot;, sep=&quot;&quot;) ann_subset &lt;- ann[match(colnames(molecules), ann[,1]),] celltype &lt;- ann_subset[,3] 构建cell-metadata数据框 cell_anns &lt;- data.frame(mouse = rep(mouseID, times=ncol(molecules)), type=celltype) rownames(cell_anns) &lt;- colnames(molecules); 练习 使用组织的其它批次重复上述处理. 答案 molecules1 &lt;- molecules cell_anns1 &lt;- cell_anns cellbarcodes &lt;- read.table(&quot;data/droplet/Kidney-10X_P4_5/barcodes.tsv&quot;) genenames &lt;- read.table(&quot;data/droplet/Kidney-10X_P4_5/genes.tsv&quot;) molecules &lt;- Matrix::readMM(&quot;data/droplet/Kidney-10X_P4_5/matrix.mtx&quot;) rownames(molecules) &lt;- genenames[,1] colnames(molecules) &lt;- paste(&quot;10X_P4_6&quot;, cellbarcodes[,1], sep=&quot;_&quot;) mouseID &lt;- &quot;3_9_M&quot; ann_subset &lt;- ann[match(colnames(molecules), ann[,1]),] celltype &lt;- ann_subset[,3] cell_anns &lt;- data.frame(mouse = rep(mouseID, times=ncol(molecules)), type=celltype) rownames(cell_anns) &lt;- colnames(molecules) molecules2 &lt;- molecules cell_anns2 &lt;- cell_anns cellbarcodes &lt;- read.table(&quot;data/droplet/Kidney-10X_P7_5/barcodes.tsv&quot;) genenames &lt;- read.table(&quot;data/droplet/Kidney-10X_P7_5/genes.tsv&quot;) molecules &lt;- Matrix::readMM(&quot;data/droplet/Kidney-10X_P7_5/matrix.mtx&quot;) rownames(molecules) &lt;- genenames[,1] colnames(molecules) &lt;- paste(&quot;10X_P7_5&quot;, cellbarcodes[,1], sep=&quot;_&quot;) mouseID &lt;- &quot;3_57_F&quot; ann_subset &lt;- ann[match(colnames(molecules), ann[,1]),] celltype &lt;- ann_subset[,3] cell_anns &lt;- data.frame(mouse = rep(mouseID, times=ncol(molecules)), type=celltype) rownames(cell_anns) &lt;- colnames(molecules) molecules3 &lt;- molecules cell_anns3 &lt;- cell_anns 6.6 创建scater对象 现在已经读入多个批次的10X数据，将其合并成一个SingleCellExperiment对象。首先检查不同批次基因名字和顺序是否一致。 identical(rownames(molecules1), rownames(molecules2)) ## [1] TRUE identical(rownames(molecules1), rownames(molecules3)) ## [1] TRUE 检查有无重复的cellIDs: sum(colnames(molecules1) %in% colnames(molecules2)) ## [1] 0 sum(colnames(molecules1) %in% colnames(molecules3)) ## [1] 0 sum(colnames(molecules2) %in% colnames(molecules3)) ## [1] 0 检查没有问题后，将数据进行合并。 Everything is ok, so we can go ahead and combine them: all_molecules &lt;- cbind(molecules1, molecules2, molecules3) all_cell_anns &lt;- as.data.frame(rbind(cell_anns1, cell_anns2, cell_anns3)) all_cell_anns$batch &lt;- rep(c(&quot;10X_P4_5&quot;, &quot;10X_P4_6&quot;,&quot;10X_P7_5&quot;), times = c(nrow(cell_anns1), nrow(cell_anns2), nrow(cell_anns3))) 练习 数据集中共有多少细胞？ 答案 创建SingleCellExperiment对象，SingleCellExperiment类的一个优势是其可以以正常矩阵或者稀疏矩阵的格式存储数据，以及HDF5格式，以有效的方式在磁盘存储和读取大型非稀疏矩阵，而不是整个加载到内存中。 all_molecules &lt;- as.matrix(all_molecules) sceset &lt;- SingleCellExperiment( assays = list(counts = as.matrix(all_molecules)), colData = all_cell_anns ) 因为这是10X数据，不包括spike-ins，可以直接存储数据。 saveRDS(sceset, &quot;kidney_droplet.rds&quot;) 6.7 进阶练习 编写R函数/脚本自动处理任何组织的任意数据类型。 "],
["cleaning-the-expression-matrix.html", "7 Cleaning the Expression Matrix 7.1 Expression QC (UMI) 7.2 Expression QC (Reads) 7.3 Data visualization 7.4 Data visualization (Reads) 7.5 Identifying confounding factors 7.6 Identifying confounding factors (Reads) 7.7 Normalization theory 7.8 Normalization practice (UMI) 7.9 Normalization practice (Reads) 7.10 Dealing with confounders 7.11 Dealing with confounders (Reads)", " 7 Cleaning the Expression Matrix 7.1 Expression QC (UMI) 7.1.1 Introduction Once gene expression has been quantified it is summarized as an expression matrix where each row corresponds to a gene (or transcript) and each column corresponds to a single cell. This matrix should be examined to remove poor quality cells which were not detected in either read QC or mapping QC steps. Failure to remove low quality cells at this stage may add technical noise which has the potential to obscure the biological signals of interest in the downstream analysis. Since there is currently no standard method for performing scRNASeq the expected values for the various QC measures that will be presented here can vary substantially from experiment to experiment. Thus, to perform QC we will be looking for cells which are outliers with respect to the rest of the dataset rather than comparing to independent quality standards. Consequently, care should be taken when comparing quality metrics across datasets collected using different protocols. 7.1.2 Tung dataset To illustrate cell QC, we consider a dataset of induced pluripotent stem cells generated from three different individuals (Tung et al. 2017) in Yoav Gilad’s lab at the University of Chicago. The experiments were carried out on the Fluidigm C1 platform and to facilitate the quantification both unique molecular identifiers (UMIs) and ERCC spike-ins were used. The data files are located in the tung folder in your working directory. These files are the copies of the original files made on the 15/03/16. We will use these copies for reproducibility purposes. library(SingleCellExperiment) library(scater) options(stringsAsFactors = FALSE) Load the data and annotations: molecules &lt;- read.table(&quot;data/tung/molecules.txt&quot;, sep = &quot;\\t&quot;) anno &lt;- read.table(&quot;data/tung/annotation.txt&quot;, sep = &quot;\\t&quot;, header = TRUE) Inspect a small portion of the expression matrix head(molecules[ , 1:3]) ## NA19098.r1.A01 NA19098.r1.A02 NA19098.r1.A03 ## ENSG00000237683 0 0 0 ## ENSG00000187634 0 0 0 ## ENSG00000188976 3 6 1 ## ENSG00000187961 0 0 0 ## ENSG00000187583 0 0 0 ## ENSG00000187642 0 0 0 head(anno) ## individual replicate well batch sample_id ## 1 NA19098 r1 A01 NA19098.r1 NA19098.r1.A01 ## 2 NA19098 r1 A02 NA19098.r1 NA19098.r1.A02 ## 3 NA19098 r1 A03 NA19098.r1 NA19098.r1.A03 ## 4 NA19098 r1 A04 NA19098.r1 NA19098.r1.A04 ## 5 NA19098 r1 A05 NA19098.r1 NA19098.r1.A05 ## 6 NA19098 r1 A06 NA19098.r1 NA19098.r1.A06 The data consists of 3 individuals and 3 replicates and therefore has 9 batches in total. We standardize the analysis by using both SingleCellExperiment (SCE) and scater packages. First, create the SCE object: umi &lt;- SingleCellExperiment( assays = list(counts = as.matrix(molecules)), colData = anno ) Remove genes that are not expressed in any cell: keep_feature &lt;- rowSums(counts(umi) &gt; 0) &gt; 0 umi &lt;- umi[keep_feature, ] Define control features (genes) - ERCC spike-ins and mitochondrial genes (provided by the authors): isSpike(umi, &quot;ERCC&quot;) &lt;- grepl(&quot;^ERCC-&quot;, rownames(umi)) isSpike(umi, &quot;MT&quot;) &lt;- rownames(umi) %in% c(&quot;ENSG00000198899&quot;, &quot;ENSG00000198727&quot;, &quot;ENSG00000198888&quot;, &quot;ENSG00000198886&quot;, &quot;ENSG00000212907&quot;, &quot;ENSG00000198786&quot;, &quot;ENSG00000198695&quot;, &quot;ENSG00000198712&quot;, &quot;ENSG00000198804&quot;, &quot;ENSG00000198763&quot;, &quot;ENSG00000228253&quot;, &quot;ENSG00000198938&quot;, &quot;ENSG00000198840&quot;) Calculate the quality metrics: umi &lt;- calculateQCMetrics( umi, feature_controls = list( ERCC = isSpike(umi, &quot;ERCC&quot;), MT = isSpike(umi, &quot;MT&quot;) ) ) ## Warning in calculateQCMetrics(umi, feature_controls = list(ERCC = ## isSpike(umi, : spike-in set &#39;ERCC&#39; overwritten by feature_controls set of ## the same name 7.1.3 Cell QC 7.1.3.1 Library size Next we consider the total number of RNA molecules detected per sample (if we were using read counts rather than UMI counts this would be the total number of reads). Wells with few reads/molecules are likely to have been broken or failed to capture a cell, and should thus be removed. hist( umi$total_counts, breaks = 100 ) abline(v = 25000, col = &quot;red&quot;) Figure 7.1: Histogram of library sizes for all cells Exercise 1 How many cells does our filter remove? What distribution do you expect that the total number of molecules for each cell should follow? Our answer ## filter_by_total_counts ## FALSE TRUE ## 46 818 7.1.3.2 Detected genes In addition to ensuring sufficient sequencing depth for each sample, we also want to make sure that the reads are distributed across the transcriptome. Thus, we count the total number of unique genes detected in each sample. hist( umi$total_features_by_counts, breaks = 100 ) abline(v = 7000, col = &quot;red&quot;) Figure 7.2: Histogram of the number of detected genes in all cells From the plot we conclude that most cells have between 7,000-10,000 detected genes, which is normal for high-depth scRNA-seq. However, this varies by experimental protocol and sequencing depth. For example, droplet-based methods or samples with lower sequencing-depth typically detect fewer genes per cell. The most notable feature in the above plot is the “heavy tail” on the left hand side of the distribution. If detection rates were equal across the cells then the distribution should be approximately normal. Thus we remove those cells in the tail of the distribution (fewer than 7,000 detected genes). Exercise 2 How many cells does our filter remove? Our answer ## filter_by_expr_features ## FALSE TRUE ## 116 748 7.1.3.3 ERCCs and MTs Another measure of cell quality is the ratio between ERCC spike-in RNAs and endogenous RNAs. This ratio can be used to estimate the total amount of RNA in the captured cells. Cells with a high level of spike-in RNAs had low starting amounts of RNA, likely due to the cell being dead or stressed which may result in the RNA being degraded. plotColData( umi, x = &quot;total_features_by_counts&quot;, y = &quot;pct_counts_MT&quot;, colour = &quot;batch&quot; ) Figure 7.3: Percentage of counts in MT genes plotColData( umi, x = &quot;total_features_by_counts&quot;, y = &quot;pct_counts_ERCC&quot;, colour = &quot;batch&quot; ) Figure 7.4: Percentage of counts in ERCCs The above analysis shows that majority of the cells from NA19098.r2 batch have a very high ERCC/Endo ratio. Indeed, it has been shown by the authors that this batch contains cells of smaller size. Exercise 3 Create filters for removing batch NA19098.r2 and cells with high expression of mitochondrial genes (&gt;10% of total counts in a cell). Our answer ## filter_by_ERCC ## FALSE TRUE ## 96 768 ## filter_by_MT ## FALSE TRUE ## 31 833 Exercise 4 What would you expect to see in the ERCC vs counts plot if you were examining a dataset containing cells of different sizes (eg. normal &amp; senescent cells)? Answer You would expect to see a group corresponding to the smaller cells (normal) with a higher fraction of ERCC reads than a separate group corresponding to the larger cells (senescent). 7.1.4 Cell filtering 7.1.4.1 Manual Now we can define a cell filter based on our previous analysis: umi$use &lt;- ( # sufficient features (genes) filter_by_expr_features &amp; # sufficient molecules counted filter_by_total_counts &amp; # sufficient endogenous RNA filter_by_ERCC &amp; # remove cells with unusual number of reads in MT genes filter_by_MT ) table(umi$use) ## ## FALSE TRUE ## 207 657 7.1.4.2 Automatic Another option available in scater is to conduct PCA on a set of QC metrics and then use automatic outlier detection to identify potentially problematic cells. By default, the following metrics are used for PCA-based outlier detection: pct_counts_top_100_features total_features pct_counts_feature_controls n_detected_feature_controls log10_counts_endogenous_features log10_counts_feature_controls scater first creates a matrix where the rows represent cells and the columns represent the different QC metrics. Then, outlier cells can also be identified by using the mvoutlier package on the QC metrics for all cells. This will identify cells that have substantially different QC metrics from the others, possibly corresponding to low-quality cells. We can visualize any outliers using a principal components plot as shown below: umi &lt;- runPCA( umi, use_coldata = TRUE, detect_outliers = TRUE ) reducedDimNames(umi) ## [1] &quot;PCA_coldata&quot; Column subsetting can then be performed based on the $outlier slot, which indicates whether or not each cell has been designated as an outlier. Automatic outlier detection can be informative, but a close inspection of QC metrics and tailored filtering for the specifics of the dataset at hand is strongly recommended. table(umi$outlier) ## ## FALSE TRUE ## 791 73 Then, we can use a PCA plot to see a 2D representation of the cells ordered by their quality metrics. plotReducedDim( umi, use_dimred = &quot;PCA_coldata&quot;, size_by = &quot;total_features_by_counts&quot;, shape_by = &quot;use&quot;, colour_by = &quot;outlier&quot; ) 7.1.5 Compare filterings Exercise 5 Compare the default, automatic and manual cell filters. Plot a Venn diagram of the outlier cells from these filterings. Hint: Use vennCounts and vennDiagram functions from the limma package to make a Venn diagram. Answer ## ## 载入程辑包：&#39;limma&#39; ## The following object is masked from &#39;package:scater&#39;: ## ## plotMDS ## The following object is masked from &#39;package:BiocGenerics&#39;: ## ## plotMA Figure 7.5: Comparison of the default, automatic and manual cell filters 7.1.6 Gene analysis 7.1.6.1 Gene expression In addition to removing cells with poor quality, it is usually a good idea to exclude genes where we suspect that technical artefacts may have skewed the results. Moreover, inspection of the gene expression profiles may provide insights about how the experimental procedures could be improved. It is often instructive to consider the number of reads consumed by the top 50 expressed genes. plotHighestExprs(umi, exprs_values = &quot;counts&quot;) Figure 7.6: Number of total counts consumed by the top 50 expressed genes The distributions are relatively flat indicating (but not guaranteeing!) good coverage of the full transcriptome of these cells. However, there are several spike-ins in the top 15 genes which suggests a greater dilution of the spike-ins may be preferrable if the experiment is to be repeated. 7.1.6.2 Gene filtering It is typically a good idea to remove genes whose expression level is considered “undetectable”. We define a gene as detectable if at least two cells contain more than 1 transcript from the gene. If we were considering read counts rather than UMI counts a reasonable threshold is to require at least five reads in at least two cells. However, in both cases the threshold strongly depends on the sequencing depth. It is important to keep in mind that genes must be filtered after cell filtering since some genes may only be detected in poor quality cells (note colData(umi)$use filter applied to the umi dataset). keep_feature &lt;- nexprs( umi[,colData(umi)$use], byrow = TRUE, detection_limit = 1 ) &gt;= 2 rowData(umi)$use &lt;- keep_feature table(keep_feature) ## keep_feature ## FALSE TRUE ## 4660 14066 Depending on the cell-type, protocol and sequencing depth, other cut-offs may be appropriate. 7.1.7 Save the data Dimensions of the QCed dataset (do not forget about the gene filter we defined above): dim(umi[rowData(umi)$use, colData(umi)$use]) ## [1] 14066 657 Let’s create an additional slot with log-transformed counts (we will need it in the next chapters) and remove saved PCA results from the reducedDim slot: assay(umi, &quot;logcounts_raw&quot;) &lt;- log2(counts(umi) + 1) reducedDim(umi) &lt;- NULL Save the data: saveRDS(umi, file = &quot;data/tung/umi.rds&quot;) 7.1.8 Big Exercise Perform exactly the same QC analysis with read counts of the same Blischak data. Use tung/reads.txt file to load the reads. Once you have finished please compare your results to ours (next chapter). 7.2 Expression QC (Reads) library(SingleCellExperiment) library(scater) options(stringsAsFactors = FALSE) reads &lt;- read.table(&quot;data/tung/reads.txt&quot;, sep = &quot;\\t&quot;) anno &lt;- read.table(&quot;data/tung/annotation.txt&quot;, sep = &quot;\\t&quot;, header = TRUE) head(reads[ , 1:3]) ## NA19098.r1.A01 NA19098.r1.A02 NA19098.r1.A03 ## ENSG00000237683 0 0 0 ## ENSG00000187634 0 0 0 ## ENSG00000188976 57 140 1 ## ENSG00000187961 0 0 0 ## ENSG00000187583 0 0 0 ## ENSG00000187642 0 0 0 head(anno) ## individual replicate well batch sample_id ## 1 NA19098 r1 A01 NA19098.r1 NA19098.r1.A01 ## 2 NA19098 r1 A02 NA19098.r1 NA19098.r1.A02 ## 3 NA19098 r1 A03 NA19098.r1 NA19098.r1.A03 ## 4 NA19098 r1 A04 NA19098.r1 NA19098.r1.A04 ## 5 NA19098 r1 A05 NA19098.r1 NA19098.r1.A05 ## 6 NA19098 r1 A06 NA19098.r1 NA19098.r1.A06 reads &lt;- SingleCellExperiment( assays = list(counts = as.matrix(reads)), colData = anno ) keep_feature &lt;- rowSums(counts(reads) &gt; 0) &gt; 0 reads &lt;- reads[keep_feature, ] isSpike(reads, &quot;ERCC&quot;) &lt;- grepl(&quot;^ERCC-&quot;, rownames(reads)) isSpike(reads, &quot;MT&quot;) &lt;- rownames(reads) %in% c(&quot;ENSG00000198899&quot;, &quot;ENSG00000198727&quot;, &quot;ENSG00000198888&quot;, &quot;ENSG00000198886&quot;, &quot;ENSG00000212907&quot;, &quot;ENSG00000198786&quot;, &quot;ENSG00000198695&quot;, &quot;ENSG00000198712&quot;, &quot;ENSG00000198804&quot;, &quot;ENSG00000198763&quot;, &quot;ENSG00000228253&quot;, &quot;ENSG00000198938&quot;, &quot;ENSG00000198840&quot;) reads &lt;- calculateQCMetrics( reads, feature_controls = list( ERCC = isSpike(reads, &quot;ERCC&quot;), MT = isSpike(reads, &quot;MT&quot;) ) ) ## Warning in calculateQCMetrics(reads, feature_controls = list(ERCC = ## isSpike(reads, : spike-in set &#39;ERCC&#39; overwritten by feature_controls set of ## the same name hist( reads$total_counts, breaks = 100 ) abline(v = 1.3e6, col = &quot;red&quot;) Figure 7.7: Histogram of library sizes for all cells filter_by_total_counts &lt;- (reads$total_counts &gt; 1.3e6) table(filter_by_total_counts) ## filter_by_total_counts ## FALSE TRUE ## 180 684 hist( reads$total_features_by_counts, breaks = 100 ) abline(v = 7000, col = &quot;red&quot;) Figure 7.8: Histogram of the number of detected genes in all cells filter_by_expr_features &lt;- (reads$total_features_by_counts &gt; 7000) table(filter_by_expr_features) ## filter_by_expr_features ## FALSE TRUE ## 116 748 plotColData( reads, x = &quot;total_features_by_counts&quot;, y = &quot;pct_counts_MT&quot;, colour = &quot;batch&quot; ) Figure 7.9: Percentage of counts in MT genes plotColData( reads, x = &quot;total_features_by_counts&quot;, y = &quot;pct_counts_ERCC&quot;, colour = &quot;batch&quot; ) Figure 7.10: Percentage of counts in ERCCs filter_by_ERCC &lt;- reads$batch != &quot;NA19098.r2&quot; &amp; reads$pct_counts_ERCC &lt; 25 table(filter_by_ERCC) ## filter_by_ERCC ## FALSE TRUE ## 103 761 filter_by_MT &lt;- reads$pct_counts_MT &lt; 30 table(filter_by_MT) ## filter_by_MT ## FALSE TRUE ## 18 846 reads$use &lt;- ( # sufficient features (genes) filter_by_expr_features &amp; # sufficient molecules counted filter_by_total_counts &amp; # sufficient endogenous RNA filter_by_ERCC &amp; # remove cells with unusual number of reads in MT genes filter_by_MT ) table(reads$use) ## ## FALSE TRUE ## 258 606 reads &lt;- runPCA( reads, use_coldata = TRUE, detect_outliers = TRUE ) reducedDimNames(reads) ## [1] &quot;PCA_coldata&quot; table(reads$outlier) ## ## FALSE TRUE ## 753 111 plotReducedDim( reads, use_dimred = &quot;PCA_coldata&quot;, size_by = &quot;total_features_by_counts&quot;, shape_by = &quot;use&quot;, colour_by = &quot;outlier&quot; ) library(limma) auto &lt;- colnames(reads)[reads$outlier] man &lt;- colnames(reads)[!reads$use] venn.diag &lt;- vennCounts( cbind(colnames(reads) %in% auto, colnames(reads) %in% man) ) vennDiagram( venn.diag, names = c(&quot;Automatic&quot;, &quot;Manual&quot;), circle.col = c(&quot;blue&quot;, &quot;green&quot;) ) Figure 7.11: Comparison of the default, automatic and manual cell filters plotHighestExprs(reads, exprs_values = &quot;counts&quot;) Figure 7.12: Number of total counts consumed by the top 50 expressed genes keep_feature &lt;- nexprs( reads[,colData(reads)$use], byrow = TRUE, detection_limit = 1 ) &gt;= 2 rowData(reads)$use &lt;- keep_feature table(keep_feature) ## keep_feature ## FALSE TRUE ## 2664 16062 dim(reads[rowData(reads)$use, colData(reads)$use]) ## [1] 16062 606 assay(reads, &quot;logcounts_raw&quot;) &lt;- log2(counts(reads) + 1) reducedDim(reads) &lt;- NULL saveRDS(reads, file = &quot;data/tung/reads.rds&quot;) By comparing Figure 7.5 and Figure 7.11, it is clear that the reads based filtering removed more cells than the UMI based analysis. If you go back and compare the results you should be able to conclude that the ERCC and MT filters are more strict for the reads-based analysis. 7.3 Data visualization 7.3.1 Introduction In this chapter we will continue to work with the filtered Tung dataset produced in the previous chapter. We will explore different ways of visualizing the data to allow you to asses what happened to the expression matrix after the quality control step. scater package provides several very useful functions to simplify visualisation. One important aspect of single-cell RNA-seq is to control for batch effects. Batch effects are technical artefacts that are added to the samples during handling. For example, if two sets of samples were prepared in different labs or even on different days in the same lab, then we may observe greater similarities between the samples that were handled together. In the worst case scenario, batch effects may be mistaken for true biological variation. The Tung data allows us to explore these issues in a controlled manner since some of the salient aspects of how the samples were handled have been recorded. Ideally, we expect to see batches from the same individual grouping together and distinct groups corresponding to each individual. library(SingleCellExperiment) library(scater) options(stringsAsFactors = FALSE) umi &lt;- readRDS(&quot;data/tung/umi.rds&quot;) umi.qc &lt;- umi[rowData(umi)$use, colData(umi)$use] endog_genes &lt;- !rowData(umi.qc)$is_feature_control 7.3.2 PCA plot The easiest way to overview the data is by transforming it using the principal component analysis and then visualize the first two principal components. Principal component analysis (PCA) is a statistical procedure that uses a transformation to convert a set of observations into a set of values of linearly uncorrelated variables called principal components (PCs). The number of principal components is less than or equal to the number of original variables. Mathematically, the PCs correspond to the eigenvectors of the covariance matrix. The eigenvectors are sorted by eigenvalue so that the first principal component accounts for as much of the variability in the data as possible, and each succeeding component in turn has the highest variance possible under the constraint that it is orthogonal to the preceding components (the figure below is taken from here). Figure 7.13: Schematic representation of PCA dimensionality reduction 7.3.2.1 Before QC Without log-transformation: tmp &lt;- runPCA( umi[endog_genes, ], exprs_values = &quot;counts&quot; ) plotPCA( tmp, colour_by = &quot;batch&quot;, size_by = &quot;total_features_by_counts&quot;, shape_by = &quot;individual&quot; ) Figure 7.14: PCA plot of the tung data With log-transformation: tmp &lt;- runPCA( umi[endog_genes, ], exprs_values = &quot;logcounts_raw&quot; ) plotPCA( tmp, colour_by = &quot;batch&quot;, size_by = &quot;total_features_by_counts&quot;, shape_by = &quot;individual&quot; ) knitr::include_graphics(&quot;https://scrnaseq-course.cog.sanger.ac.uk/website/exprs-overview_files/figure-html/expr-overview-pca-before-qc2-1.png&quot;) Clearly log-transformation is benefitial for our data - it reduces the variance on the first principal component and already separates some biological effects. Moreover, it makes the distribution of the expression values more normal. In the following analysis and chapters we will be using log-transformed raw counts by default. However, note that just a log-transformation is not enough to account for different technical factors between the cells (e.g. sequencing depth). Therefore, please do not use logcounts_raw for your downstream analysis, instead as a minimum suitable data use the logcounts slot of the SingleCellExperiment object, which not just log-transformed, but also normalised by library size (e.g. CPM normalisation). In the course we use logcounts_raw only for demonstration purposes! 7.3.2.2 After QC tmp &lt;- runPCA( umi.qc[endog_genes, ], exprs_values = &quot;logcounts_raw&quot; ) plotPCA( tmp, colour_by = &quot;batch&quot;, size_by = &quot;total_features_by_counts&quot;, shape_by = &quot;individual&quot; ) Figure 7.15: PCA plot of the tung data Comparing Figure ?? and Figure ??, it is clear that after quality control the NA19098.r2 cells no longer form a group of outliers. By default only the top 500 most variable genes are used by scater to calculate the PCA. This can be adjusted by changing the ntop argument. Exercise 1 How do the PCA plots change if when all 14,066 genes are used? Or when only top 50 genes are used? Why does the fraction of variance accounted for by the first PC change so dramatically? Hint Use ntop argument of the plotPCA function. Our answer Figure 7.16: PCA plot of the tung data (14214 genes) Figure 7.17: PCA plot of the tung data (50 genes) If your answers are different please compare your code with ours (you need to search for this exercise in the opened file). 7.3.3 tSNE map An alternative to PCA for visualizing scRNASeq data is a tSNE plot. tSNE (t-Distributed Stochastic Neighbor Embedding) combines dimensionality reduction (e.g. PCA) with random walks on the nearest-neighbour network to map high dimensional data (i.e. our 14,214 dimensional expression matrix) to a 2-dimensional space while preserving local distances between cells. In contrast with PCA, tSNE is a stochastic algorithm which means running the method multiple times on the same dataset will result in different plots. Due to the non-linear and stochastic nature of the algorithm, tSNE is more difficult to intuitively interpret tSNE. To ensure reproducibility, we fix the “seed” of the random-number generator in the code below so that we always get the same plot. 7.3.3.1 Before QC set.seed(123456) tmp &lt;- runTSNE( umi[endog_genes, ], exprs_values = &quot;logcounts_raw&quot;, perplexity = 130 ) plotTSNE( tmp, colour_by = &quot;batch&quot;, size_by = &quot;total_features_by_counts&quot;, shape_by = &quot;individual&quot; ) Figure 7.18: tSNE map of the tung data 7.3.3.2 After QC set.seed(123456) tmp &lt;- runTSNE( umi.qc[endog_genes, ], exprs_values = &quot;logcounts_raw&quot;, perplexity = 130 ) plotTSNE( tmp, colour_by = &quot;batch&quot;, size_by = &quot;total_features_by_counts&quot;, shape_by = &quot;individual&quot; ) Figure 7.19: tSNE map of the tung data Interpreting PCA and tSNE plots is often challenging and due to their stochastic and non-linear nature, they are less intuitive. However, in this case it is clear that they provide a similar picture of the data. Comparing Figure 7.18 and 7.19, it is again clear that the samples from NA19098.r2 are no longer outliers after the QC filtering. Furthermore tSNE requires you to provide a value of perplexity which reflects the number of neighbours used to build the nearest-neighbour network; a high value creates a dense network which clumps cells together while a low value makes the network more sparse allowing groups of cells to separate from each other. scater uses a default perplexity of the total number of cells divided by five (rounded down). You can read more about the pitfalls of using tSNE here. Exercise 2 How do the tSNE plots change when a perplexity of 10 or 200 is used? How does the choice of perplexity affect the interpretation of the results? Our answer Figure 7.20: tSNE map of the tung data (perplexity = 10) Figure 7.21: tSNE map of the tung data (perplexity = 200) 7.3.4 Big Exercise Perform the same analysis with read counts of the Blischak data. Use tung/reads.rds file to load the reads SCE object. Once you have finished please compare your results to ours (next chapter). 7.4 Data visualization (Reads) library(scater) options(stringsAsFactors = FALSE) reads &lt;- readRDS(&quot;data/tung/reads.rds&quot;) reads.qc &lt;- reads[rowData(reads)$use, colData(reads)$use] endog_genes &lt;- !rowData(reads.qc)$is_feature_control tmp &lt;- runPCA( reads[endog_genes, ], exprs_values = &quot;counts&quot; ) plotPCA( tmp, colour_by = &quot;batch&quot;, size_by = &quot;total_features_by_counts&quot;, shape_by = &quot;individual&quot; ) Figure 7.22: PCA plot of the tung data tmp &lt;- runPCA( reads[endog_genes, ], exprs_values = &quot;logcounts_raw&quot; ) plotPCA( tmp, colour_by = &quot;batch&quot;, size_by = &quot;total_features_by_counts&quot;, shape_by = &quot;individual&quot; ) Figure 7.23: PCA plot of the tung data tmp &lt;- runPCA( reads.qc[endog_genes, ], exprs_values = &quot;logcounts_raw&quot; ) plotPCA( tmp, colour_by = &quot;batch&quot;, size_by = &quot;total_features_by_counts&quot;, shape_by = &quot;individual&quot; ) Figure 7.24: PCA plot of the tung data set.seed(123456) tmp &lt;- runTSNE( reads[endog_genes, ], exprs_values = &quot;logcounts_raw&quot;, perplexity = 130 ) plotTSNE( tmp, colour_by = &quot;batch&quot;, size_by = &quot;total_features_by_counts&quot;, shape_by = &quot;individual&quot; ) Figure 7.25: tSNE map of the tung data set.seed(123456) tmp &lt;- runTSNE( reads.qc[endog_genes, ], exprs_values = &quot;logcounts_raw&quot;, perplexity = 130 ) plotTSNE( tmp, colour_by = &quot;batch&quot;, size_by = &quot;total_features_by_counts&quot;, shape_by = &quot;individual&quot; ) Figure 7.26: tSNE map of the tung data Figure 7.27: tSNE map of the tung data (perplexity = 10) Figure 7.28: tSNE map of the tung data (perplexity = 200) 7.5 Identifying confounding factors 7.5.1 Introduction There is a large number of potential confounders, artifacts and biases in sc-RNA-seq data. One of the main challenges in analyzing scRNA-seq data stems from the fact that it is difficult to carry out a true technical replicate (why?) to distinguish biological and technical variability. In the previous chapters we considered batch effects and in this chapter we will continue to explore how experimental artifacts can be identified and removed. We will continue using the scater package since it provides a set of methods specifically for quality control of experimental and explanatory variables. Moreover, we will continue to work with the Blischak data that was used in the previous chapter. library(scater, quietly = TRUE) options(stringsAsFactors = FALSE) umi &lt;- readRDS(&quot;data/tung/umi.rds&quot;) umi.qc &lt;- umi[rowData(umi)$use, colData(umi)$use] endog_genes &lt;- !rowData(umi.qc)$is_feature_control The umi.qc dataset contains filtered cells and genes. Our next step is to explore technical drivers of variability in the data to inform data normalisation before downstream analysis. 7.5.2 Correlations with PCs Let’s first look again at the PCA plot of the QCed dataset: tmp &lt;- runPCA( umi.qc[endog_genes, ], exprs_values = &quot;logcounts_raw&quot; ) plotPCA( tmp, colour_by = &quot;batch&quot;, size_by = &quot;total_features_by_counts&quot; ) Figure 7.29: PCA plot of the tung data scater allows one to identify principal components that correlate with experimental and QC variables of interest (it ranks principle components by \\(R^2\\) from a linear model regressing PC value against the variable of interest). Let’s test whether some of the variables correlate with any of the PCs. 7.5.2.1 Detected genes logcounts(umi.qc) &lt;- assay(umi.qc, &quot;logcounts_raw&quot;) plotExplanatoryPCs( umi.qc[endog_genes, ], variables = &quot;total_features_by_counts&quot; ) Figure 7.30: PC correlation with the number of detected genes logcounts(umi.qc) &lt;- NULL Indeed, we can see that PC1 can be almost completely explained by the number of detected genes. In fact, it was also visible on the PCA plot above. This is a well-known issue in scRNA-seq and was described here. 7.5.3 Explanatory variables scater can also compute the marginal \\(R^2\\) for each variable when fitting a linear model regressing expression values for each gene against just that variable, and display a density plot of the gene-wise marginal \\(R^2\\) values for the variables. plotExplanatoryVariables( umi.qc[endog_genes, ], exprs_values = &quot;logcounts_raw&quot;, variables = c( &quot;total_features_by_counts&quot;, &quot;total_counts&quot;, &quot;batch&quot;, &quot;individual&quot;, &quot;pct_counts_ERCC&quot;, &quot;pct_counts_MT&quot; ) ) Figure 7.31: Explanatory variables This analysis indicates that the number of detected genes (again) and also the sequencing depth (number of counts) have substantial explanatory power for many genes, so these variables are good candidates for conditioning out in a normalisation step, or including in downstream statistical models. Expression of ERCCs also appears to be an important explanatory variable and one notable feature of the above plot is that batch explains more than individual. What does that tell us about the technical and biological variability of the data? 7.5.4 Other confounders In addition to correcting for batch, there are other factors that one may want to compensate for. As with batch correction, these adjustments require extrinsic information. One popular method is scLVM which allows you to identify and subtract the effect from processes such as cell-cycle or apoptosis. In addition, protocols may differ in terms of their coverage of each transcript, their bias based on the average content of A/T nucleotides, or their ability to capture short transcripts. Ideally, we would like to compensate for all of these differences and biases. 7.5.5 Exercise Perform the same analysis with read counts of the Blischak data. Use tung/reads.rds file to load the reads SCESet object. Once you have finished please compare your results to ours (next chapter). 7.6 Identifying confounding factors (Reads) Figure 7.32: PCA plot of the tung data Figure 7.33: PC correlation with the number of detected genes Figure 7.34: Explanatory variables 7.7 Normalization theory 7.7.1 Introduction In the previous chapter we identified important confounding factors and explanatory variables. scater allows one to account for these variables in subsequent statistical models or to condition them out using normaliseExprs(), if so desired. This can be done by providing a design matrix to normaliseExprs(). We are not covering this topic here, but you can try to do it yourself as an exercise. Instead we will explore how simple size-factor normalisations correcting for library size can remove the effects of some of the confounders and explanatory variables. 7.7.2 Library size Library sizes vary because scRNA-seq data is often sequenced on highly multiplexed platforms the total reads which are derived from each cell may differ substantially. Some quantification methods (eg. Cufflinks, RSEM) incorporated library size when determining gene expression estimates thus do not require this normalization. However, if another quantification method was used then library size must be corrected for by multiplying or dividing each column of the expression matrix by a “normalization factor” which is an estimate of the library size relative to the other cells. Many methods to correct for library size have been developped for bulk RNA-seq and can be equally applied to scRNA-seq (eg. UQ, SF, CPM, RPKM, FPKM, TPM). 7.7.3 Normalisations 7.7.3.1 CPM The simplest way to normalize this data is to convert it to counts per million (CPM) by dividing each column by its total then multiplying by 1,000,000. Note that spike-ins should be excluded from the calculation of total expression in order to correct for total cell RNA content, therefore we will only use endogenous genes. Example of a CPM function in R: calc_cpm &lt;- function (expr_mat, spikes = NULL) { norm_factor &lt;- colSums(expr_mat[-spikes, ]) return(t(t(expr_mat)/norm_factor)) * 10^6 } One potential drawback of CPM is if your sample contains genes that are both very highly expressed and differentially expressed across the cells. In this case, the total molecules in the cell may depend of whether such genes are on/off in the cell and normalizing by total molecules may hide the differential expression of those genes and/or falsely create differential expression for the remaining genes. Note RPKM, FPKM and TPM are variants on CPM which further adjust counts by the length of the respective gene/transcript. To deal with this potentiality several other measures were devised. 7.7.3.2 RLE (SF) The size factor (SF) was proposed and popularized by DESeq (Anders and Huber 2010). First the geometric mean of each gene across all cells is calculated. The size factor for each cell is the median across genes of the ratio of the expression to the gene’s geometric mean. A drawback to this method is that since it uses the geometric mean only genes with non-zero expression values across all cells can be used in its calculation, making it unadvisable for large low-depth scRNASeq experiments. edgeR &amp; scater call this method RLE for “relative log expression”. Example of a SF function in R: calc_sf &lt;- function (expr_mat, spikes = NULL) { geomeans &lt;- exp(rowMeans(log(expr_mat[-spikes, ]))) SF &lt;- function(cnts) { median((cnts/geomeans)[(is.finite(geomeans) &amp; geomeans &gt; 0)]) } norm_factor &lt;- apply(expr_mat[-spikes, ], 2, SF) return(t(t(expr_mat)/norm_factor)) } 7.7.3.3 UQ The upperquartile (UQ) was proposed by (Bullard et al. 2010). Here each column is divided by the 75% quantile of the counts for each library. Often the calculated quantile is scaled by the median across cells to keep the absolute level of expression relatively consistent. A drawback to this method is that for low-depth scRNASeq experiments the large number of undetected genes may result in the 75% quantile being zero (or close to it). This limitation can be overcome by generalizing the idea and using a higher quantile (eg. the 99% quantile is the default in scater) or by excluding zeros prior to calculating the 75% quantile. Example of a UQ function in R: calc_uq &lt;- function (expr_mat, spikes = NULL) { UQ &lt;- function(x) { quantile(x[x &gt; 0], 0.75) } uq &lt;- unlist(apply(expr_mat[-spikes, ], 2, UQ)) norm_factor &lt;- uq/median(uq) return(t(t(expr_mat)/norm_factor)) } 7.7.3.4 TMM Another method is called TMM is the weighted trimmed mean of M-values (to the reference) proposed by (Robinson and Oshlack 2010). The M-values in question are the gene-wise log2 fold changes between individual cells. One cell is used as the reference then the M-values for each other cell is calculated compared to this reference. These values are then trimmed by removing the top and bottom ~30%, and the average of the remaining values is calculated by weighting them to account for the effect of the log scale on variance. Each non-reference cell is multiplied by the calculated factor. Two potential issues with this method are insufficient non-zero genes left after trimming, and the assumption that most genes are not differentially expressed. 7.7.3.5 scran scran package implements a variant on CPM specialized for single-cell data (L. Lun, Bach, and Marioni 2016). Briefly this method deals with the problem of vary large numbers of zero values per cell by pooling cells together calculating a normalization factor (similar to CPM) for the sum of each pool. Since each cell is found in many different pools, cell-specific factors can be deconvoluted from the collection of pool-specific factors using linear algebra. 7.7.3.6 Downsampling A final way to correct for library size is to downsample the expression matrix so that each cell has approximately the same total number of molecules. The benefit of this method is that zero values will be introduced by the down sampling thus eliminating any biases due to differing numbers of detected genes. However, the major drawback is that the process is not deterministic so each time the downsampling is run the resulting expression matrix is slightly different. Thus, often analyses must be run on multiple downsamplings to ensure results are robust. Example of a downsampling function in R: Down_Sample_Matrix &lt;- function (expr_mat) { min_lib_size &lt;- min(colSums(expr_mat)) down_sample &lt;- function(x) { prob &lt;- min_lib_size/sum(x) return(unlist(lapply(x, function(y) { rbinom(1, y, prob) }))) } down_sampled_mat &lt;- apply(expr_mat, 2, down_sample) return(down_sampled_mat) } 7.7.4 Effectiveness to compare the efficiency of different normalization methods we will use visual inspection of PCA plots and calculation of cell-wise relative log expression via scater’s plotRLE() function. Namely, cells with many (few) reads have higher (lower) than median expression for most genes resulting in a positive (negative) RLE across the cell, whereas normalized cells have an RLE close to zero. Example of a RLE function in R: calc_cell_RLE &lt;- function (expr_mat, spikes = NULL) { RLE_gene &lt;- function(x) { if (median(unlist(x)) &gt; 0) { log((x + 1)/(median(unlist(x)) + 1))/log(2) } else { rep(NA, times = length(x)) } } if (!is.null(spikes)) { RLE_matrix &lt;- t(apply(expr_mat[-spikes, ], 1, RLE_gene)) } else { RLE_matrix &lt;- t(apply(expr_mat, 1, RLE_gene)) } cell_RLE &lt;- apply(RLE_matrix, 2, median, na.rm = T) return(cell_RLE) } Note The RLE, TMM, and UQ size-factor methods were developed for bulk RNA-seq data and, depending on the experimental context, may not be appropriate for single-cell RNA-seq data, as their underlying assumptions may be problematically violated. Note scater acts as a wrapper for the calcNormFactors function from edgeR which implements several library size normalization methods making it easy to apply any of these methods to our data. Note edgeR makes extra adjustments to some of the normalization methods which may result in somewhat different results than if the original methods are followed exactly, e.g. edgeR’s and scater’s “RLE” method which is based on the “size factor” used by DESeq may give different results to the estimateSizeFactorsForMatrix method in the DESeq/DESeq2 packages. In addition, some versions of edgeR will not calculate the normalization factors correctly unless lib.size is set at 1 for all cells. Note For CPM normalisation we use scater’s calculateCPM() function. For RLE, UQ and TMM we used to use scater’s normaliseExprs() function (it is deprecated now and therefore we removed the corresponding subchapters). For scran we use scran package to calculate size factors (it also operates on SingleCellExperiment class) and scater’s normalize() to normalise the data. All these normalization functions save the results to the logcounts slot of the SCE object. For downsampling we use our own functions shown above. 7.8 Normalization practice (UMI) We will continue to work with the tung data that was used in the previous chapter. library(scRNA.seq.funcs) library(scater) library(scran) options(stringsAsFactors = FALSE) set.seed(1234567) umi &lt;- readRDS(&quot;data/tung/umi.rds&quot;) umi.qc &lt;- umi[rowData(umi)$use, colData(umi)$use] endog_genes &lt;- !rowData(umi.qc)$is_feature_control 7.8.1 Raw tmp &lt;- runPCA( umi.qc[endog_genes, ], exprs_values = &quot;logcounts_raw&quot; ) plotPCA( tmp, colour_by = &quot;batch&quot;, size_by = &quot;total_features_by_counts&quot;, shape_by = &quot;individual&quot; ) Figure 7.35: PCA plot of the tung data 7.8.2 CPM logcounts(umi.qc) &lt;- log2(calculateCPM(umi.qc, use_size_factors = FALSE) + 1) plotPCA( umi.qc[endog_genes, ], colour_by = &quot;batch&quot;, size_by = &quot;total_features_by_counts&quot;, shape_by = &quot;individual&quot; ) Figure 7.36: PCA plot of the tung data after CPM normalisation Figure 7.37: Cell-wise RLE of the tung data Figure 7.38: Cell-wise RLE of the tung data 7.8.3 scran qclust &lt;- quickCluster(umi.qc, min.size = 30) ## Warning: Setting &#39;use.ranks=TRUE&#39; for the old defaults. ## Set &#39;use.ranks=FALSE&#39; for the new defaults. umi.qc &lt;- computeSumFactors(umi.qc, sizes = 15, clusters = qclust) umi.qc &lt;- normalize(umi.qc) ## Warning in .get_all_sf_sets(object): spike-in set &#39;ERCC&#39; should have its ## own size factors ## Warning in .get_all_sf_sets(object): spike-in set &#39;MT&#39; should have its own ## size factors plotPCA( umi.qc[endog_genes, ], colour_by = &quot;batch&quot;, size_by = &quot;total_features_by_counts&quot;, shape_by = &quot;individual&quot; ) Figure 7.39: PCA plot of the tung data after LSF normalisation plotRLE( umi.qc[endog_genes, ], exprs_values = &quot;logcounts_raw&quot;, colour_by = &quot;batch&quot; ) Figure 7.40: Cell-wise RLE of the tung data plotRLE( umi.qc[endog_genes, ], exprs_values = &quot;logcounts&quot;, colour_by = &quot;batch&quot; ) Figure 7.41: Cell-wise RLE of the tung data scran sometimes calculates negative or zero size factors. These will completely distort the normalized expression matrix. We can check the size factors scran has computed like so: summary(sizeFactors(umi.qc)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.4832 0.7812 0.9535 1.0000 1.1469 3.2595 For this dataset all the size factors are reasonable so we are done. If you find scran has calculated negative size factors try increasing the cluster and pool sizes until they are all positive. 7.8.4 Downsampling logcounts(umi.qc) &lt;- log2(Down_Sample_Matrix(counts(umi.qc)) + 1) plotPCA( umi.qc[endog_genes, ], colour_by = &quot;batch&quot;, size_by = &quot;total_features_by_counts&quot;, shape_by = &quot;individual&quot; ) Figure 7.42: PCA plot of the tung data after downsampling plotRLE( umi.qc[endog_genes, ], exprs_values = &quot;logcounts_raw&quot;, colour_by = &quot;batch&quot; ) Figure 7.43: Cell-wise RLE of the tung data plotRLE( umi.qc[endog_genes, ], exprs_values = &quot;logcounts&quot;, colour_by = &quot;batch&quot; ) Figure 7.44: Cell-wise RLE of the tung data 7.8.5 Normalisation for gene/transcript length Some methods combine library size and fragment/gene length normalization such as: RPKM - Reads Per Kilobase Million (for single-end sequencing) FPKM - Fragments Per Kilobase Million (same as RPKM but for paired-end sequencing, makes sure that paired ends mapped to the same fragment are not counted twice) TPM - Transcripts Per Kilobase Million (same as RPKM, but the order of normalizations is reversed - length first and sequencing depth second) These methods are not applicable to our dataset since the end of the transcript which contains the UMI was preferentially sequenced. Furthermore in general these should only be calculated using appropriate quantification software from aligned BAM files not from read counts since often only a portion of the entire gene/transcript is sequenced, not the entire length. If in doubt check for a relationship between gene/transcript length and expression level. However, here we show how these normalisations can be calculated using scater. First, we need to find the effective transcript length in Kilobases. However, our dataset containes only gene IDs, therefore we will be using the gene lengths instead of transcripts. scater uses the biomaRt package, which allows one to annotate genes by other attributes: umi.qc &lt;- getBMFeatureAnnos( umi.qc, filters = &quot;ensembl_gene_id&quot;, attributes = c( &quot;ensembl_gene_id&quot;, &quot;hgnc_symbol&quot;, &quot;chromosome_name&quot;, &quot;start_position&quot;, &quot;end_position&quot; ), biomart = &quot;ENSEMBL_MART_ENSEMBL&quot;, dataset = &quot;hsapiens_gene_ensembl&quot;, host = &quot;www.ensembl.org&quot; ) # If you have mouse data, change the arguments based on this example: # getBMFeatureAnnos( # object, # filters = &quot;ensembl_transcript_id&quot;, # attributes = c( # &quot;ensembl_transcript_id&quot;, # &quot;ensembl_gene_id&quot;, # &quot;mgi_symbol&quot;, # &quot;chromosome_name&quot;, # &quot;transcript_biotype&quot;, # &quot;transcript_start&quot;, # &quot;transcript_end&quot;, # &quot;transcript_count&quot; # ), # biomart = &quot;ENSEMBL_MART_ENSEMBL&quot;, # dataset = &quot;mmusculus_gene_ensembl&quot;, # host = &quot;www.ensembl.org&quot; # ) Some of the genes were not annotated, therefore we filter them out: umi.qc.ann &lt;- umi.qc[!is.na(rowData(umi.qc)$ensembl_gene_id), ] Now we compute the total gene length in Kilobases by using the end_position and start_position fields: eff_length &lt;- abs(rowData(umi.qc.ann)$end_position - rowData(umi.qc.ann)$start_position) / 1000 plot(eff_length, rowMeans(counts(umi.qc.ann))) Figure 7.45: Gene length vs Mean Expression for the raw data There is no relationship between gene length and mean expression so __FPKM__s &amp; __TPM__s are inappropriate for this dataset. But we will demonstrate them anyway. Note Here calculate the total gene length instead of the total exon length. Many genes will contain lots of introns so their eff_length will be very different from what we have calculated. Please consider our calculation as approximation. If you want to use the total exon lengths, please refer to this page. Now we are ready to perform the normalisations: tpm(umi.qc.ann) &lt;- log2(calculateTPM(umi.qc.ann, eff_length) + 1) Plot the results as a PCA plot: tmp &lt;- runPCA( umi.qc.ann, exprs_values = &quot;tpm&quot;, ) plotPCA( tmp, colour_by = &quot;batch&quot;, size_by = &quot;total_features_by_counts&quot;, shape_by = &quot;individual&quot; ) Figure 7.46: PCA plot of the tung data after TPM normalisation tpm(umi.qc.ann) &lt;- log2(calculateFPKM(umi.qc.ann, eff_length) + 1) tmp &lt;- runPCA( umi.qc.ann, exprs_values = &quot;tpm&quot;, ) plotPCA( tmp, colour_by = &quot;batch&quot;, size_by = &quot;total_features_by_counts&quot;, shape_by = &quot;individual&quot; ) knitr::include_graphics(&quot;https://scrnaseq-course.cog.sanger.ac.uk/website/exprs-norm_files/figure-html/norm-pca-tpm-1.png&quot;) Note The PCA looks for differences between cells. Gene length is the same across cells for each gene thus FPKM is almost identical to the CPM plot (it is just rotated) since it performs CPM first then normalizes gene length. Whereas, TPM is different because it weights genes by their length before performing CPM. 7.8.6 Exercise Perform the same analysis with read counts of the tung data. Use tung/reads.rds file to load the reads SCE object. Once you have finished please compare your results to ours (next chapter). 7.9 Normalization practice (Reads) library(scRNA.seq.funcs) library(scater) library(scran) options(stringsAsFactors = FALSE) set.seed(1234567) library(knitr) opts_chunk$set(out.width=&#39;90%&#39;, fig.align = &#39;center&#39;, echo=FALSE) reads &lt;- readRDS(&quot;data/tung/reads.rds&quot;) reads.qc &lt;- reads[rowData(reads)$use, colData(reads)$use] endog_genes &lt;- !rowData(reads.qc)$is_feature_control tmp &lt;- runPCA( reads.qc[endog_genes, ], exprs_values = &quot;logcounts_raw&quot; ) plotPCA( tmp, colour_by = &quot;batch&quot;, size_by = &quot;total_features_by_counts&quot;, shape_by = &quot;individual&quot; ) Figure 7.47: PCA plot of the tung data logcounts(reads.qc) &lt;- log2(calculateCPM(reads.qc, use_size_factors = FALSE) + 1) plotPCA( reads.qc[endog_genes, ], colour_by = &quot;batch&quot;, size_by = &quot;total_features_by_counts&quot;, shape_by = &quot;individual&quot; ) Figure 7.48: PCA plot of the tung data after CPM normalisation plotRLE( reads.qc[endog_genes, ], exprs_values = &quot;logcounts_raw&quot;, colour_by = &quot;batch&quot; ) Figure 7.49: Cell-wise RLE of the tung data plotRLE( reads.qc[endog_genes, ], exprs_values = &quot;logcounts&quot;, colour_by = &quot;batch&quot; ) Figure 7.50: Cell-wise RLE of the tung data qclust &lt;- quickCluster(reads.qc, min.size = 30) ## Warning: Setting &#39;use.ranks=TRUE&#39; for the old defaults. ## Set &#39;use.ranks=FALSE&#39; for the new defaults. reads.qc &lt;- computeSumFactors(reads.qc, sizes = 15, clusters = qclust) reads.qc &lt;- normalize(reads.qc) ## Warning in .get_all_sf_sets(object): spike-in set &#39;ERCC&#39; should have its ## own size factors ## Warning in .get_all_sf_sets(object): spike-in set &#39;MT&#39; should have its own ## size factors plotPCA( reads.qc[endog_genes, ], colour_by = &quot;batch&quot;, size_by = &quot;total_features_by_counts&quot;, shape_by = &quot;individual&quot; ) Figure 7.51: PCA plot of the tung data after LSF normalisation plotRLE( reads.qc[endog_genes, ], exprs_values = &quot;logcounts_raw&quot;, colour_by = &quot;batch&quot; ) Figure 7.52: Cell-wise RLE of the tung data plotRLE( reads.qc[endog_genes, ], exprs_values = &quot;logcounts&quot;, colour_by = &quot;batch&quot; ) Figure 7.53: Cell-wise RLE of the tung data logcounts(reads.qc) &lt;- log2(Down_Sample_Matrix(counts(reads.qc)) + 1) plotPCA( reads.qc[endog_genes, ], colour_by = &quot;batch&quot;, size_by = &quot;total_features_by_counts&quot;, shape_by = &quot;individual&quot; ) Figure 7.54: PCA plot of the tung data after downsampling plotRLE( reads.qc[endog_genes, ], exprs_values = &quot;logcounts_raw&quot;, colour_by = &quot;batch&quot; ) Figure 7.55: Cell-wise RLE of the tung data plotRLE( reads.qc[endog_genes, ], exprs_values = &quot;logcounts&quot;, colour_by = &quot;batch&quot; ) Figure 7.56: Cell-wise RLE of the tung data reads.qc &lt;- getBMFeatureAnnos( reads.qc, filters = &quot;ensembl_gene_id&quot;, attributes = c( &quot;ensembl_gene_id&quot;, &quot;hgnc_symbol&quot;, &quot;chromosome_name&quot;, &quot;start_position&quot;, &quot;end_position&quot; ), biomart = &quot;ENSEMBL_MART_ENSEMBL&quot;, dataset = &quot;hsapiens_gene_ensembl&quot;, host = &quot;www.ensembl.org&quot; ) reads.qc.ann &lt;- reads.qc[!is.na(rowData(reads.qc)$ensembl_gene_id), ] eff_length &lt;- abs(rowData(reads.qc.ann)$end_position - rowData(reads.qc.ann)$start_position) / 1000 tpm(reads.qc.ann) &lt;- log2(calculateTPM(reads.qc.ann, eff_length) + 1) tmp &lt;- runPCA( reads.qc.ann, exprs_values = &quot;tpm&quot;, ) plotPCA( tmp, colour_by = &quot;batch&quot;, size_by = &quot;total_features_by_counts&quot;, shape_by = &quot;individual&quot; ) Figure 7.57: PCA plot of the tung data after TPM normalisation tpm(reads.qc.ann) &lt;- log2(calculateFPKM(reads.qc.ann, eff_length) + 1) tmp &lt;- runPCA( reads.qc.ann, exprs_values = &quot;tpm&quot;, ) plotPCA( tmp, colour_by = &quot;batch&quot;, size_by = &quot;total_features_by_counts&quot;, shape_by = &quot;individual&quot; ) 7.10 Dealing with confounders 7.10.1 Introduction In the previous chapter we normalized for library size, effectively removing it as a confounder. Now we will consider removing other less well defined confounders from our data. Technical confounders (aka batch effects) can arise from difference in reagents, isolation methods, the lab/experimenter who performed the experiment, even which day/time the experiment was performed. Accounting for technical confounders, and batch effects particularly, is a large topic that also involves principles of experimental design. Here we address approaches that can be taken to account for confounders when the experimental design is appropriate. Fundamentally, accounting for technical confounders involves identifying and, ideally, removing sources of variation in the expression data that are not related to (i.e. are confounding) the biological signal of interest. Various approaches exist, some of which use spike-in or housekeeping genes, and some of which use endogenous genes. 7.10.1.1 Advantages and disadvantages of using spike-ins to remove confounders The use of spike-ins as control genes is appealing, since the same amount of ERCC (or other) spike-in was added to each cell in our experiment. In principle, all the variablity we observe for these genes is due to technical noise; whereas endogenous genes are affected by both technical noise and biological variability. Technical noise can be removed by fitting a model to the spike-ins and “substracting” this from the endogenous genes. There are several methods available based on this premise (eg. BASiCS, scLVM, RUVg); each using different noise models and different fitting procedures. Alternatively, one can identify genes which exhibit significant variation beyond technical noise (eg. Distance to median, Highly variable genes). However, there are issues with the use of spike-ins for normalisation (particularly ERCCs, derived from bacterial sequences), including that their variability can, for various reasons, actually be higher than that of endogenous genes. Given the issues with using spike-ins, better results can often be obtained by using endogenous genes instead. Where we have a large number of endogenous genes that, on average, do not vary systematically between cells and where we expect technical effects to affect a large number of genes (a very common and reasonable assumption), then such methods (for example, the RUVs method) can perform well. We explore both general approaches below. library(scRNA.seq.funcs) library(RUVSeq) library(scater) library(SingleCellExperiment) library(scran) library(kBET) library(sva) # Combat library(edgeR) library(harmony) set.seed(1234567) options(stringsAsFactors = FALSE) umi &lt;- readRDS(&quot;data/tung/umi.rds&quot;) umi.qc &lt;- umi[rowData(umi)$use, colData(umi)$use] endog_genes &lt;- !rowData(umi.qc)$is_feature_control erccs &lt;- rowData(umi.qc)$is_feature_control qclust &lt;- quickCluster(umi.qc, min.size = 30) umi.qc &lt;- computeSumFactors(umi.qc, sizes = 15, clusters = qclust) umi.qc &lt;- normalize(umi.qc) 7.10.2 Remove Unwanted Variation Factors contributing to technical noise frequently appear as “batch effects” where cells processed on different days or by different technicians systematically vary from one another. Removing technical noise and correcting for batch effects can frequently be performed using the same tool or slight variants on it. We will be considering the Remove Unwanted Variation (RUVSeq). Briefly, RUVSeq works as follows. For \\(n\\) samples and \\(J\\) genes, consider the following generalized linear model (GLM), where the RNA-Seq read counts are regressed on both the known covariates of interest and unknown factors of unwanted variation: \\[\\log E[Y|W,X,O] = W\\alpha + X\\beta + O\\] Here, \\(Y\\) is the \\(n \\times J\\) matrix of observed gene-level read counts, \\(W\\) is an \\(n \\times k\\) matrix corresponding to the factors of “unwanted variation” and \\(O\\) is an \\(n \\times J\\) matrix of offsets that can either be set to zero or estimated with some other normalization procedure (such as upper-quartile normalization). The simultaneous estimation of \\(W\\), \\(\\alpha\\), \\(\\beta\\), and \\(k\\) is infeasible. For a given \\(k\\), instead the following three approaches to estimate the factors of unwanted variation \\(W\\) are used: RUVg uses negative control genes (e.g. ERCCs), assumed to have constant expression across samples; RUVs uses centered (technical) replicate/negative control samples for which the covariates of interest are constant; RUVr uses residuals, e.g., from a first-pass GLM regression of the counts on the covariates of interest. We will concentrate on the first two approaches. 7.10.2.1 RUVg ruvg &lt;- RUVg(counts(umi.qc), erccs, k = 1) assay(umi.qc, &quot;ruvg1&quot;) &lt;- log2( t(t(ruvg$normalizedCounts) / colSums(ruvg$normalizedCounts) * 1e6) + 1 ) ruvg &lt;- RUVg(counts(umi.qc), erccs, k = 10) assay(umi.qc, &quot;ruvg10&quot;) &lt;- log2( t(t(ruvg$normalizedCounts) / colSums(ruvg$normalizedCounts) * 1e6) + 1 ) 7.10.2.2 RUVs scIdx &lt;- matrix(-1, ncol = max(table(umi.qc$individual)), nrow = 3) tmp &lt;- which(umi.qc$individual == &quot;NA19098&quot;) scIdx[1, 1:length(tmp)] &lt;- tmp tmp &lt;- which(umi.qc$individual == &quot;NA19101&quot;) scIdx[2, 1:length(tmp)] &lt;- tmp tmp &lt;- which(umi.qc$individual == &quot;NA19239&quot;) scIdx[3, 1:length(tmp)] &lt;- tmp cIdx &lt;- rownames(umi.qc) ruvs &lt;- RUVs(counts(umi.qc), cIdx, k = 1, scIdx = scIdx, isLog = FALSE) assay(umi.qc, &quot;ruvs1&quot;) &lt;- log2( t(t(ruvs$normalizedCounts) / colSums(ruvs$normalizedCounts) * 1e6) + 1 ) ruvs &lt;- RUVs(counts(umi.qc), cIdx, k = 10, scIdx = scIdx, isLog = FALSE) assay(umi.qc, &quot;ruvs10&quot;) &lt;- log2( t(t(ruvs$normalizedCounts) / colSums(ruvs$normalizedCounts) * 1e6) + 1 ) 7.10.3 Combat If you have an experiment with a balanced design, Combat can be used to eliminate batch effects while preserving biological effects by specifying the biological effects using the mod parameter. However the Tung data contains multiple experimental replicates rather than a balanced design so using mod1 to preserve biological variability will result in an error. combat_data &lt;- logcounts(umi.qc) mod_data &lt;- as.data.frame(t(combat_data)) # Basic batch removal mod0 = model.matrix(~ 1, data = mod_data) # Preserve biological variability mod1 = model.matrix(~ umi.qc$individual, data = mod_data) # adjust for total genes detected mod2 = model.matrix(~ umi.qc$total_features_by_counts, data = mod_data) assay(umi.qc, &quot;combat&quot;) &lt;- ComBat( dat = t(mod_data), batch = factor(umi.qc$batch), mod = mod0, par.prior = TRUE, prior.plots = FALSE ) Exercise 1 Perform ComBat correction accounting for total features as a co-variate. Store the corrected matrix in the combat_tf slot. assay(umi.qc, &quot;combat_tf&quot;) &lt;- ComBat( dat = t(mod_data), batch = factor(umi.qc$batch), mod = mod2, par.prior = TRUE, prior.plots = FALSE ) 7.10.4 mnnCorrect mnnCorrect (Haghverdi et al. 2017) assumes that each batch shares at least one biological condition with each other batch. Thus it works well for a variety of balanced experimental designs. However, the Tung data contains multiple replicates for each invidividual rather than balanced batches, thus we will normalized each individual separately. Note that this will remove batch effects between batches within the same individual but not the batch effects between batches in different individuals, due to the confounded experimental design. Thus we will merge a replicate from each individual to form three batches. do_mnn &lt;- function(data.qc) { batch1 &lt;- logcounts(data.qc[, data.qc$replicate == &quot;r1&quot;]) batch2 &lt;- logcounts(data.qc[, data.qc$replicate == &quot;r2&quot;]) batch3 &lt;- logcounts(data.qc[, data.qc$replicate == &quot;r3&quot;]) if (ncol(batch2) &gt; 0) { x = mnnCorrect( batch1, batch2, batch3, k = 20, sigma = 0.1, cos.norm.in = TRUE, svd.dim = 2 ) res1 &lt;- x$corrected[[1]] res2 &lt;- x$corrected[[2]] res3 &lt;- x$corrected[[3]] dimnames(res1) &lt;- dimnames(batch1) dimnames(res2) &lt;- dimnames(batch2) dimnames(res3) &lt;- dimnames(batch3) return(cbind(res1, res2, res3)) } else { x = mnnCorrect( batch1, batch3, k = 20, sigma = 0.1, cos.norm.in = TRUE, svd.dim = 2 ) res1 &lt;- x$corrected[[1]] res3 &lt;- x$corrected[[2]] dimnames(res1) &lt;- dimnames(batch1) dimnames(res3) &lt;- dimnames(batch3) return(cbind(res1, res3)) } } indi1 &lt;- do_mnn(umi.qc[, umi.qc$individual == &quot;NA19098&quot;]) indi2 &lt;- do_mnn(umi.qc[, umi.qc$individual == &quot;NA19101&quot;]) indi3 &lt;- do_mnn(umi.qc[, umi.qc$individual == &quot;NA19239&quot;]) assay(umi.qc, &quot;mnn&quot;) &lt;- cbind(indi1, indi2, indi3) # For a balanced design: #assay(umi.qc, &quot;mnn&quot;) &lt;- mnnCorrect( # list(B1 = logcounts(batch1), B2 = logcounts(batch2), B3 = logcounts(batch3)), # k = 20, # sigma = 0.1, # cos.norm = TRUE, # svd.dim = 2 #) 7.10.5 GLM A general linear model is a simpler version of Combat. It can correct for batches while preserving biological effects if you have a balanced design. In a confounded/replicate design biological effects will not be fit/preserved. Similar to mnnCorrect we could remove batch effects from each individual separately in order to preserve biological (and technical) variance between individuals. For demonstation purposes we will naively correct all cofounded batch effects: glm_fun &lt;- function(g, batch, indi) { model &lt;- glm(g ~ batch + indi) model$coef[1] &lt;- 0 # replace intercept with 0 to preserve reference batch. return(model$coef) } effects &lt;- apply( logcounts(umi.qc), 1, glm_fun, batch = umi.qc$batch, indi = umi.qc$individual ) corrected &lt;- logcounts(umi.qc) - t(effects[as.numeric(factor(umi.qc$batch)), ]) assay(umi.qc, &quot;glm&quot;) &lt;- corrected Exercise 2 Perform GLM correction for each individual separately. Store the final corrected matrix in the glm_indi slot. glm_fun1 &lt;- function(g, batch) { model &lt;- glm(g ~ batch) model$coef[1] &lt;- 0 # replace intercept with 0 to preserve reference batch. return(model$coef) } do_glm &lt;- function(data.qc) { effects &lt;- apply( logcounts(data.qc), 1, glm_fun1, batch = data.qc$batch ) corrected &lt;- logcounts(data.qc) - t(effects[as.numeric(factor(data.qc$batch)), ]) return(corrected) } indi1 &lt;- do_glm(umi.qc[, umi.qc$individual == &quot;NA19098&quot;]) indi2 &lt;- do_glm(umi.qc[, umi.qc$individual == &quot;NA19101&quot;]) indi3 &lt;- do_glm(umi.qc[, umi.qc$individual == &quot;NA19239&quot;]) assay(umi.qc, &quot;glm_indi&quot;) &lt;- cbind(indi1, indi2, indi3); 7.10.6 Harmony Harmony [Korsunsky2018fast] is a newer batch correction method, which is designed to operate on PC space. The algorithm proceeds to iteratively cluster the cells, with the objective function formulated to promote cells from multiple datasets within each cluster. Once a clustering is obtained, the positions of the centroids of each dataset are obtained on a per-cluster basis and the coordinates are corrected. This procedure is iterated until convergence. Harmony comes with a theta parameter that controls the degree of batch correction (higher values lead to more dataset integration), and can account for multiple experimental and biological factors on input. Seeing how the end result of Harmony is an altered dimensional reduction space created on the basis of PCA, we plot the obtained manifold here and exclude it from the rest of the follow-ups in the section. umi.qc.endog = umi.qc[endog_genes,] umi.qc.endog = runPCA(umi.qc.endog, exprs_values = &#39;logcounts&#39;, ncomponents = 20) pca &lt;- as.matrix(umi.qc.endog@reducedDims@listData[[&quot;PCA&quot;]]) harmony_emb &lt;- HarmonyMatrix(pca, umi.qc.endog$batch, theta=2, do_pca=FALSE) umi.qc.endog@reducedDims@listData[[&#39;harmony&#39;]] &lt;- harmony_emb plotReducedDim( umi.qc.endog, use_dimred = &#39;harmony&#39;, colour_by = &quot;batch&quot;, size_by = &quot;total_features_by_counts&quot;, shape_by = &quot;individual&quot; ) 7.10.7 How to evaluate and compare confounder removal strategies A key question when considering the different methods for removing confounders is how to quantitatively determine which one is the most effective. The main reason why comparisons are challenging is because it is often difficult to know what corresponds to technical counfounders and what is interesting biological variability. Here, we consider three different metrics which are all reasonable based on our knowledge of the experimental design. Depending on the biological question that you wish to address, it is important to choose a metric that allows you to evaluate the confounders that are likely to be the biggest concern for the given situation. 7.10.7.1 Effectiveness 1 We evaluate the effectiveness of the normalization by inspecting the PCA plot where colour corresponds the technical replicates and shape corresponds to different biological samples (individuals). Separation of biological samples and interspersed batches indicates that technical variation has been removed. We always use log2-cpm normalized data to match the assumptions of PCA. for(n in assayNames(umi.qc)) { tmp &lt;- runPCA( umi.qc[endog_genes, ], exprs_values = n ) print( plotPCA( tmp, colour_by = &quot;batch&quot;, size_by = &quot;total_features_by_counts&quot;, shape_by = &quot;individual&quot; ) + ggtitle(n) ) } Exercise 3 Consider different ks for RUV normalizations. Which gives the best results? 7.10.7.2 Effectiveness 2 We can also examine the effectiveness of correction using the relative log expression (RLE) across cells to confirm technical noise has been removed from the dataset. Note RLE only evaluates whether the number of genes higher and lower than average are equal for each cell - i.e. systemic technical effects. Random technical noise between batches may not be detected by RLE. res &lt;- list() for(n in assayNames(umi.qc)) { res[[n]] &lt;- suppressWarnings(calc_cell_RLE(assay(umi.qc, n), erccs)) } par(mar=c(6,4,1,1)) boxplot(res, las=2) #### Effectiveness 3 Another method to check the efficacy of batch-effect correction is to consider the intermingling of points from different batches in local subsamples of the data. If there are no batch-effects then proportion of cells from each batch in any local region should be equal to the global proportion of cells in each batch. kBET (Buttner et al. 2017) takes kNN networks around random cells and tests the number of cells from each batch against a binomial distribution. The rejection rate of these tests indicates the severity of batch-effects still present in the data (high rejection rate = strong batch effects). kBET assumes each batch contains the same complement of biological groups, thus it can only be applied to the entire dataset if a perfectly balanced design has been used. However, kBET can also be applied to replicate-data if it is applied to each biological group separately. In the case of the Tung data, we will apply kBET to each individual independently to check for residual batch effects. However, this method will not identify residual batch-effects which are confounded with biological conditions. In addition, kBET does not determine if biological signal has been preserved. compare_kBET_results &lt;- function(sce){ indiv &lt;- unique(sce$individual) norms &lt;- assayNames(sce) # Get all normalizations results &lt;- list() for (i in indiv){ for (j in norms){ tmp &lt;- kBET( df = t(assay(sce[,sce$individual== i], j)), batch = sce$batch[sce$individual==i], heuristic = TRUE, verbose = FALSE, addTest = FALSE, plot = FALSE) results[[i]][[j]] &lt;- tmp$summary$kBET.observed[1] } } return(as.data.frame(results)) } eff_debatching &lt;- compare_kBET_results(umi.qc) require(&quot;reshape2&quot;) require(&quot;RColorBrewer&quot;) # Plot results dod &lt;- melt(as.matrix(eff_debatching), value.name = &quot;kBET&quot;) colnames(dod)[1:2] &lt;- c(&quot;Normalisation&quot;, &quot;Individual&quot;) colorset &lt;- c(&#39;gray&#39;, brewer.pal(n = 9, &quot;RdYlBu&quot;)) ggplot(dod, aes(Normalisation, Individual, fill=kBET)) + geom_tile() + scale_fill_gradient2( na.value = &quot;gray&quot;, low = colorset[2], mid=colorset[6], high = colorset[10], midpoint = 0.5, limit = c(0,1)) + scale_x_discrete(expand = c(0, 0)) + scale_y_discrete(expand = c(0, 0)) + theme( axis.text.x = element_text( angle = 45, vjust = 1, size = 12, hjust = 1 ) ) + ggtitle(&quot;Effect of batch regression methods per individual&quot;) Exercise 4 Why do the raw counts appear to have little batch effects? 7.10.8 Big Exercise Perform the same analysis with read counts of the tung data. Use tung/reads.rds file to load the reads SCE object. Once you have finished please compare your results to ours (next chapter). Additionally, experiment with other combinations of normalizations and compare the results. 7.11 Dealing with confounders (Reads) library(scRNA.seq.funcs) library(RUVSeq) library(scater) library(SingleCellExperiment) library(scran) library(kBET) library(sva) # Combat library(harmony) library(edgeR) set.seed(1234567) options(stringsAsFactors = FALSE) reads &lt;- readRDS(&quot;data/tung/reads.rds&quot;) reads.qc &lt;- reads[rowData(reads)$use, colData(reads)$use] endog_genes &lt;- !rowData(reads.qc)$is_feature_control erccs &lt;- rowData(reads.qc)$is_feature_control qclust &lt;- quickCluster(reads.qc, min.size = 30) reads.qc &lt;- computeSumFactors(reads.qc, sizes = 15, clusters = qclust) reads.qc &lt;- normalize(reads.qc) ruvg &lt;- RUVg(counts(reads.qc), erccs, k = 1) assay(reads.qc, &quot;ruvg1&quot;) &lt;- log2( t(t(ruvg$normalizedCounts) / colSums(ruvg$normalizedCounts) * 1e6) + 1 ) ruvg &lt;- RUVg(counts(reads.qc), erccs, k = 10) assay(reads.qc, &quot;ruvg10&quot;) &lt;- log2( t(t(ruvg$normalizedCounts) / colSums(ruvg$normalizedCounts) * 1e6) + 1 ) scIdx &lt;- matrix(-1, ncol = max(table(reads.qc$individual)), nrow = 3) tmp &lt;- which(reads.qc$individual == &quot;NA19098&quot;) scIdx[1, 1:length(tmp)] &lt;- tmp tmp &lt;- which(reads.qc$individual == &quot;NA19101&quot;) scIdx[2, 1:length(tmp)] &lt;- tmp tmp &lt;- which(reads.qc$individual == &quot;NA19239&quot;) scIdx[3, 1:length(tmp)] &lt;- tmp cIdx &lt;- rownames(reads.qc) ruvs &lt;- RUVs(counts(reads.qc), cIdx, k = 1, scIdx = scIdx, isLog = FALSE) assay(reads.qc, &quot;ruvs1&quot;) &lt;- log2( t(t(ruvs$normalizedCounts) / colSums(ruvs$normalizedCounts) * 1e6) + 1 ) ruvs &lt;- RUVs(counts(reads.qc), cIdx, k = 10, scIdx = scIdx, isLog = FALSE) assay(reads.qc, &quot;ruvs10&quot;) &lt;- log2( t(t(ruvs$normalizedCounts) / colSums(ruvs$normalizedCounts) * 1e6) + 1 ) combat_data &lt;- logcounts(reads.qc) mod_data &lt;- as.data.frame(t(combat_data)) # Basic batch removal mod0 = model.matrix(~ 1, data = mod_data) # Preserve biological variability mod1 = model.matrix(~ reads.qc$individual, data = mod_data) # adjust for total genes detected mod2 = model.matrix(~ reads.qc$total_features_by_counts, data = mod_data) assay(reads.qc, &quot;combat&quot;) &lt;- ComBat( dat = t(mod_data), batch = factor(reads.qc$batch), mod = mod0, par.prior = TRUE, prior.plots = FALSE ) Exercise 1 assay(reads.qc, &quot;combat_tf&quot;) &lt;- ComBat( dat = t(mod_data), batch = factor(reads.qc$batch), mod = mod2, par.prior = TRUE, prior.plots = FALSE ) do_mnn &lt;- function(data.qc) { batch1 &lt;- logcounts(data.qc[, data.qc$replicate == &quot;r1&quot;]) batch2 &lt;- logcounts(data.qc[, data.qc$replicate == &quot;r2&quot;]) batch3 &lt;- logcounts(data.qc[, data.qc$replicate == &quot;r3&quot;]) if (ncol(batch2) &gt; 0) { x = mnnCorrect( batch1, batch2, batch3, k = 20, sigma = 0.1, cos.norm.in = TRUE, svd.dim = 2 ) res1 &lt;- x$corrected[[1]] res2 &lt;- x$corrected[[2]] res3 &lt;- x$corrected[[3]] dimnames(res1) &lt;- dimnames(batch1) dimnames(res2) &lt;- dimnames(batch2) dimnames(res3) &lt;- dimnames(batch3) return(cbind(res1, res2, res3)) } else { x = mnnCorrect( batch1, batch3, k = 20, sigma = 0.1, cos.norm.in = TRUE, svd.dim = 2 ) res1 &lt;- x$corrected[[1]] res3 &lt;- x$corrected[[2]] dimnames(res1) &lt;- dimnames(batch1) dimnames(res3) &lt;- dimnames(batch3) return(cbind(res1, res3)) } } indi1 &lt;- do_mnn(reads.qc[, reads.qc$individual == &quot;NA19098&quot;]) indi2 &lt;- do_mnn(reads.qc[, reads.qc$individual == &quot;NA19101&quot;]) indi3 &lt;- do_mnn(reads.qc[, reads.qc$individual == &quot;NA19239&quot;]) assay(reads.qc, &quot;mnn&quot;) &lt;- cbind(indi1, indi2, indi3) # For a balanced design: #assay(reads.qc, &quot;mnn&quot;) &lt;- mnnCorrect( # list(B1 = logcounts(batch1), B2 = logcounts(batch2), B3 = logcounts(batch3)), # k = 20, # sigma = 0.1, # cos.norm = TRUE, # svd.dim = 2 #) glm_fun &lt;- function(g, batch, indi) { model &lt;- glm(g ~ batch + indi) model$coef[1] &lt;- 0 # replace intercept with 0 to preserve reference batch. return(model$coef) } effects &lt;- apply( logcounts(reads.qc), 1, glm_fun, batch = reads.qc$batch, indi = reads.qc$individual ) corrected &lt;- logcounts(reads.qc) - t(effects[as.numeric(factor(reads.qc$batch)), ]) assay(reads.qc, &quot;glm&quot;) &lt;- corrected Exercise 2 glm_fun1 &lt;- function(g, batch) { model &lt;- glm(g ~ batch) model$coef[1] &lt;- 0 # replace intercept with 0 to preserve reference batch. return(model$coef) } do_glm &lt;- function(data.qc) { effects &lt;- apply( logcounts(data.qc), 1, glm_fun1, batch = data.qc$batch ) corrected &lt;- logcounts(data.qc) - t(effects[as.numeric(factor(data.qc$batch)), ]) return(corrected) } indi1 &lt;- do_glm(reads.qc[, reads.qc$individual == &quot;NA19098&quot;]) indi2 &lt;- do_glm(reads.qc[, reads.qc$individual == &quot;NA19101&quot;]) indi3 &lt;- do_glm(reads.qc[, reads.qc$individual == &quot;NA19239&quot;]) assay(reads.qc, &quot;glm_indi&quot;) &lt;- cbind(indi1, indi2, indi3); reads.qc.endog = reads.qc[endog_genes,] reads.qc.endog = runPCA(reads.qc.endog, exprs_values = &#39;logcounts&#39;, ncomponents = 20) pca &lt;- as.matrix(reads.qc.endog@reducedDims@listData[[&quot;PCA&quot;]]) harmony_emb &lt;- HarmonyMatrix(pca, reads.qc.endog$batch, theta=2, do_pca=FALSE) reads.qc.endog@reducedDims@listData[[&#39;harmony&#39;]] &lt;- harmony_emb plotReducedDim( reads.qc.endog, use_dimred = &#39;harmony&#39;, colour_by = &quot;batch&quot;, size_by = &quot;total_features_by_counts&quot;, shape_by = &quot;individual&quot; ) for(n in assayNames(reads.qc)) { tmp &lt;- runPCA( reads.qc[endog_genes, ], exprs_values = n ) print( plotPCA( tmp, colour_by = &quot;batch&quot;, size_by = &quot;total_features_by_counts&quot;, shape_by = &quot;individual&quot; ) + ggtitle(n) ) } ## R version 3.6.0 (2019-04-26) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 7 x64 (build 7601) Service Pack 1 ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=Chinese (Simplified)_People&#39;s Republic of China.936 ## [2] LC_CTYPE=Chinese (Simplified)_People&#39;s Republic of China.936 ## [3] LC_MONETARY=Chinese (Simplified)_People&#39;s Republic of China.936 ## [4] LC_NUMERIC=C ## [5] LC_TIME=Chinese (Simplified)_People&#39;s Republic of China.936 ## ## attached base packages: ## [1] parallel stats4 stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] scran_1.12.1 scRNA.seq.funcs_0.1.0 ## [3] limma_3.40.2 scater_1.12.2 ## [5] ggplot2_3.2.0 SingleCellExperiment_1.6.0 ## [7] SummarizedExperiment_1.14.0 DelayedArray_0.10.0 ## [9] BiocParallel_1.17.18 matrixStats_0.54.0 ## [11] Biobase_2.44.0 GenomicRanges_1.36.0 ## [13] GenomeInfoDb_1.20.0 IRanges_2.18.1 ## [15] S4Vectors_0.22.0 BiocGenerics_0.30.0 ## [17] knitr_1.23 ## ## loaded via a namespace (and not attached): ## [1] Rtsne_0.15 ggbeeswarm_0.6.0 ## [3] colorspace_1.4-1 mvoutlier_2.0.9 ## [5] class_7.3-15 modeltools_0.2-22 ## [7] rio_0.5.16 dynamicTreeCut_1.63-1 ## [9] mclust_5.4.4 XVector_0.24.0 ## [11] pls_2.7-1 BiocNeighbors_1.2.0 ## [13] cvTools_0.3.2 flexmix_2.3-15 ## [15] mvtnorm_1.0-11 ranger_0.11.2 ## [17] codetools_0.2-16 splines_3.6.0 ## [19] sROC_0.1-2 robustbase_0.93-5 ## [21] robCompositions_2.1.0 cluster_2.1.0 ## [23] kernlab_0.9-27 rrcov_1.4-7 ## [25] compiler_3.6.0 dqrng_0.2.1 ## [27] assertthat_0.2.1 Matrix_1.2-17 ## [29] lazyeval_0.2.2 BiocSingular_1.0.0 ## [31] htmltools_0.3.6 tools_3.6.0 ## [33] igraph_1.2.4.1 rsvd_1.0.1 ## [35] gtable_0.3.0 glue_1.3.1 ## [37] GenomeInfoDbData_1.2.1 dplyr_0.8.2 ## [39] Rcpp_1.0.1 carData_3.0-2 ## [41] cellranger_1.1.0 zCompositions_1.3.2-1 ## [43] sgeostat_1.0-27 fpc_2.2-3 ## [45] DelayedMatrixStats_1.6.0 lmtest_0.9-37 ## [47] xfun_0.8 laeken_0.5.0 ## [49] stringr_1.4.0 openxlsx_4.1.0.1 ## [51] irlba_2.3.3 hypergeo_1.2-13 ## [53] statmod_1.4.32 edgeR_3.26.5 ## [55] DEoptimR_1.0-8 zlibbioc_1.30.0 ## [57] MASS_7.3-51.4 zoo_1.8-6 ## [59] scales_1.0.0 VIM_4.8.0 ## [61] hms_0.4.2 RColorBrewer_1.1-2 ## [63] yaml_2.2.0 curl_3.3 ## [65] NADA_1.6-1 gridExtra_2.3 ## [67] reshape_0.8.8 stringi_1.4.3 ## [69] highr_0.8 pcaPP_1.9-73 ## [71] orthopolynom_1.0-5 e1071_1.7-2 ## [73] contfrac_1.1-12 boot_1.3-22 ## [75] zip_2.0.2 truncnorm_1.0-8 ## [77] moments_0.14 rlang_0.4.0 ## [79] pkgconfig_2.0.2 prabclus_2.3-1 ## [81] bitops_1.0-6 evaluate_0.14 ## [83] lattice_0.20-38 purrr_0.3.2 ## [85] labeling_0.3 cowplot_0.9.4 ## [87] tidyselect_0.2.5 deSolve_1.23 ## [89] GGally_1.4.0 plyr_1.8.4 ## [91] magrittr_1.5 bookdown_0.11 ## [93] R6_2.4.0 pillar_1.4.2 ## [95] haven_2.1.0 foreign_0.8-71 ## [97] withr_2.1.2 survival_2.44-1.1 ## [99] abind_1.4-5 RCurl_1.95-4.12 ## [101] sp_1.3-1 nnet_7.3-12 ## [103] tibble_2.1.3 crayon_1.3.4 ## [105] car_3.0-3 rmarkdown_1.13 ## [107] viridis_0.5.1 locfit_1.5-9.1 ## [109] grid_3.6.0 readxl_1.3.1 ## [111] data.table_1.12.2 forcats_0.4.0 ## [113] vcd_1.4-4 digest_0.6.19 ## [115] diptest_0.75-7 tidyr_0.8.3 ## [117] elliptic_1.4-0 munsell_0.5.0 ## [119] beeswarm_0.2.3 viridisLite_0.3.0 ## [121] vipor_0.4.5 References "],
["references.html", "8 References", " 8 References "]
]
